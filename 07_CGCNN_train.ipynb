{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_templet = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --output=slurm_logs/%x_%A.out\n",
    "#SBATCH --error=slurm_logs/%x_%A.err\n",
    "#SBATCH --partition=C9654\n",
    "#SBATCH --nodelist=c3\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=64\n",
    "#SBATCH --mem-per-gpu=100G\n",
    "#SBATCH --gres=gpu:1\n",
    "export PATH=/opt/share/miniconda3/envs/mofmthnn/bin/:$PATH\n",
    "export LD_LIBRARY_PATH=/opt/share/miniconda3/envs/mofmthnn/lib/:$LD_LIBRARY_PATH\n",
    "\n",
    "srun python -u {py_executor} --progress_bar --task_cfg {task_config} --model_cfg {model_config}\n",
    "\"\"\".strip()\n",
    "\n",
    "def run_slurm_job(work_dir, executor=\"sbatch\", script_name=\"run\"):\n",
    "    work_dir = Path(work_dir)\n",
    "    # Create a script to run the job\n",
    "    process = subprocess.Popen(\n",
    "        f\"{executor} {work_dir/script_name}\",\n",
    "        # [executor, str(work_dir/'run'), \"&\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        shell=True,                                                                                                                         \n",
    "        env=os.environ.copy(),\n",
    "        cwd=str(work_dir)\n",
    "    )\n",
    "    return process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training original CGCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 199555\n",
      "Submitted job opt_tsd_ssd_ws24_cgcnn_raw with PID 1736896\n"
     ]
    }
   ],
   "source": [
    "work_dir = Path(\"./CGCNN_MT\").absolute()\n",
    "\n",
    "task_configs = [\n",
    "    # \"tsd_ssd\",\n",
    "    \"tsd_ssd_ws24\",\n",
    "    # \"tsd_ssd_ws24_water\",\n",
    "    # \"tsd_ssd_ws24_water_water4\",\n",
    "    # \"tsd_ssd_ws24_water\",\n",
    "    # \"ssd_ws24\",\n",
    "    # \"ws24\",\n",
    "    \"tsd\",\n",
    "    \"ssd\",\n",
    "    \"ws24_water\",\n",
    "    \"ws24_water4\",\n",
    "    \"ws24_acid\",\n",
    "    \"ws24_base\",\n",
    "    \"ws24_boiling\"\n",
    "                    ]\n",
    "model_configs = [\n",
    "    # \"att_cgcnn\",\n",
    "    # \"cgcnn\",\n",
    "    \"cgcnn_raw\",\n",
    "    # \"fcnn\",\n",
    "    # \"att_fcnn\",\n",
    "    # \"cgcnn_uni_atom\"\n",
    "]\n",
    "script_name = \"run_slurm.sh\"\n",
    "py_executor = \"hyperopt.py\"\n",
    "# py_executor = \"main.py\"\n",
    "model_conf = {\n",
    "            'batch_size': 32,\n",
    "            'max_epochs': 500, \n",
    "            'max_graph_len': 200,\n",
    "            'atom_fea_len': 256,\n",
    "            'extra_fea_len': 16,\n",
    "            'h_fea_len': 128,\n",
    "            'n_conv': 6,\n",
    "            'n_h': 4,\n",
    "            'dropout_prob': 0.5,\n",
    "            'use_extra_fea': False,\n",
    "            'use_cell_params': False,\n",
    "            'atom_layer_norm': False,\n",
    "            'loss_aggregation': \"fixed_weight_sum\",   # fixed_weight_sum, dwa, sum, sample_weight_sum, trainable_weight_sum\n",
    "            'dl_sampler': 'random',\n",
    "            'task_att_type': 'none',\n",
    "            'augment': False,\n",
    "            'lr': 0.001,\n",
    "            'lr_mult': 10,\n",
    "            'group_lr': False,\n",
    "            'optim_config': \"fine\",  # fine or coarse\n",
    "            'auto_lr_bs_find': False, \n",
    "            'patience': 50,\n",
    "            'task_norm': False,\n",
    "            'log_dir': \"logs\",\n",
    "            'optuna_name': \"optuna\",\n",
    "            }\n",
    "\n",
    "for task_config in task_configs:\n",
    "    for model_config in model_configs:\n",
    "        job_name = f\"{task_config.replace('_config', '')}_{model_config.replace('_config', '')}\"\n",
    "        if py_executor == \"hyperopt.py\":\n",
    "            job_name = \"opt_\" + job_name\n",
    "            # job_templet_ = job_templet + \" --pruning\"\n",
    "            job_templet_ = job_templet\n",
    "        else:\n",
    "            job_templet_ = job_templet\n",
    "        job_script = job_templet_.format(job_name=job_name, \n",
    "                                        task_config=task_config, \n",
    "                                        model_config=model_config,\n",
    "                                        py_executor=py_executor\n",
    "                                        )\n",
    "        \n",
    "        for key, value in model_conf.items():\n",
    "            if isinstance(value, bool):\n",
    "                if value:\n",
    "                    job_script += f\" --{key}\"\n",
    "                continue\n",
    "            job_script += f\" --{key} {value}\"\n",
    "        with open(work_dir/script_name, \"w\") as f:\n",
    "            f.write(job_script)\n",
    "        process = run_slurm_job(work_dir, executor=\"sbatch\", script_name=script_name)\n",
    "        ## get the output of the job\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == b'' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.decode().strip())\n",
    "        print(f\"Submitted job {job_name} with PID {process.pid}\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training refined CGCNN model (MOFSNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching: python -u hyperopt.py --progress_bar --task_cfg tsd_ssd_ws24 --model_cfg att_cgcnn --num_workers 14 --batch_size 128 --max_epochs 500 --max_graph_len 200 --atom_fea_len 256 --extra_fea_len 16 --h_fea_len 128 --n_conv 6 --n_h 4 --dropout_prob 0.5 --use_cell_params --atom_layer_norm --loss_aggregation fixed_weight_sum --dl_sampler random --task_att_type self --lr 0.001 --lr_mult 10 --group_lr --optim_config fine --patience 50 --task_norm --log_dir logs --optuna_name optuna\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/lightning_fabric/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-12-03 18:35:44.847099: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-03 18:35:44.914799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-03 18:35:46.446166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "[I 2025-12-03 18:35:48,241] Using an existing study with name 'tsd_ssd_ws24_att_cgcnn_fixed_weight_sum' instead of creating a new one.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 18\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : None\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 16\n",
      "extra_fea_len : 40\n",
      "h_fea_len : 176\n",
      "n_conv : 7\n",
      "n_h : 8\n",
      "att_S : 64\n",
      "dropout_prob : 0.1\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "Using task_weights from trainset: [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "    | Name                            | Type                | Params | In sizes                                 | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 909 K  | ?                                        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 176], [128, 176], [128, 176], [128, 176], [128, 176], [128, 176], [128, 176]]]\n",
      "1   | model.embedding_atom            | Linear              | 1.5 K  | [2304, 92]                               | [2304, 16]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 32     | [2304, 16]                               | [2304, 16]\n",
      "3   | model.convs                     | ModuleList          | 17.2 K | ?                                        | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 2.5 K  | [[2304, 16], [2304, 10, 41], [2304, 10]] | [2304, 16]\n",
      "5   | model.convs.0.fc_full           | Linear              | 2.4 K  | [2304, 10, 73]                           | [2304, 10, 32]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 64     | [23040, 32]                              | [23040, 32]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 32     | [2304, 16]                               | [2304, 16]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 16]                               | [2304, 16]\n",
      "11  | model.convs.1                   | ConvLayer           | 2.5 K  | [[2304, 16], [2304, 10, 41], [2304, 10]] | [2304, 16]\n",
      "12  | model.convs.1.fc_full           | Linear              | 2.4 K  | [2304, 10, 73]                           | [2304, 10, 32]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 64     | [23040, 32]                              | [23040, 32]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 32     | [2304, 16]                               | [2304, 16]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 16]                               | [2304, 16]\n",
      "18  | model.convs.2                   | ConvLayer           | 2.5 K  | [[2304, 16], [2304, 10, 41], [2304, 10]] | [2304, 16]\n",
      "19  | model.convs.2.fc_full           | Linear              | 2.4 K  | [2304, 10, 73]                           | [2304, 10, 32]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 64     | [23040, 32]                              | [23040, 32]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 32     | [2304, 16]                               | [2304, 16]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 16]                               | [2304, 16]\n",
      "25  | model.convs.3                   | ConvLayer           | 2.5 K  | [[2304, 16], [2304, 10, 41], [2304, 10]] | [2304, 16]\n",
      "26  | model.convs.3.fc_full           | Linear              | 2.4 K  | [2304, 10, 73]                           | [2304, 10, 32]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 64     | [23040, 32]                              | [23040, 32]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 32     | [2304, 16]                               | [2304, 16]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 16]                               | [2304, 16]\n",
      "32  | model.convs.4                   | ConvLayer           | 2.5 K  | [[2304, 16], [2304, 10, 41], [2304, 10]] | [2304, 16]\n",
      "33  | model.convs.4.fc_full           | Linear              | 2.4 K  | [2304, 10, 73]                           | [2304, 10, 32]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 64     | [23040, 32]                              | [23040, 32]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 32     | [2304, 16]                               | [2304, 16]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 16]                               | [2304, 16]\n",
      "39  | model.convs.5                   | ConvLayer           | 2.5 K  | [[2304, 16], [2304, 10, 41], [2304, 10]] | [2304, 16]\n",
      "40  | model.convs.5.fc_full           | Linear              | 2.4 K  | [2304, 10, 73]                           | [2304, 10, 32]\n",
      "41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "42  | model.convs.5.softplus1         | Softplus            | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "43  | model.convs.5.bn1               | BatchNorm1d         | 64     | [23040, 32]                              | [23040, 32]\n",
      "44  | model.convs.5.bn2               | BatchNorm1d         | 32     | [2304, 16]                               | [2304, 16]\n",
      "45  | model.convs.5.softplus2         | Softplus            | 0      | [2304, 16]                               | [2304, 16]\n",
      "46  | model.convs.6                   | ConvLayer           | 2.5 K  | [[2304, 16], [2304, 10, 41], [2304, 10]] | [2304, 16]\n",
      "47  | model.convs.6.fc_full           | Linear              | 2.4 K  | [2304, 10, 73]                           | [2304, 10, 32]\n",
      "48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "49  | model.convs.6.softplus1         | Softplus            | 0      | [2304, 10, 16]                           | [2304, 10, 16]\n",
      "50  | model.convs.6.bn1               | BatchNorm1d         | 64     | [23040, 32]                              | [23040, 32]\n",
      "51  | model.convs.6.bn2               | BatchNorm1d         | 32     | [2304, 16]                               | [2304, 16]\n",
      "52  | model.convs.6.softplus2         | Softplus            | 0      | [2304, 16]                               | [2304, 16]\n",
      "53  | model.embedding_extra           | Linear              | 280    | [128, 6]                                 | [128, 40]\n",
      "54  | model.embedding_extra_norm      | BatchNorm1d         | 80     | [128, 40]                                | [128, 40]\n",
      "55  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 40]                                | [128, 40]\n",
      "56  | model.conv_to_fc                | Linear              | 10.0 K | [128, 56]                                | [128, 176]\n",
      "57  | model.conv_to_fc_norm           | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "58  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "59  | model.dropout                   | Dropout             | 0      | [128, 176]                               | [128, 176]\n",
      "60  | model.fcs                       | ModuleList          | 218 K  | ?                                        | ?\n",
      "61  | model.fcs.0                     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "62  | model.fcs.1                     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "63  | model.fcs.2                     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "64  | model.fcs.3                     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "65  | model.fcs.4                     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "66  | model.fcs.5                     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "67  | model.fcs.6                     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "68  | model.norms                     | ModuleList          | 2.5 K  | ?                                        | ?\n",
      "69  | model.norms.0                   | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "70  | model.norms.1                   | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "71  | model.norms.2                   | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "72  | model.norms.3                   | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "73  | model.norms.4                   | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "74  | model.norms.5                   | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "75  | model.norms.6                   | BatchNorm1d         | 352    | [128, 176]                               | [128, 176]\n",
      "76  | model.softpluses                | ModuleList          | 0      | ?                                        | ?\n",
      "77  | model.softpluses.0              | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "78  | model.softpluses.1              | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "79  | model.softpluses.2              | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "80  | model.softpluses.3              | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "81  | model.softpluses.4              | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "82  | model.softpluses.5              | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "83  | model.softpluses.6              | Softplus            | 0      | [128, 176]                               | [128, 176]\n",
      "84  | model.fc_outs                   | ModuleList          | 2.7 K  | ?                                        | ?\n",
      "85  | model.fc_outs.0                 | OutputLayer         | 177    | [128, 176]                               | [128, 1]\n",
      "86  | model.fc_outs.0.fc              | Linear              | 177    | [128, 176]                               | [128, 1]\n",
      "87  | model.fc_outs.1                 | OutputLayer         | 354    | [128, 176]                               | [128, 2]\n",
      "88  | model.fc_outs.1.fc              | Sequential          | 354    | [128, 176]                               | [128, 2]\n",
      "89  | model.fc_outs.1.fc.0            | Linear              | 354    | [128, 176]                               | [128, 2]\n",
      "90  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "91  | model.fc_outs.2                 | OutputLayer         | 354    | [128, 176]                               | [128, 2]\n",
      "92  | model.fc_outs.2.fc              | Sequential          | 354    | [128, 176]                               | [128, 2]\n",
      "93  | model.fc_outs.2.fc.0            | Linear              | 354    | [128, 176]                               | [128, 2]\n",
      "94  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "95  | model.fc_outs.3                 | OutputLayer         | 708    | [128, 176]                               | [128, 4]\n",
      "96  | model.fc_outs.3.fc              | Sequential          | 708    | [128, 176]                               | [128, 4]\n",
      "97  | model.fc_outs.3.fc.0            | Linear              | 708    | [128, 176]                               | [128, 4]\n",
      "98  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                 | [128, 4]\n",
      "99  | model.fc_outs.4                 | OutputLayer         | 354    | [128, 176]                               | [128, 2]\n",
      "100 | model.fc_outs.4.fc              | Sequential          | 354    | [128, 176]                               | [128, 2]\n",
      "101 | model.fc_outs.4.fc.0            | Linear              | 354    | [128, 176]                               | [128, 2]\n",
      "102 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "103 | model.fc_outs.5                 | OutputLayer         | 354    | [128, 176]                               | [128, 2]\n",
      "104 | model.fc_outs.5.fc              | Sequential          | 354    | [128, 176]                               | [128, 2]\n",
      "105 | model.fc_outs.5.fc.0            | Linear              | 354    | [128, 176]                               | [128, 2]\n",
      "106 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "107 | model.fc_outs.6                 | OutputLayer         | 354    | [128, 176]                               | [128, 2]\n",
      "108 | model.fc_outs.6.fc              | Sequential          | 354    | [128, 176]                               | [128, 2]\n",
      "109 | model.fc_outs.6.fc.0            | Linear              | 354    | [128, 176]                               | [128, 2]\n",
      "110 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "111 | model.task_norms                | ModuleList          | 2.5 K  | ?                                        | ?\n",
      "112 | model.task_norms.0              | LayerNorm           | 352    | [128, 176]                               | [128, 176]\n",
      "113 | model.task_norms.1              | LayerNorm           | 352    | [128, 176]                               | [128, 176]\n",
      "114 | model.task_norms.2              | LayerNorm           | 352    | [128, 176]                               | [128, 176]\n",
      "115 | model.task_norms.3              | LayerNorm           | 352    | [128, 176]                               | [128, 176]\n",
      "116 | model.task_norms.4              | LayerNorm           | 352    | [128, 176]                               | [128, 176]\n",
      "117 | model.task_norms.5              | LayerNorm           | 352    | [128, 176]                               | [128, 176]\n",
      "118 | model.task_norms.6              | LayerNorm           | 352    | [128, 176]                               | [128, 176]\n",
      "119 | model.task_attentions           | ModuleList          | 654 K  | ?                                        | ?\n",
      "120 | model.task_attentions.0         | SelfAttention       | 93.5 K | [128, 176]                               | [128, 176]\n",
      "121 | model.task_attentions.0.query   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "122 | model.task_attentions.0.key     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "123 | model.task_attentions.0.value   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "124 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "125 | model.task_attentions.1         | SelfAttention       | 93.5 K | [128, 176]                               | [128, 176]\n",
      "126 | model.task_attentions.1.query   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "127 | model.task_attentions.1.key     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "128 | model.task_attentions.1.value   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "129 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "130 | model.task_attentions.2         | SelfAttention       | 93.5 K | [128, 176]                               | [128, 176]\n",
      "131 | model.task_attentions.2.query   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "132 | model.task_attentions.2.key     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "133 | model.task_attentions.2.value   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "134 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "135 | model.task_attentions.3         | SelfAttention       | 93.5 K | [128, 176]                               | [128, 176]\n",
      "136 | model.task_attentions.3.query   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "137 | model.task_attentions.3.key     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "138 | model.task_attentions.3.value   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "139 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "140 | model.task_attentions.4         | SelfAttention       | 93.5 K | [128, 176]                               | [128, 176]\n",
      "141 | model.task_attentions.4.query   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "142 | model.task_attentions.4.key     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "143 | model.task_attentions.4.value   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "144 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "145 | model.task_attentions.5         | SelfAttention       | 93.5 K | [128, 176]                               | [128, 176]\n",
      "146 | model.task_attentions.5.query   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "147 | model.task_attentions.5.key     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "148 | model.task_attentions.5.value   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "149 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "150 | model.task_attentions.6         | SelfAttention       | 93.5 K | [128, 176]                               | [128, 176]\n",
      "151 | model.task_attentions.6.query   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "152 | model.task_attentions.6.key     | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "153 | model.task_attentions.6.value   | Linear              | 31.2 K | [128, 176]                               | [128, 176]\n",
      "154 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "909 K     Trainable params\n",
      "0         Non-trainable params\n",
      "909 K     Total params\n",
      "3.637     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 18 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 909 K  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 176], [128, 176], [128, 176], [128, 176], [128, 176], [128, 176], [128, 176]]]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "909 K     Trainable params\n",
      "0         Non-trainable params\n",
      "909 K     Total params\n",
      "3.637     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(0): metric=0.2371 > best_metric=0.0000, log val results..\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "Epoch 0, global step 34: 'val_Metric' reached 0.23711 (best 0.23711), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=00-val_Metric=0.237.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(1): metric=0.3083 > best_metric=0.2371, log val results..\n",
      "Epoch 1, global step 68: 'val_Metric' reached 0.30831 (best 0.30831), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=01-val_Metric=0.308.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(2): metric=0.3323 > best_metric=0.3083, log val results..\n",
      "Epoch 2, global step 102: 'val_Metric' reached 0.33232 (best 0.33232), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=02-val_Metric=0.332.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(3): metric=0.3669 > best_metric=0.3323, log val results..\n",
      "Epoch 3, global step 136: 'val_Metric' reached 0.36692 (best 0.36692), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=03-val_Metric=0.367.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 4, global step 170: 'val_Metric' reached 0.36791 (best 0.36791), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=04-val_Metric=0.368.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(5): metric=0.3999 > best_metric=0.3669, log val results..\n",
      "Epoch 5, global step 204: 'val_Metric' reached 0.39985 (best 0.39985), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=05-val_Metric=0.400.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 6, global step 238: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 7, global step 272: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(8): metric=0.4340 > best_metric=0.3999, log val results..\n",
      "Epoch 8, global step 306: 'val_Metric' reached 0.43399 (best 0.43399), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=08-val_Metric=0.434.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(9): metric=0.4389 > best_metric=0.4340, log val results..\n",
      "Epoch 9, global step 340: 'val_Metric' reached 0.43891 (best 0.43891), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=09-val_Metric=0.439.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 10, global step 374: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(11): metric=0.4685 > best_metric=0.4389, log val results..\n",
      "Epoch 11, global step 408: 'val_Metric' reached 0.46848 (best 0.46848), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=11-val_Metric=0.468.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 12, global step 442: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 13, global step 476: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(14): metric=0.5076 > best_metric=0.4685, log val results..\n",
      "Epoch 14, global step 510: 'val_Metric' reached 0.50762 (best 0.50762), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=14-val_Metric=0.508.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 15, global step 544: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 16, global step 578: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 17, global step 612: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 18, global step 646: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 19, global step 680: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 20, global step 714: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 21, global step 748: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 22, global step 782: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 23, global step 816: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 24, global step 850: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 25, global step 884: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 26, global step 918: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 27, global step 952: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 28, global step 986: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 29, global step 1020: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 30, global step 1054: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 31, global step 1088: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 32, global step 1122: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 33, global step 1156: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(34): metric=0.5106 > best_metric=0.5076, log val results..\n",
      "Epoch 34, global step 1190: 'val_Metric' reached 0.51055 (best 0.51055), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=34-val_Metric=0.511.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 35, global step 1224: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 36, global step 1258: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(37): metric=0.5182 > best_metric=0.5106, log val results..\n",
      "Epoch 37, global step 1292: 'val_Metric' reached 0.51817 (best 0.51817), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=37-val_Metric=0.518.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 38, global step 1326: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 39, global step 1360: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 40, global step 1394: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 41, global step 1428: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 42, global step 1462: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(43): metric=0.5260 > best_metric=0.5182, log val results..\n",
      "Epoch 43, global step 1496: 'val_Metric' reached 0.52595 (best 0.52595), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=43-val_Metric=0.526.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 44, global step 1530: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 45, global step 1564: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 46, global step 1598: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 47, global step 1632: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 48, global step 1666: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 49, global step 1700: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 50, global step 1734: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 51, global step 1768: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 52, global step 1802: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 53, global step 1836: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 54, global step 1870: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 55, global step 1904: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 56, global step 1938: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 57, global step 1972: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 58, global step 2006: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 59, global step 2040: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 60, global step 2074: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 61, global step 2108: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 62, global step 2142: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 63, global step 2176: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 64, global step 2210: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 65, global step 2244: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 66, global step 2278: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 67, global step 2312: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 68, global step 2346: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 69, global step 2380: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 70, global step 2414: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 71, global step 2448: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 72, global step 2482: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 73, global step 2516: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 74, global step 2550: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 75, global step 2584: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 76, global step 2618: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 77, global step 2652: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 78, global step 2686: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 79, global step 2720: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 80, global step 2754: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 81, global step 2788: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 82, global step 2822: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 83, global step 2856: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 84, global step 2890: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 85, global step 2924: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 86, global step 2958: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 87, global step 2992: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 88, global step 3026: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 89, global step 3060: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 90, global step 3094: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 91, global step 3128: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 92, global step 3162: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(93): metric=0.5316 > best_metric=0.5260, log val results..\n",
      "Epoch 93, global step 3196: 'val_Metric' reached 0.53155 (best 0.53155), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=93-val_Metric=0.532.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 94, global step 3230: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 95, global step 3264: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 96, global step 3298: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 97, global step 3332: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 98, global step 3366: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 99, global step 3400: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 100, global step 3434: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 101, global step 3468: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 102, global step 3502: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 103, global step 3536: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 104, global step 3570: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 105, global step 3604: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 106, global step 3638: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 107, global step 3672: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 108, global step 3706: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 109, global step 3740: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 110, global step 3774: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 111, global step 3808: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(112): metric=0.5438 > best_metric=0.5316, log val results..\n",
      "Epoch 112, global step 3842: 'val_Metric' reached 0.54380 (best 0.54380), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=112-val_Metric=0.544.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 113, global step 3876: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 114, global step 3910: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 115, global step 3944: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 116, global step 3978: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 117, global step 4012: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 118, global step 4046: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 119, global step 4080: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 120, global step 4114: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 121, global step 4148: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 122, global step 4182: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 123, global step 4216: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 124, global step 4250: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 125, global step 4284: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 126, global step 4318: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 127, global step 4352: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 128, global step 4386: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 129, global step 4420: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 130, global step 4454: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 131, global step 4488: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 132, global step 4522: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 133, global step 4556: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 134, global step 4590: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 135, global step 4624: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 136, global step 4658: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 137, global step 4692: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 138, global step 4726: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 139, global step 4760: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 140, global step 4794: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 141, global step 4828: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 142, global step 4862: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 143, global step 4896: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 144, global step 4930: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 145, global step 4964: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 146, global step 4998: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 147, global step 5032: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 148, global step 5066: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 149, global step 5100: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 150, global step 5134: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 151, global step 5168: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 152, global step 5202: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 153, global step 5236: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 154, global step 5270: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 155, global step 5304: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 156, global step 5338: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 157, global step 5372: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 158, global step 5406: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 159, global step 5440: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 160, global step 5474: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 161, global step 5508: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 162, global step 5542: 'val_Metric' was not in top 1\n",
      "Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=112-val_Metric=0.544.ckpt\n",
      "##################################################best\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=112-val_Metric=0.544.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=112-val_Metric=0.544.ckpt\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m       SSD/val_MulticlassAUROC       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7248406410217285         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/val_MulticlassAccuracy      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6840757727622986         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_MulticlassF1Score      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6840757727622986         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m SSD/val_MulticlassMatthewsCorrCoef  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3508988618850708         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         SSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.5923562049865723         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanAbsoluteError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         54.93253707885742          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m TSD/val_MeanAbsolutePercentageError \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.14876806735992432         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanSquaredError       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          4666.01025390625          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           TSD/val_R2Score           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3648926615715027         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         TSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5876466035842896         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_acid/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7882652878761292         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7857142686843872         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7857142686843872         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.596284806728363          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_acid/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          1.73932683467865          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_base/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.20000000298023224         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6458333730697632         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6458333730697632         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.1703440248966217         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_base/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.814023494720459          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_boiling/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6857638955116272         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6666666865348816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6666666865348816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/val_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.33806169033050537         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_boiling/val_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.8849246501922607         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5259032249450684         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6424768567085266         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6424768567085266         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/val_MulticlassMatthewsCor\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3068254292011261         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_water/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.3768231868743896         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water4/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.723457932472229          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5525144338607788         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5525144338607788         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/val_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3334923982620239         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water4/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.200005054473877          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m       val_MergedMetric_epoch        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5568108558654785         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m             val_Metric              \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5438021781197253         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           val_loss_epoch            \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.1695568561553955         \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/val_loss : tensor(0.5876)\n",
      "TSD/val_loss_epoch : tensor(0.5876)\n",
      "TSD/val_loss_weight : tensor(2.5558)\n",
      "TSD/val_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/val_R2Score : tensor(0.3649)\n",
      "TSD/val_MeanAbsoluteError : tensor(54.9325)\n",
      "TSD/val_MeanAbsolutePercentageError : tensor(0.1488)\n",
      "TSD/val_MeanSquaredError : tensor(4666.0103)\n",
      "val_loss : tensor(3.1696)\n",
      "val_loss_epoch : tensor(3.1696)\n",
      "val_MergedMetric : tensor(0.5568)\n",
      "val_MergedMetric_epoch : tensor(0.5568)\n",
      "SSD/val_loss : tensor(1.5924)\n",
      "SSD/val_loss_epoch : tensor(1.5924)\n",
      "SSD/val_loss_weight : tensor(1.6995)\n",
      "SSD/val_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/val_MulticlassAccuracy : tensor(0.6841)\n",
      "SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3509)\n",
      "SSD/val_MulticlassF1Score : tensor(0.6841)\n",
      "SSD/val_MulticlassAUROC : tensor(0.7248)\n",
      "WS24_water/val_loss : tensor(2.3768)\n",
      "WS24_water/val_loss_epoch : tensor(2.3768)\n",
      "WS24_water/val_loss_weight : tensor(1.1472)\n",
      "WS24_water/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/val_MulticlassAccuracy : tensor(0.6425)\n",
      "WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.3068)\n",
      "WS24_water/val_MulticlassF1Score : tensor(0.6425)\n",
      "WS24_water/val_MulticlassAUROC : tensor(0.5259)\n",
      "WS24_water4/val_loss : tensor(3.2000)\n",
      "WS24_water4/val_loss_epoch : tensor(3.2000)\n",
      "WS24_water4/val_loss_weight : tensor(1.1472)\n",
      "WS24_water4/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/val_MulticlassAccuracy : tensor(0.5525)\n",
      "WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.3335)\n",
      "WS24_water4/val_MulticlassF1Score : tensor(0.5525)\n",
      "WS24_water4/val_MulticlassAUROC : tensor(0.7235)\n",
      "WS24_acid/val_loss : tensor(1.7393)\n",
      "WS24_acid/val_loss_epoch : tensor(1.7393)\n",
      "WS24_acid/val_loss_weight : tensor(0.1841)\n",
      "WS24_acid/val_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/val_MulticlassAccuracy : tensor(0.7857)\n",
      "WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.5963)\n",
      "WS24_acid/val_MulticlassF1Score : tensor(0.7857)\n",
      "WS24_acid/val_MulticlassAUROC : tensor(0.7883)\n",
      "WS24_base/val_loss : tensor(2.8140)\n",
      "WS24_base/val_loss_epoch : tensor(2.8140)\n",
      "WS24_base/val_loss_weight : tensor(0.1315)\n",
      "WS24_base/val_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/val_MulticlassAccuracy : tensor(0.6458)\n",
      "WS24_base/val_MulticlassMatthewsCorrCoef : tensor(0.1703)\n",
      "WS24_base/val_MulticlassF1Score : tensor(0.6458)\n",
      "WS24_base/val_MulticlassAUROC : tensor(0.2000)\n",
      "WS24_boiling/val_loss : tensor(3.8849)\n",
      "WS24_boiling/val_loss_epoch : tensor(3.8849)\n",
      "WS24_boiling/val_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/val_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/val_MulticlassAccuracy : tensor(0.6667)\n",
      "WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.3381)\n",
      "WS24_boiling/val_MulticlassF1Score : tensor(0.6667)\n",
      "WS24_boiling/val_MulticlassAUROC : tensor(0.6858)\n",
      "val_Metric : tensor(0.5438, dtype=torch.float64)\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=112-val_Metric=0.544.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_25/checkpoints/best-epoch=112-val_Metric=0.544.ckpt\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m            Test metric             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0             \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/test_MulticlassAUROC      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7214937806129456          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    SSD/test_MulticlassAccuracy     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m             0.673828125             \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_MulticlassF1Score     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m             0.673828125             \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mSSD/test_MulticlassMatthewsCorrCoef \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.32265418767929077         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        SSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.3545634746551514          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanAbsoluteError     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         53.479209899902344          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mTSD/test_MeanAbsolutePercentageError\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.15894171595573425         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanSquaredError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          4942.22607421875           \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          TSD/test_R2Score          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3047926425933838          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        TSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6224337816238403          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8981481790542603          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_acid/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8333333134651184          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8333333134651184          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          0.670820415019989          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_acid/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          0.955023467540741          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.40416666865348816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_base/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6136363744735718          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6136363744735718          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.23333333432674408         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_base/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.2944183349609375          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6257396340370178          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassAccuracy\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4615384638309479          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4615384638309479          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassMatthew\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        -0.08671099692583084         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_boiling/test_loss_epoch    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.9039759635925293          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7496822476387024          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6671088933944702          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6671088933944702          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/test_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3322714567184448          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.9779506921768188          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8000646829605103          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5678819417953491          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5678819417953491          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassMatthews\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3050854504108429          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_water4/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.7042500972747803          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m            test_Metric             \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5147867191918998          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          test_loss_epoch           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.7690000534057617          \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/test_loss : tensor(0.6224)\n",
      "TSD/test_loss_epoch : tensor(0.6224)\n",
      "TSD/test_loss_weight : tensor(2.5558)\n",
      "TSD/test_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/test_R2Score : tensor(0.3048)\n",
      "TSD/test_MeanAbsoluteError : tensor(53.4792)\n",
      "TSD/test_MeanAbsolutePercentageError : tensor(0.1589)\n",
      "TSD/test_MeanSquaredError : tensor(4942.2261)\n",
      "test_loss : tensor(2.7690)\n",
      "test_loss_epoch : tensor(2.7690)\n",
      "SSD/test_loss : tensor(1.3546)\n",
      "SSD/test_loss_epoch : tensor(1.3546)\n",
      "SSD/test_loss_weight : tensor(1.6995)\n",
      "SSD/test_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/test_MulticlassAccuracy : tensor(0.6738)\n",
      "SSD/test_MulticlassMatthewsCorrCoef : tensor(0.3227)\n",
      "SSD/test_MulticlassF1Score : tensor(0.6738)\n",
      "SSD/test_MulticlassAUROC : tensor(0.7215)\n",
      "WS24_water/test_loss : tensor(1.9780)\n",
      "WS24_water/test_loss_epoch : tensor(1.9780)\n",
      "WS24_water/test_loss_weight : tensor(1.1472)\n",
      "WS24_water/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/test_MulticlassAccuracy : tensor(0.6671)\n",
      "WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.3323)\n",
      "WS24_water/test_MulticlassF1Score : tensor(0.6671)\n",
      "WS24_water/test_MulticlassAUROC : tensor(0.7497)\n",
      "WS24_water4/test_loss : tensor(2.7043)\n",
      "WS24_water4/test_loss_epoch : tensor(2.7043)\n",
      "WS24_water4/test_loss_weight : tensor(1.1472)\n",
      "WS24_water4/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/test_MulticlassAccuracy : tensor(0.5679)\n",
      "WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3051)\n",
      "WS24_water4/test_MulticlassF1Score : tensor(0.5679)\n",
      "WS24_water4/test_MulticlassAUROC : tensor(0.8001)\n",
      "WS24_acid/test_loss : tensor(0.9550)\n",
      "WS24_acid/test_loss_epoch : tensor(0.9550)\n",
      "WS24_acid/test_loss_weight : tensor(0.1841)\n",
      "WS24_acid/test_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/test_MulticlassAccuracy : tensor(0.8333)\n",
      "WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.6708)\n",
      "WS24_acid/test_MulticlassF1Score : tensor(0.8333)\n",
      "WS24_acid/test_MulticlassAUROC : tensor(0.8981)\n",
      "WS24_base/test_loss : tensor(1.2944)\n",
      "WS24_base/test_loss_epoch : tensor(1.2944)\n",
      "WS24_base/test_loss_weight : tensor(0.1315)\n",
      "WS24_base/test_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/test_MulticlassAccuracy : tensor(0.6136)\n",
      "WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.2333)\n",
      "WS24_base/test_MulticlassF1Score : tensor(0.6136)\n",
      "WS24_base/test_MulticlassAUROC : tensor(0.4042)\n",
      "WS24_boiling/test_loss : tensor(3.9040)\n",
      "WS24_boiling/test_loss_epoch : tensor(3.9040)\n",
      "WS24_boiling/test_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/test_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/test_MulticlassAccuracy : tensor(0.4615)\n",
      "WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(-0.0867)\n",
      "WS24_boiling/test_MulticlassF1Score : tensor(0.4615)\n",
      "WS24_boiling/test_MulticlassAUROC : tensor(0.6257)\n",
      "test_Metric : tensor(0.5148, dtype=torch.float64)\n",
      "[I 2025-12-03 19:07:27,789] Trial 27 finished with value: 0.5098005160622234 and parameters: {'atom_fea_len': 16, 'h_fea_len': 176, 'n_conv': 7, 'n_h': 8, 'lr_mult': 18, 'extra_fea_len': 40, 'dropout': 0.1}. Best is trial 8 with value: 0.5247209443643848.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 12\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 112\n",
      "extra_fea_len : 12\n",
      "h_fea_len : 16\n",
      "n_conv : 8\n",
      "n_h : 10\n",
      "att_S : 64\n",
      "dropout_prob : 0.7000000000000001\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=16, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-6): 7 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=73, out_features=32, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=40, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=56, out_features=176, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-6): 7 x Linear(in_features=176, out_features=176, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-6): 7 x BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-6): 7 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=176, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=176, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=176, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=176, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((176,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=176, out_features=176, bias=True)\n",
      "      (key): Linear(in_features=176, out_features=176, bias=True)\n",
      "      (value): Linear(in_features=176, out_features=176, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef8938cbe0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef8938ceb0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef8938c400>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef8938c910>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef8938cc70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef8938c7f0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef8938c9a0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 503 K  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 16], [128, 16], [128, 16], [128, 16], [128, 16], [128, 16], [128, 16]]]\n",
      "1   | model.embedding_atom            | Linear              | 10.4 K | [2304, 92]                                | [2304, 112]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 224    | [2304, 112]                               | [2304, 112]\n",
      "3   | model.convs                     | ModuleList          | 482 K  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "5   | model.convs.0.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "11  | model.convs.1                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "12  | model.convs.1.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "18  | model.convs.2                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "19  | model.convs.2.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "25  | model.convs.3                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "26  | model.convs.3.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "32  | model.convs.4                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "33  | model.convs.4.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "39  | model.convs.5                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "40  | model.convs.5.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "42  | model.convs.5.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "43  | model.convs.5.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "44  | model.convs.5.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "45  | model.convs.5.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "46  | model.convs.6                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "47  | model.convs.6.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "49  | model.convs.6.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "50  | model.convs.6.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "51  | model.convs.6.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "52  | model.convs.6.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "53  | model.convs.7                   | ConvLayer           | 60.3 K | [[2304, 112], [2304, 10, 41], [2304, 10]] | [2304, 112]\n",
      "54  | model.convs.7.fc_full           | Linear              | 59.6 K | [2304, 10, 265]                           | [2304, 10, 224]\n",
      "55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "56  | model.convs.7.softplus1         | Softplus            | 0      | [2304, 10, 112]                           | [2304, 10, 112]\n",
      "57  | model.convs.7.bn1               | BatchNorm1d         | 448    | [23040, 224]                              | [23040, 224]\n",
      "58  | model.convs.7.bn2               | BatchNorm1d         | 224    | [2304, 112]                               | [2304, 112]\n",
      "59  | model.convs.7.softplus2         | Softplus            | 0      | [2304, 112]                               | [2304, 112]\n",
      "60  | model.embedding_extra           | Linear              | 84     | [128, 6]                                  | [128, 12]\n",
      "61  | model.embedding_extra_norm      | BatchNorm1d         | 24     | [128, 12]                                 | [128, 12]\n",
      "62  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 12]                                 | [128, 12]\n",
      "63  | model.conv_to_fc                | Linear              | 2.0 K  | [128, 124]                                | [128, 16]\n",
      "64  | model.conv_to_fc_norm           | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "65  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "66  | model.dropout                   | Dropout             | 0      | [128, 16]                                 | [128, 16]\n",
      "67  | model.fcs                       | ModuleList          | 2.4 K  | ?                                         | ?\n",
      "68  | model.fcs.0                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "69  | model.fcs.1                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "70  | model.fcs.2                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "71  | model.fcs.3                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "72  | model.fcs.4                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "73  | model.fcs.5                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "74  | model.fcs.6                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "75  | model.fcs.7                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "76  | model.fcs.8                     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "77  | model.norms                     | ModuleList          | 288    | ?                                         | ?\n",
      "78  | model.norms.0                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "79  | model.norms.1                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "80  | model.norms.2                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "81  | model.norms.3                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "82  | model.norms.4                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "83  | model.norms.5                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "84  | model.norms.6                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "85  | model.norms.7                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "86  | model.norms.8                   | BatchNorm1d         | 32     | [128, 16]                                 | [128, 16]\n",
      "87  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "88  | model.softpluses.0              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "89  | model.softpluses.1              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "90  | model.softpluses.2              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "91  | model.softpluses.3              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "92  | model.softpluses.4              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "93  | model.softpluses.5              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "94  | model.softpluses.6              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "95  | model.softpluses.7              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "96  | model.softpluses.8              | Softplus            | 0      | [128, 16]                                 | [128, 16]\n",
      "97  | model.fc_outs                   | ModuleList          | 255    | ?                                         | ?\n",
      "98  | model.fc_outs.0                 | OutputLayer         | 17     | [128, 16]                                 | [128, 1]\n",
      "99  | model.fc_outs.0.fc              | Linear              | 17     | [128, 16]                                 | [128, 1]\n",
      "100 | model.fc_outs.1                 | OutputLayer         | 34     | [128, 16]                                 | [128, 2]\n",
      "101 | model.fc_outs.1.fc              | Sequential          | 34     | [128, 16]                                 | [128, 2]\n",
      "102 | model.fc_outs.1.fc.0            | Linear              | 34     | [128, 16]                                 | [128, 2]\n",
      "103 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "104 | model.fc_outs.2                 | OutputLayer         | 34     | [128, 16]                                 | [128, 2]\n",
      "105 | model.fc_outs.2.fc              | Sequential          | 34     | [128, 16]                                 | [128, 2]\n",
      "106 | model.fc_outs.2.fc.0            | Linear              | 34     | [128, 16]                                 | [128, 2]\n",
      "107 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "108 | model.fc_outs.3                 | OutputLayer         | 68     | [128, 16]                                 | [128, 4]\n",
      "109 | model.fc_outs.3.fc              | Sequential          | 68     | [128, 16]                                 | [128, 4]\n",
      "110 | model.fc_outs.3.fc.0            | Linear              | 68     | [128, 16]                                 | [128, 4]\n",
      "111 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "112 | model.fc_outs.4                 | OutputLayer         | 34     | [128, 16]                                 | [128, 2]\n",
      "113 | model.fc_outs.4.fc              | Sequential          | 34     | [128, 16]                                 | [128, 2]\n",
      "114 | model.fc_outs.4.fc.0            | Linear              | 34     | [128, 16]                                 | [128, 2]\n",
      "115 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "116 | model.fc_outs.5                 | OutputLayer         | 34     | [128, 16]                                 | [128, 2]\n",
      "117 | model.fc_outs.5.fc              | Sequential          | 34     | [128, 16]                                 | [128, 2]\n",
      "118 | model.fc_outs.5.fc.0            | Linear              | 34     | [128, 16]                                 | [128, 2]\n",
      "119 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "120 | model.fc_outs.6                 | OutputLayer         | 34     | [128, 16]                                 | [128, 2]\n",
      "121 | model.fc_outs.6.fc              | Sequential          | 34     | [128, 16]                                 | [128, 2]\n",
      "122 | model.fc_outs.6.fc.0            | Linear              | 34     | [128, 16]                                 | [128, 2]\n",
      "123 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "124 | model.task_norms                | ModuleList          | 224    | ?                                         | ?\n",
      "125 | model.task_norms.0              | LayerNorm           | 32     | [128, 16]                                 | [128, 16]\n",
      "126 | model.task_norms.1              | LayerNorm           | 32     | [128, 16]                                 | [128, 16]\n",
      "127 | model.task_norms.2              | LayerNorm           | 32     | [128, 16]                                 | [128, 16]\n",
      "128 | model.task_norms.3              | LayerNorm           | 32     | [128, 16]                                 | [128, 16]\n",
      "129 | model.task_norms.4              | LayerNorm           | 32     | [128, 16]                                 | [128, 16]\n",
      "130 | model.task_norms.5              | LayerNorm           | 32     | [128, 16]                                 | [128, 16]\n",
      "131 | model.task_norms.6              | LayerNorm           | 32     | [128, 16]                                 | [128, 16]\n",
      "132 | model.task_attentions           | ModuleList          | 5.7 K  | ?                                         | ?\n",
      "133 | model.task_attentions.0         | SelfAttention       | 816    | [128, 16]                                 | [128, 16]\n",
      "134 | model.task_attentions.0.query   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "135 | model.task_attentions.0.key     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "136 | model.task_attentions.0.value   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "137 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "138 | model.task_attentions.1         | SelfAttention       | 816    | [128, 16]                                 | [128, 16]\n",
      "139 | model.task_attentions.1.query   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "140 | model.task_attentions.1.key     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "141 | model.task_attentions.1.value   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "142 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "143 | model.task_attentions.2         | SelfAttention       | 816    | [128, 16]                                 | [128, 16]\n",
      "144 | model.task_attentions.2.query   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "145 | model.task_attentions.2.key     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "146 | model.task_attentions.2.value   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "147 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "148 | model.task_attentions.3         | SelfAttention       | 816    | [128, 16]                                 | [128, 16]\n",
      "149 | model.task_attentions.3.query   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "150 | model.task_attentions.3.key     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "151 | model.task_attentions.3.value   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "152 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "153 | model.task_attentions.4         | SelfAttention       | 816    | [128, 16]                                 | [128, 16]\n",
      "154 | model.task_attentions.4.query   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "155 | model.task_attentions.4.key     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "156 | model.task_attentions.4.value   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "157 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "158 | model.task_attentions.5         | SelfAttention       | 816    | [128, 16]                                 | [128, 16]\n",
      "159 | model.task_attentions.5.query   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "160 | model.task_attentions.5.key     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "161 | model.task_attentions.5.value   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "162 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "163 | model.task_attentions.6         | SelfAttention       | 816    | [128, 16]                                 | [128, 16]\n",
      "164 | model.task_attentions.6.query   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "165 | model.task_attentions.6.key     | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "166 | model.task_attentions.6.value   | Linear              | 272    | [128, 16]                                 | [128, 16]\n",
      "167 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "503 K     Trainable params\n",
      "0         Non-trainable params\n",
      "503 K     Total params\n",
      "2.015     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight', 'fcs.7.weight', 'fcs.8.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'fcs.7.bias', 'fcs.8.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'norms.7.weight', 'norms.7.bias', 'norms.8.weight', 'norms.8.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 12 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 503 K  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 16], [128, 16], [128, 16], [128, 16], [128, 16], [128, 16], [128, 16]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "503 K     Trainable params\n",
      "0         Non-trainable params\n",
      "503 K     Total params\n",
      "2.015     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "current_epoch(0): metric=0.0016 > best_metric=0.0000, log val results..\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(0): metric=0.2945 > best_metric=0.0016, log val results..\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "Epoch 0, global step 34: 'val_Metric' reached 0.29449 (best 0.29449), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=00-val_Metric=0.294.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(1): metric=0.3053 > best_metric=0.2945, log val results..\n",
      "Epoch 1, global step 68: 'val_Metric' reached 0.30528 (best 0.30528), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=01-val_Metric=0.305.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(2): metric=0.3518 > best_metric=0.3053, log val results..\n",
      "Epoch 2, global step 102: 'val_Metric' reached 0.35178 (best 0.35178), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=02-val_Metric=0.352.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 3, global step 136: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(4): metric=0.3793 > best_metric=0.3518, log val results..\n",
      "Epoch 4, global step 170: 'val_Metric' reached 0.37930 (best 0.37930), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=04-val_Metric=0.379.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(5): metric=0.3934 > best_metric=0.3793, log val results..\n",
      "Epoch 5, global step 204: 'val_Metric' reached 0.39344 (best 0.39344), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=05-val_Metric=0.393.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(6): metric=0.4000 > best_metric=0.3934, log val results..\n",
      "Epoch 6, global step 238: 'val_Metric' reached 0.40002 (best 0.40002), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=06-val_Metric=0.400.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 7, global step 272: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(8): metric=0.4058 > best_metric=0.4000, log val results..\n",
      "Epoch 8, global step 306: 'val_Metric' reached 0.40583 (best 0.40583), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=08-val_Metric=0.406.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 9, global step 340: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(10): metric=0.4148 > best_metric=0.4058, log val results..\n",
      "Epoch 10, global step 374: 'val_Metric' reached 0.41482 (best 0.41482), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=10-val_Metric=0.415.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(11): metric=0.4175 > best_metric=0.4148, log val results..\n",
      "Epoch 11, global step 408: 'val_Metric' reached 0.41746 (best 0.41746), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=11-val_Metric=0.417.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(12): metric=0.4191 > best_metric=0.4175, log val results..\n",
      "Epoch 12, global step 442: 'val_Metric' reached 0.41912 (best 0.41912), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=12-val_Metric=0.419.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(13): metric=0.4322 > best_metric=0.4191, log val results..\n",
      "Epoch 13, global step 476: 'val_Metric' reached 0.43218 (best 0.43218), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=13-val_Metric=0.432.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 14, global step 510: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 15, global step 544: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 16, global step 578: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(17): metric=0.4408 > best_metric=0.4322, log val results..\n",
      "Epoch 17, global step 612: 'val_Metric' reached 0.44085 (best 0.44085), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=17-val_Metric=0.441.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 18, global step 646: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 19, global step 680: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 20, global step 714: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(21): metric=0.4602 > best_metric=0.4408, log val results..\n",
      "Epoch 21, global step 748: 'val_Metric' reached 0.46023 (best 0.46023), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=21-val_Metric=0.460.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 22, global step 782: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 23, global step 816: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 24, global step 850: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 25, global step 884: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 26, global step 918: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 27, global step 952: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(28): metric=0.4826 > best_metric=0.4602, log val results..\n",
      "Epoch 28, global step 986: 'val_Metric' reached 0.48263 (best 0.48263), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=28-val_Metric=0.483.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 29, global step 1020: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 30, global step 1054: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 31, global step 1088: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 32, global step 1122: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 33, global step 1156: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 34, global step 1190: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 35, global step 1224: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(36): metric=0.4956 > best_metric=0.4826, log val results..\n",
      "Epoch 36, global step 1258: 'val_Metric' reached 0.49564 (best 0.49564), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=36-val_Metric=0.496.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 37, global step 1292: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 38, global step 1326: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 39, global step 1360: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 40, global step 1394: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 41, global step 1428: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(42): metric=0.5093 > best_metric=0.4956, log val results..\n",
      "Epoch 42, global step 1462: 'val_Metric' reached 0.50928 (best 0.50928), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=42-val_Metric=0.509.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 43, global step 1496: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 44, global step 1530: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 45, global step 1564: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 46, global step 1598: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 47, global step 1632: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 48, global step 1666: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 49, global step 1700: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 50, global step 1734: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(51): metric=0.5129 > best_metric=0.5093, log val results..\n",
      "Epoch 51, global step 1768: 'val_Metric' reached 0.51294 (best 0.51294), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=51-val_Metric=0.513.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(52): metric=0.5186 > best_metric=0.5129, log val results..\n",
      "Epoch 52, global step 1802: 'val_Metric' reached 0.51864 (best 0.51864), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=52-val_Metric=0.519.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 53, global step 1836: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 54, global step 1870: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 55, global step 1904: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 56, global step 1938: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 57, global step 1972: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 58, global step 2006: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 59, global step 2040: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 60, global step 2074: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 61, global step 2108: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 62, global step 2142: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 63, global step 2176: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 64, global step 2210: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 65, global step 2244: 'val_Metric' reached 0.51944 (best 0.51944), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=65-val_Metric=0.519.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(66): metric=0.5327 > best_metric=0.5186, log val results..\n",
      "Epoch 66, global step 2278: 'val_Metric' reached 0.53273 (best 0.53273), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=66-val_Metric=0.533.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 67, global step 2312: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 68, global step 2346: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 69, global step 2380: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 70, global step 2414: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 71, global step 2448: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 72, global step 2482: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(73): metric=0.5428 > best_metric=0.5327, log val results..\n",
      "Epoch 73, global step 2516: 'val_Metric' reached 0.54284 (best 0.54284), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=73-val_Metric=0.543.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 74, global step 2550: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 75, global step 2584: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 76, global step 2618: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 77, global step 2652: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 78, global step 2686: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 79, global step 2720: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 80, global step 2754: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 81, global step 2788: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 82, global step 2822: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 83, global step 2856: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 84, global step 2890: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 85, global step 2924: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 86, global step 2958: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 87, global step 2992: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 88, global step 3026: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 89, global step 3060: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 90, global step 3094: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 91, global step 3128: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 92, global step 3162: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 93, global step 3196: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 94, global step 3230: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 95, global step 3264: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 96, global step 3298: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 97, global step 3332: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 98, global step 3366: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 99, global step 3400: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 100, global step 3434: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 101, global step 3468: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 102, global step 3502: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 103, global step 3536: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 104, global step 3570: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 105, global step 3604: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 106, global step 3638: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 107, global step 3672: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 108, global step 3706: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 109, global step 3740: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 110, global step 3774: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 111, global step 3808: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 112, global step 3842: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 113, global step 3876: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 114, global step 3910: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 115, global step 3944: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 116, global step 3978: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 117, global step 4012: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 118, global step 4046: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 119, global step 4080: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 120, global step 4114: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 121, global step 4148: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 122, global step 4182: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 123, global step 4216: 'val_Metric' was not in top 1\n",
      "Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=73-val_Metric=0.543.ckpt\n",
      "##################################################best\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=73-val_Metric=0.543.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=73-val_Metric=0.543.ckpt\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m       SSD/val_MulticlassAUROC       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7737341523170471         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/val_MulticlassAccuracy      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7360471487045288         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_MulticlassF1Score      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7360471487045288         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m SSD/val_MulticlassMatthewsCorrCoef  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.45504945516586304         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         SSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5639814138412476         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanAbsoluteError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         56.117244720458984         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m TSD/val_MeanAbsolutePercentageError \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.15267038345336914         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanSquaredError       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          5121.04541015625          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           TSD/val_R2Score           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.2859581708908081         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         TSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6449546813964844         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_acid/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8316326141357422         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8214285969734192         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8214285969734192         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6581451892852783         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_acid/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5554771423339844         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_base/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.15000000596046448         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7291666269302368         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7291666269302368         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.27179235219955444         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_base/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.3044216632843018         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_boiling/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5763888955116272         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                0.5                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                0.5                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/val_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                0.0                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_boiling/val_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1311553716659546         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5390639901161194         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8221643567085266         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8221643567085266         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/val_MulticlassMatthewsCor\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6305707097053528         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_water/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6668354868888855         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water4/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6916688680648804         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.598349928855896          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.598349928855896          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/val_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.2929965853691101         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water4/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.411559820175171          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m       val_MergedMetric_epoch        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5836530327796936         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m             val_Metric              \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5428423992044816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           val_loss_epoch            \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6268683671951294         \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/val_loss : tensor(0.6450)\n",
      "TSD/val_loss_epoch : tensor(0.6450)\n",
      "TSD/val_loss_weight : tensor(2.5558)\n",
      "TSD/val_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/val_R2Score : tensor(0.2860)\n",
      "TSD/val_MeanAbsoluteError : tensor(56.1172)\n",
      "TSD/val_MeanAbsolutePercentageError : tensor(0.1527)\n",
      "TSD/val_MeanSquaredError : tensor(5121.0454)\n",
      "val_loss : tensor(1.6269)\n",
      "val_loss_epoch : tensor(1.6269)\n",
      "val_MergedMetric : tensor(0.5837)\n",
      "val_MergedMetric_epoch : tensor(0.5837)\n",
      "SSD/val_loss : tensor(0.5640)\n",
      "SSD/val_loss_epoch : tensor(0.5640)\n",
      "SSD/val_loss_weight : tensor(1.6995)\n",
      "SSD/val_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/val_MulticlassAccuracy : tensor(0.7360)\n",
      "SSD/val_MulticlassMatthewsCorrCoef : tensor(0.4550)\n",
      "SSD/val_MulticlassF1Score : tensor(0.7360)\n",
      "SSD/val_MulticlassAUROC : tensor(0.7737)\n",
      "WS24_water/val_loss : tensor(0.6668)\n",
      "WS24_water/val_loss_epoch : tensor(0.6668)\n",
      "WS24_water/val_loss_weight : tensor(1.1472)\n",
      "WS24_water/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/val_MulticlassAccuracy : tensor(0.8222)\n",
      "WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.6306)\n",
      "WS24_water/val_MulticlassF1Score : tensor(0.8222)\n",
      "WS24_water/val_MulticlassAUROC : tensor(0.5391)\n",
      "WS24_water4/val_loss : tensor(1.4116)\n",
      "WS24_water4/val_loss_epoch : tensor(1.4116)\n",
      "WS24_water4/val_loss_weight : tensor(1.1472)\n",
      "WS24_water4/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/val_MulticlassAccuracy : tensor(0.5983)\n",
      "WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.2930)\n",
      "WS24_water4/val_MulticlassF1Score : tensor(0.5983)\n",
      "WS24_water4/val_MulticlassAUROC : tensor(0.6917)\n",
      "WS24_acid/val_loss : tensor(0.5555)\n",
      "WS24_acid/val_loss_epoch : tensor(0.5555)\n",
      "WS24_acid/val_loss_weight : tensor(0.1841)\n",
      "WS24_acid/val_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/val_MulticlassAccuracy : tensor(0.8214)\n",
      "WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.6581)\n",
      "WS24_acid/val_MulticlassF1Score : tensor(0.8214)\n",
      "WS24_acid/val_MulticlassAUROC : tensor(0.8316)\n",
      "WS24_base/val_loss : tensor(1.3044)\n",
      "WS24_base/val_loss_epoch : tensor(1.3044)\n",
      "WS24_base/val_loss_weight : tensor(0.1315)\n",
      "WS24_base/val_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/val_MulticlassAccuracy : tensor(0.7292)\n",
      "WS24_base/val_MulticlassMatthewsCorrCoef : tensor(0.2718)\n",
      "WS24_base/val_MulticlassF1Score : tensor(0.7292)\n",
      "WS24_base/val_MulticlassAUROC : tensor(0.1500)\n",
      "WS24_boiling/val_loss : tensor(1.1312)\n",
      "WS24_boiling/val_loss_epoch : tensor(1.1312)\n",
      "WS24_boiling/val_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/val_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/val_MulticlassAccuracy : tensor(0.5000)\n",
      "WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.)\n",
      "WS24_boiling/val_MulticlassF1Score : tensor(0.5000)\n",
      "WS24_boiling/val_MulticlassAUROC : tensor(0.5764)\n",
      "val_Metric : tensor(0.5428, dtype=torch.float64)\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=73-val_Metric=0.543.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_26/checkpoints/best-epoch=73-val_Metric=0.543.ckpt\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m            Test metric             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0             \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/test_MulticlassAUROC      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6420247554779053          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    SSD/test_MulticlassAccuracy     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6853298544883728          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_MulticlassF1Score     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6853298544883728          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mSSD/test_MulticlassMatthewsCorrCoef \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.2486495077610016          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        SSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6481069326400757          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanAbsoluteError     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          49.91291809082031          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mTSD/test_MeanAbsolutePercentageError\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.15441326797008514         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanSquaredError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          4457.84814453125           \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          TSD/test_R2Score          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3722502589225769          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        TSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5614302158355713          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8456790447235107          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_acid/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8055555820465088          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8055555820465088          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6361464262008667          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_acid/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5638507008552551          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3916666507720947          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_base/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6136363744735718          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6136363744735718          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.2501487731933594          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_base/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.1705400943756104          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5917159914970398          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassAccuracy\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                 0.5                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                 0.5                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassMatthew\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                 0.0                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_boiling/test_loss_epoch    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          0.786953330039978          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8394153118133545          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7756333351135254          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7756333351135254          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/test_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5194845795631409          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7171429395675659          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7624852657318115          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6575521230697632          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6575521230697632          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassMatthews\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.37832149863243103         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_water4/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8413712978363037          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m            test_Metric             \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5184663141897093          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          test_loss_epoch           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.4060956239700317          \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/test_loss : tensor(0.5614)\n",
      "TSD/test_loss_epoch : tensor(0.5614)\n",
      "TSD/test_loss_weight : tensor(2.5558)\n",
      "TSD/test_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/test_R2Score : tensor(0.3723)\n",
      "TSD/test_MeanAbsoluteError : tensor(49.9129)\n",
      "TSD/test_MeanAbsolutePercentageError : tensor(0.1544)\n",
      "TSD/test_MeanSquaredError : tensor(4457.8481)\n",
      "test_loss : tensor(1.4061)\n",
      "test_loss_epoch : tensor(1.4061)\n",
      "SSD/test_loss : tensor(0.6481)\n",
      "SSD/test_loss_epoch : tensor(0.6481)\n",
      "SSD/test_loss_weight : tensor(1.6995)\n",
      "SSD/test_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/test_MulticlassAccuracy : tensor(0.6853)\n",
      "SSD/test_MulticlassMatthewsCorrCoef : tensor(0.2486)\n",
      "SSD/test_MulticlassF1Score : tensor(0.6853)\n",
      "SSD/test_MulticlassAUROC : tensor(0.6420)\n",
      "WS24_water/test_loss : tensor(0.7171)\n",
      "WS24_water/test_loss_epoch : tensor(0.7171)\n",
      "WS24_water/test_loss_weight : tensor(1.1472)\n",
      "WS24_water/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/test_MulticlassAccuracy : tensor(0.7756)\n",
      "WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.5195)\n",
      "WS24_water/test_MulticlassF1Score : tensor(0.7756)\n",
      "WS24_water/test_MulticlassAUROC : tensor(0.8394)\n",
      "WS24_water4/test_loss : tensor(0.8414)\n",
      "WS24_water4/test_loss_epoch : tensor(0.8414)\n",
      "WS24_water4/test_loss_weight : tensor(1.1472)\n",
      "WS24_water4/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/test_MulticlassAccuracy : tensor(0.6576)\n",
      "WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3783)\n",
      "WS24_water4/test_MulticlassF1Score : tensor(0.6576)\n",
      "WS24_water4/test_MulticlassAUROC : tensor(0.7625)\n",
      "WS24_acid/test_loss : tensor(0.5639)\n",
      "WS24_acid/test_loss_epoch : tensor(0.5639)\n",
      "WS24_acid/test_loss_weight : tensor(0.1841)\n",
      "WS24_acid/test_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/test_MulticlassAccuracy : tensor(0.8056)\n",
      "WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.6361)\n",
      "WS24_acid/test_MulticlassF1Score : tensor(0.8056)\n",
      "WS24_acid/test_MulticlassAUROC : tensor(0.8457)\n",
      "WS24_base/test_loss : tensor(2.1705)\n",
      "WS24_base/test_loss_epoch : tensor(2.1705)\n",
      "WS24_base/test_loss_weight : tensor(0.1315)\n",
      "WS24_base/test_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/test_MulticlassAccuracy : tensor(0.6136)\n",
      "WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.2501)\n",
      "WS24_base/test_MulticlassF1Score : tensor(0.6136)\n",
      "WS24_base/test_MulticlassAUROC : tensor(0.3917)\n",
      "WS24_boiling/test_loss : tensor(0.7870)\n",
      "WS24_boiling/test_loss_epoch : tensor(0.7870)\n",
      "WS24_boiling/test_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/test_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/test_MulticlassAccuracy : tensor(0.5000)\n",
      "WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.)\n",
      "WS24_boiling/test_MulticlassF1Score : tensor(0.5000)\n",
      "WS24_boiling/test_MulticlassAUROC : tensor(0.5917)\n",
      "test_Metric : tensor(0.5185, dtype=torch.float64)\n",
      "[I 2025-12-03 19:58:51,317] Trial 28 finished with value: 0.5228006968293444 and parameters: {'atom_fea_len': 112, 'h_fea_len': 16, 'n_conv': 8, 'n_h': 10, 'lr_mult': 12, 'extra_fea_len': 12, 'dropout': 0.7000000000000001}. Best is trial 8 with value: 0.5247209443643848.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 10\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 176\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 80\n",
      "n_conv : 8\n",
      "n_h : 10\n",
      "att_S : 64\n",
      "dropout_prob : 0.75\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=112, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((112,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-7): 8 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=265, out_features=224, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=12, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=124, out_features=16, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.7000000000000001, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-8): 9 x Linear(in_features=16, out_features=16, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-8): 9 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-8): 9 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (key): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (value): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e36a760>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e36ad00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef673f6f70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef673f6a60>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef673f6be0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef673f62e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef673f6040>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.4 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80]]]\n",
      "1   | model.embedding_atom            | Linear              | 16.4 K | [2304, 92]                                | [2304, 176]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 352    | [2304, 176]                               | [2304, 176]\n",
      "3   | model.convs                     | ModuleList          | 1.1 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "5   | model.convs.0.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "11  | model.convs.1                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "12  | model.convs.1.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "18  | model.convs.2                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "19  | model.convs.2.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "25  | model.convs.3                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "26  | model.convs.3.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "32  | model.convs.4                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "33  | model.convs.4.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "39  | model.convs.5                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "40  | model.convs.5.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "42  | model.convs.5.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "43  | model.convs.5.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "44  | model.convs.5.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "45  | model.convs.5.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "46  | model.convs.6                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "47  | model.convs.6.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "49  | model.convs.6.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "50  | model.convs.6.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "51  | model.convs.6.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "52  | model.convs.6.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "53  | model.convs.7                   | ConvLayer           | 139 K  | [[2304, 176], [2304, 10, 41], [2304, 10]] | [2304, 176]\n",
      "54  | model.convs.7.fc_full           | Linear              | 138 K  | [2304, 10, 393]                           | [2304, 10, 352]\n",
      "55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "56  | model.convs.7.softplus1         | Softplus            | 0      | [2304, 10, 176]                           | [2304, 10, 176]\n",
      "57  | model.convs.7.bn1               | BatchNorm1d         | 704    | [23040, 352]                              | [23040, 352]\n",
      "58  | model.convs.7.bn2               | BatchNorm1d         | 352    | [2304, 176]                               | [2304, 176]\n",
      "59  | model.convs.7.softplus2         | Softplus            | 0      | [2304, 176]                               | [2304, 176]\n",
      "60  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "61  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "62  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "63  | model.conv_to_fc                | Linear              | 18.6 K | [128, 232]                                | [128, 80]\n",
      "64  | model.conv_to_fc_norm           | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "65  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "66  | model.dropout                   | Dropout             | 0      | [128, 80]                                 | [128, 80]\n",
      "67  | model.fcs                       | ModuleList          | 58.3 K | ?                                         | ?\n",
      "68  | model.fcs.0                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "69  | model.fcs.1                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "70  | model.fcs.2                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "71  | model.fcs.3                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "72  | model.fcs.4                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "73  | model.fcs.5                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "74  | model.fcs.6                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "75  | model.fcs.7                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "76  | model.fcs.8                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "77  | model.norms                     | ModuleList          | 1.4 K  | ?                                         | ?\n",
      "78  | model.norms.0                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "79  | model.norms.1                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "80  | model.norms.2                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "81  | model.norms.3                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "82  | model.norms.4                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "83  | model.norms.5                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "84  | model.norms.6                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "85  | model.norms.7                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "86  | model.norms.8                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "87  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "88  | model.softpluses.0              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "89  | model.softpluses.1              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "90  | model.softpluses.2              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "91  | model.softpluses.3              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "92  | model.softpluses.4              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "93  | model.softpluses.5              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "94  | model.softpluses.6              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "95  | model.softpluses.7              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "96  | model.softpluses.8              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "97  | model.fc_outs                   | ModuleList          | 1.2 K  | ?                                         | ?\n",
      "98  | model.fc_outs.0                 | OutputLayer         | 81     | [128, 80]                                 | [128, 1]\n",
      "99  | model.fc_outs.0.fc              | Linear              | 81     | [128, 80]                                 | [128, 1]\n",
      "100 | model.fc_outs.1                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "101 | model.fc_outs.1.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "102 | model.fc_outs.1.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "103 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "104 | model.fc_outs.2                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "105 | model.fc_outs.2.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "106 | model.fc_outs.2.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "107 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "108 | model.fc_outs.3                 | OutputLayer         | 324    | [128, 80]                                 | [128, 4]\n",
      "109 | model.fc_outs.3.fc              | Sequential          | 324    | [128, 80]                                 | [128, 4]\n",
      "110 | model.fc_outs.3.fc.0            | Linear              | 324    | [128, 80]                                 | [128, 4]\n",
      "111 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "112 | model.fc_outs.4                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "113 | model.fc_outs.4.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "114 | model.fc_outs.4.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "115 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "116 | model.fc_outs.5                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "117 | model.fc_outs.5.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "118 | model.fc_outs.5.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "119 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "120 | model.fc_outs.6                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "121 | model.fc_outs.6.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "122 | model.fc_outs.6.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "123 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "124 | model.task_norms                | ModuleList          | 1.1 K  | ?                                         | ?\n",
      "125 | model.task_norms.0              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "126 | model.task_norms.1              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "127 | model.task_norms.2              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "128 | model.task_norms.3              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "129 | model.task_norms.4              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "130 | model.task_norms.5              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "131 | model.task_norms.6              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "132 | model.task_attentions           | ModuleList          | 136 K  | ?                                         | ?\n",
      "133 | model.task_attentions.0         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "134 | model.task_attentions.0.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "135 | model.task_attentions.0.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "136 | model.task_attentions.0.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "137 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "138 | model.task_attentions.1         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "139 | model.task_attentions.1.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "140 | model.task_attentions.1.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "141 | model.task_attentions.1.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "142 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "143 | model.task_attentions.2         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "144 | model.task_attentions.2.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "145 | model.task_attentions.2.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "146 | model.task_attentions.2.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "147 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "148 | model.task_attentions.3         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "149 | model.task_attentions.3.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "150 | model.task_attentions.3.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "151 | model.task_attentions.3.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "152 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "153 | model.task_attentions.4         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "154 | model.task_attentions.4.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "155 | model.task_attentions.4.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "156 | model.task_attentions.4.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "157 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "158 | model.task_attentions.5         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "159 | model.task_attentions.5.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "160 | model.task_attentions.5.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "161 | model.task_attentions.5.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "162 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "163 | model.task_attentions.6         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "164 | model.task_attentions.6.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "165 | model.task_attentions.6.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "166 | model.task_attentions.6.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "167 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.409     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_27\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight', 'fcs.7.weight', 'fcs.8.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'fcs.7.bias', 'fcs.8.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'norms.7.weight', 'norms.7.bias', 'norms.8.weight', 'norms.8.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 10 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.4 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.409     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 19:59:01,135] Trial 29 failed with parameters: {'atom_fea_len': 176, 'h_fea_len': 80, 'n_conv': 8, 'n_h': 10, 'lr_mult': 10, 'extra_fea_len': 56, 'dropout': 0.75} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 688.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 364.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.47 GiB memory in use. Of the allocated memory 21.12 GiB is allocated by PyTorch, and 123.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 90, in forward\n",
      "    total_gated_fea = self.fc_full(total_nbr_fea)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 688.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 364.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.47 GiB memory in use. Of the allocated memory 21.12 GiB is allocated by PyTorch, and 123.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 19:59:01,139] Trial 29 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 11\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 208\n",
      "extra_fea_len : 36\n",
      "h_fea_len : 224\n",
      "n_conv : 8\n",
      "n_h : 9\n",
      "att_S : 64\n",
      "dropout_prob : 0.75\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=176, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-7): 8 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=393, out_features=352, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=232, out_features=80, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.75, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-8): 9 x Linear(in_features=80, out_features=80, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-8): 9 x BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-8): 9 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=80, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=80, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=80, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=80, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=80, out_features=80, bias=True)\n",
      "      (key): Linear(in_features=80, out_features=80, bias=True)\n",
      "      (value): Linear(in_features=80, out_features=80, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef857baca0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef857bae80>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef857bad30>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef857ba5b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef857ba6a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef857bab50>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef857badc0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 3.1 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 224], [128, 224], [128, 224], [128, 224], [128, 224], [128, 224], [128, 224]]]\n",
      "1   | model.embedding_atom            | Linear              | 19.3 K | [2304, 92]                                | [2304, 208]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 416    | [2304, 208]                               | [2304, 208]\n",
      "3   | model.convs                     | ModuleList          | 1.5 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "5   | model.convs.0.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "11  | model.convs.1                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "12  | model.convs.1.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "18  | model.convs.2                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "19  | model.convs.2.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "25  | model.convs.3                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "26  | model.convs.3.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "32  | model.convs.4                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "33  | model.convs.4.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "39  | model.convs.5                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "40  | model.convs.5.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "42  | model.convs.5.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "43  | model.convs.5.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "44  | model.convs.5.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "45  | model.convs.5.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "46  | model.convs.6                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "47  | model.convs.6.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "49  | model.convs.6.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "50  | model.convs.6.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "51  | model.convs.6.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "52  | model.convs.6.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "53  | model.convs.7                   | ConvLayer           | 191 K  | [[2304, 208], [2304, 10, 41], [2304, 10]] | [2304, 208]\n",
      "54  | model.convs.7.fc_full           | Linear              | 190 K  | [2304, 10, 457]                           | [2304, 10, 416]\n",
      "55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "56  | model.convs.7.softplus1         | Softplus            | 0      | [2304, 10, 208]                           | [2304, 10, 208]\n",
      "57  | model.convs.7.bn1               | BatchNorm1d         | 832    | [23040, 416]                              | [23040, 416]\n",
      "58  | model.convs.7.bn2               | BatchNorm1d         | 416    | [2304, 208]                               | [2304, 208]\n",
      "59  | model.convs.7.softplus2         | Softplus            | 0      | [2304, 208]                               | [2304, 208]\n",
      "60  | model.embedding_extra           | Linear              | 252    | [128, 6]                                  | [128, 36]\n",
      "61  | model.embedding_extra_norm      | BatchNorm1d         | 72     | [128, 36]                                 | [128, 36]\n",
      "62  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 36]                                 | [128, 36]\n",
      "63  | model.conv_to_fc                | Linear              | 54.9 K | [128, 244]                                | [128, 224]\n",
      "64  | model.conv_to_fc_norm           | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "65  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "66  | model.dropout                   | Dropout             | 0      | [128, 224]                                | [128, 224]\n",
      "67  | model.fcs                       | ModuleList          | 403 K  | ?                                         | ?\n",
      "68  | model.fcs.0                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "69  | model.fcs.1                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "70  | model.fcs.2                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "71  | model.fcs.3                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "72  | model.fcs.4                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "73  | model.fcs.5                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "74  | model.fcs.6                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "75  | model.fcs.7                     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "76  | model.norms                     | ModuleList          | 3.6 K  | ?                                         | ?\n",
      "77  | model.norms.0                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "78  | model.norms.1                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "79  | model.norms.2                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "80  | model.norms.3                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "81  | model.norms.4                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "82  | model.norms.5                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "83  | model.norms.6                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "84  | model.norms.7                   | BatchNorm1d         | 448    | [128, 224]                                | [128, 224]\n",
      "85  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "86  | model.softpluses.0              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "87  | model.softpluses.1              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "88  | model.softpluses.2              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "89  | model.softpluses.3              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "90  | model.softpluses.4              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "91  | model.softpluses.5              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "92  | model.softpluses.6              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "93  | model.softpluses.7              | Softplus            | 0      | [128, 224]                                | [128, 224]\n",
      "94  | model.fc_outs                   | ModuleList          | 3.4 K  | ?                                         | ?\n",
      "95  | model.fc_outs.0                 | OutputLayer         | 225    | [128, 224]                                | [128, 1]\n",
      "96  | model.fc_outs.0.fc              | Linear              | 225    | [128, 224]                                | [128, 1]\n",
      "97  | model.fc_outs.1                 | OutputLayer         | 450    | [128, 224]                                | [128, 2]\n",
      "98  | model.fc_outs.1.fc              | Sequential          | 450    | [128, 224]                                | [128, 2]\n",
      "99  | model.fc_outs.1.fc.0            | Linear              | 450    | [128, 224]                                | [128, 2]\n",
      "100 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "101 | model.fc_outs.2                 | OutputLayer         | 450    | [128, 224]                                | [128, 2]\n",
      "102 | model.fc_outs.2.fc              | Sequential          | 450    | [128, 224]                                | [128, 2]\n",
      "103 | model.fc_outs.2.fc.0            | Linear              | 450    | [128, 224]                                | [128, 2]\n",
      "104 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "105 | model.fc_outs.3                 | OutputLayer         | 900    | [128, 224]                                | [128, 4]\n",
      "106 | model.fc_outs.3.fc              | Sequential          | 900    | [128, 224]                                | [128, 4]\n",
      "107 | model.fc_outs.3.fc.0            | Linear              | 900    | [128, 224]                                | [128, 4]\n",
      "108 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "109 | model.fc_outs.4                 | OutputLayer         | 450    | [128, 224]                                | [128, 2]\n",
      "110 | model.fc_outs.4.fc              | Sequential          | 450    | [128, 224]                                | [128, 2]\n",
      "111 | model.fc_outs.4.fc.0            | Linear              | 450    | [128, 224]                                | [128, 2]\n",
      "112 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "113 | model.fc_outs.5                 | OutputLayer         | 450    | [128, 224]                                | [128, 2]\n",
      "114 | model.fc_outs.5.fc              | Sequential          | 450    | [128, 224]                                | [128, 2]\n",
      "115 | model.fc_outs.5.fc.0            | Linear              | 450    | [128, 224]                                | [128, 2]\n",
      "116 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "117 | model.fc_outs.6                 | OutputLayer         | 450    | [128, 224]                                | [128, 2]\n",
      "118 | model.fc_outs.6.fc              | Sequential          | 450    | [128, 224]                                | [128, 2]\n",
      "119 | model.fc_outs.6.fc.0            | Linear              | 450    | [128, 224]                                | [128, 2]\n",
      "120 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "121 | model.task_norms                | ModuleList          | 3.1 K  | ?                                         | ?\n",
      "122 | model.task_norms.0              | LayerNorm           | 448    | [128, 224]                                | [128, 224]\n",
      "123 | model.task_norms.1              | LayerNorm           | 448    | [128, 224]                                | [128, 224]\n",
      "124 | model.task_norms.2              | LayerNorm           | 448    | [128, 224]                                | [128, 224]\n",
      "125 | model.task_norms.3              | LayerNorm           | 448    | [128, 224]                                | [128, 224]\n",
      "126 | model.task_norms.4              | LayerNorm           | 448    | [128, 224]                                | [128, 224]\n",
      "127 | model.task_norms.5              | LayerNorm           | 448    | [128, 224]                                | [128, 224]\n",
      "128 | model.task_norms.6              | LayerNorm           | 448    | [128, 224]                                | [128, 224]\n",
      "129 | model.task_attentions           | ModuleList          | 1.1 M  | ?                                         | ?\n",
      "130 | model.task_attentions.0         | SelfAttention       | 151 K  | [128, 224]                                | [128, 224]\n",
      "131 | model.task_attentions.0.query   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "132 | model.task_attentions.0.key     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "133 | model.task_attentions.0.value   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "134 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "135 | model.task_attentions.1         | SelfAttention       | 151 K  | [128, 224]                                | [128, 224]\n",
      "136 | model.task_attentions.1.query   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "137 | model.task_attentions.1.key     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "138 | model.task_attentions.1.value   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "139 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "140 | model.task_attentions.2         | SelfAttention       | 151 K  | [128, 224]                                | [128, 224]\n",
      "141 | model.task_attentions.2.query   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "142 | model.task_attentions.2.key     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "143 | model.task_attentions.2.value   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "144 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "145 | model.task_attentions.3         | SelfAttention       | 151 K  | [128, 224]                                | [128, 224]\n",
      "146 | model.task_attentions.3.query   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "147 | model.task_attentions.3.key     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "148 | model.task_attentions.3.value   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "149 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "150 | model.task_attentions.4         | SelfAttention       | 151 K  | [128, 224]                                | [128, 224]\n",
      "151 | model.task_attentions.4.query   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "152 | model.task_attentions.4.key     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "153 | model.task_attentions.4.value   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "154 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "155 | model.task_attentions.5         | SelfAttention       | 151 K  | [128, 224]                                | [128, 224]\n",
      "156 | model.task_attentions.5.query   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "157 | model.task_attentions.5.key     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "158 | model.task_attentions.5.value   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "159 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "160 | model.task_attentions.6         | SelfAttention       | 151 K  | [128, 224]                                | [128, 224]\n",
      "161 | model.task_attentions.6.query   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "162 | model.task_attentions.6.key     | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "163 | model.task_attentions.6.value   | Linear              | 50.4 K | [128, 224]                                | [128, 224]\n",
      "164 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.325    Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_28\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight', 'fcs.7.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'fcs.7.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'norms.7.weight', 'norms.7.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 11 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 3.1 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 224], [128, 224], [128, 224], [128, 224], [128, 224], [128, 224], [128, 224]]]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.325    Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 19:59:12,538] Trial 30 failed with parameters: {'atom_fea_len': 208, 'h_fea_len': 224, 'n_conv': 8, 'n_h': 9, 'lr_mult': 11, 'extra_fea_len': 36, 'dropout': 0.75} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 8.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.82 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 318.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 94, in forward\n",
      "    nbr_filter = self.sigmoid(nbr_filter)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 329, in forward\n",
      "    return torch.sigmoid(input)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 8.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.82 GiB memory in use. Of the allocated memory 21.28 GiB is allocated by PyTorch, and 318.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 19:59:12,539] Trial 30 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 3\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 48\n",
      "extra_fea_len : 12\n",
      "h_fea_len : 112\n",
      "n_conv : 4\n",
      "n_h : 1\n",
      "att_S : 64\n",
      "dropout_prob : 0.35000000000000003\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=208, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((208,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-7): 8 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=457, out_features=416, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=36, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=244, out_features=224, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.75, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-7): 8 x Linear(in_features=224, out_features=224, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-7): 8 x BatchNorm1d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-7): 8 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=224, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=224, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=224, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=224, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((224,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=224, out_features=224, bias=True)\n",
      "      (key): Linear(in_features=224, out_features=224, bias=True)\n",
      "      (value): Linear(in_features=224, out_features=224, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef674acbe0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef674ac520>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef674acc10>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef674ac700>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef674ac8e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef674ac9d0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef674acd00>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                 | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 334 K  | ?                                        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112]]]\n",
      "1   | model.embedding_atom            | Linear              | 4.5 K  | [2304, 92]                               | [2304, 48]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 96     | [2304, 48]                               | [2304, 48]\n",
      "3   | model.convs                     | ModuleList          | 54.1 K | ?                                        | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 13.5 K | [[2304, 48], [2304, 10, 41], [2304, 10]] | [2304, 48]\n",
      "5   | model.convs.0.fc_full           | Linear              | 13.2 K | [2304, 10, 137]                          | [2304, 10, 96]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 192    | [23040, 96]                              | [23040, 96]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 96     | [2304, 48]                               | [2304, 48]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 48]                               | [2304, 48]\n",
      "11  | model.convs.1                   | ConvLayer           | 13.5 K | [[2304, 48], [2304, 10, 41], [2304, 10]] | [2304, 48]\n",
      "12  | model.convs.1.fc_full           | Linear              | 13.2 K | [2304, 10, 137]                          | [2304, 10, 96]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 192    | [23040, 96]                              | [23040, 96]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 96     | [2304, 48]                               | [2304, 48]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 48]                               | [2304, 48]\n",
      "18  | model.convs.2                   | ConvLayer           | 13.5 K | [[2304, 48], [2304, 10, 41], [2304, 10]] | [2304, 48]\n",
      "19  | model.convs.2.fc_full           | Linear              | 13.2 K | [2304, 10, 137]                          | [2304, 10, 96]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 192    | [23040, 96]                              | [23040, 96]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 96     | [2304, 48]                               | [2304, 48]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 48]                               | [2304, 48]\n",
      "25  | model.convs.3                   | ConvLayer           | 13.5 K | [[2304, 48], [2304, 10, 41], [2304, 10]] | [2304, 48]\n",
      "26  | model.convs.3.fc_full           | Linear              | 13.2 K | [2304, 10, 137]                          | [2304, 10, 96]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 48]                           | [2304, 10, 48]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 192    | [23040, 96]                              | [23040, 96]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 96     | [2304, 48]                               | [2304, 48]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 48]                               | [2304, 48]\n",
      "32  | model.embedding_extra           | Linear              | 84     | [128, 6]                                 | [128, 12]\n",
      "33  | model.embedding_extra_norm      | BatchNorm1d         | 24     | [128, 12]                                | [128, 12]\n",
      "34  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 12]                                | [128, 12]\n",
      "35  | model.conv_to_fc                | Linear              | 6.8 K  | [128, 60]                                | [128, 112]\n",
      "36  | model.conv_to_fc_norm           | BatchNorm1d         | 224    | [128, 112]                               | [128, 112]\n",
      "37  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 112]                               | [128, 112]\n",
      "38  | model.dropout                   | Dropout             | 0      | [128, 112]                               | [128, 112]\n",
      "39  | model.fc_outs                   | ModuleList          | 1.7 K  | ?                                        | ?\n",
      "40  | model.fc_outs.0                 | OutputLayer         | 113    | [128, 112]                               | [128, 1]\n",
      "41  | model.fc_outs.0.fc              | Linear              | 113    | [128, 112]                               | [128, 1]\n",
      "42  | model.fc_outs.1                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "43  | model.fc_outs.1.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "44  | model.fc_outs.1.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "45  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "46  | model.fc_outs.2                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "47  | model.fc_outs.2.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "48  | model.fc_outs.2.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "49  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "50  | model.fc_outs.3                 | OutputLayer         | 452    | [128, 112]                               | [128, 4]\n",
      "51  | model.fc_outs.3.fc              | Sequential          | 452    | [128, 112]                               | [128, 4]\n",
      "52  | model.fc_outs.3.fc.0            | Linear              | 452    | [128, 112]                               | [128, 4]\n",
      "53  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                 | [128, 4]\n",
      "54  | model.fc_outs.4                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "55  | model.fc_outs.4.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "56  | model.fc_outs.4.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "57  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "58  | model.fc_outs.5                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "59  | model.fc_outs.5.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "60  | model.fc_outs.5.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "61  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "62  | model.fc_outs.6                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "63  | model.fc_outs.6.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "64  | model.fc_outs.6.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "65  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "66  | model.task_norms                | ModuleList          | 1.6 K  | ?                                        | ?\n",
      "67  | model.task_norms.0              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "68  | model.task_norms.1              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "69  | model.task_norms.2              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "70  | model.task_norms.3              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "71  | model.task_norms.4              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "72  | model.task_norms.5              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "73  | model.task_norms.6              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "74  | model.task_attentions           | ModuleList          | 265 K  | ?                                        | ?\n",
      "75  | model.task_attentions.0         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "76  | model.task_attentions.0.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "77  | model.task_attentions.0.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "78  | model.task_attentions.0.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "79  | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "80  | model.task_attentions.1         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "81  | model.task_attentions.1.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "82  | model.task_attentions.1.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "83  | model.task_attentions.1.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "84  | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "85  | model.task_attentions.2         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "86  | model.task_attentions.2.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "87  | model.task_attentions.2.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "88  | model.task_attentions.2.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "89  | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "90  | model.task_attentions.3         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "91  | model.task_attentions.3.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "92  | model.task_attentions.3.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "93  | model.task_attentions.3.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "94  | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "95  | model.task_attentions.4         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "96  | model.task_attentions.4.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "97  | model.task_attentions.4.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "98  | model.task_attentions.4.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "99  | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "100 | model.task_attentions.5         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "101 | model.task_attentions.5.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "102 | model.task_attentions.5.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "103 | model.task_attentions.5.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "104 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "105 | model.task_attentions.6         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "106 | model.task_attentions.6.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "107 | model.task_attentions.6.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "108 | model.task_attentions.6.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "109 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "334 K     Trainable params\n",
      "0         Non-trainable params\n",
      "334 K     Total params\n",
      "1.340     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 3 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 334 K  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112]]]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "334 K     Trainable params\n",
      "0         Non-trainable params\n",
      "334 K     Total params\n",
      "1.340     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(0): metric=0.3659 > best_metric=0.0000, log val results..\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "Epoch 0, global step 34: 'val_Metric' reached 0.36589 (best 0.36589), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=00-val_Metric=0.366.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 1, global step 68: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(2): metric=0.4130 > best_metric=0.3659, log val results..\n",
      "Epoch 2, global step 102: 'val_Metric' reached 0.41296 (best 0.41296), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=02-val_Metric=0.413.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 3, global step 136: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 4, global step 170: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 5, global step 204: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(6): metric=0.4737 > best_metric=0.4130, log val results..\n",
      "Epoch 6, global step 238: 'val_Metric' reached 0.47371 (best 0.47371), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=06-val_Metric=0.474.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 7, global step 272: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(8): metric=0.4786 > best_metric=0.4737, log val results..\n",
      "Epoch 8, global step 306: 'val_Metric' reached 0.47863 (best 0.47863), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=08-val_Metric=0.479.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 9, global step 340: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(10): metric=0.5019 > best_metric=0.4786, log val results..\n",
      "Epoch 10, global step 374: 'val_Metric' reached 0.50193 (best 0.50193), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=10-val_Metric=0.502.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 11, global step 408: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(12): metric=0.5031 > best_metric=0.5019, log val results..\n",
      "Epoch 12, global step 442: 'val_Metric' reached 0.50314 (best 0.50314), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=12-val_Metric=0.503.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 13, global step 476: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(14): metric=0.5042 > best_metric=0.5031, log val results..\n",
      "Epoch 14, global step 510: 'val_Metric' reached 0.50424 (best 0.50424), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=14-val_Metric=0.504.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(15): metric=0.5083 > best_metric=0.5042, log val results..\n",
      "Epoch 15, global step 544: 'val_Metric' reached 0.50831 (best 0.50831), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=15-val_Metric=0.508.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 16, global step 578: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 17, global step 612: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 18, global step 646: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(19): metric=0.5175 > best_metric=0.5083, log val results..\n",
      "Epoch 19, global step 680: 'val_Metric' reached 0.51748 (best 0.51748), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=19-val_Metric=0.517.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(20): metric=0.5317 > best_metric=0.5175, log val results..\n",
      "Epoch 20, global step 714: 'val_Metric' reached 0.53173 (best 0.53173), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=20-val_Metric=0.532.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 21, global step 748: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 22, global step 782: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(23): metric=0.5339 > best_metric=0.5317, log val results..\n",
      "Epoch 23, global step 816: 'val_Metric' reached 0.53387 (best 0.53387), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=23-val_Metric=0.534.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 24, global step 850: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 25, global step 884: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 26, global step 918: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 27, global step 952: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 28, global step 986: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 29, global step 1020: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 30, global step 1054: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(31): metric=0.5451 > best_metric=0.5339, log val results..\n",
      "Epoch 31, global step 1088: 'val_Metric' reached 0.54510 (best 0.54510), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=31-val_Metric=0.545.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 32, global step 1122: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 33, global step 1156: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 34, global step 1190: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 35, global step 1224: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(36): metric=0.5484 > best_metric=0.5451, log val results..\n",
      "Epoch 36, global step 1258: 'val_Metric' reached 0.54842 (best 0.54842), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=36-val_Metric=0.548.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 37, global step 1292: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 38, global step 1326: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 39, global step 1360: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 40, global step 1394: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 41, global step 1428: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 42, global step 1462: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 43, global step 1496: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 44, global step 1530: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 45, global step 1564: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 46, global step 1598: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 47, global step 1632: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 48, global step 1666: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(49): metric=0.5609 > best_metric=0.5484, log val results..\n",
      "Epoch 49, global step 1700: 'val_Metric' reached 0.56088 (best 0.56088), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=49-val_Metric=0.561.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 50, global step 1734: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 51, global step 1768: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 52, global step 1802: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(53): metric=0.5706 > best_metric=0.5609, log val results..\n",
      "Epoch 53, global step 1836: 'val_Metric' reached 0.57061 (best 0.57061), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=53-val_Metric=0.571.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 54, global step 1870: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 55, global step 1904: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 56, global step 1938: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 57, global step 1972: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 58, global step 2006: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 59, global step 2040: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 60, global step 2074: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 61, global step 2108: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 62, global step 2142: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 63, global step 2176: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 64, global step 2210: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 65, global step 2244: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 66, global step 2278: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 67, global step 2312: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 68, global step 2346: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 69, global step 2380: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 70, global step 2414: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 71, global step 2448: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 72, global step 2482: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 73, global step 2516: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 74, global step 2550: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 75, global step 2584: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 76, global step 2618: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 77, global step 2652: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 78, global step 2686: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 79, global step 2720: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 80, global step 2754: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 81, global step 2788: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 82, global step 2822: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 83, global step 2856: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 84, global step 2890: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 85, global step 2924: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 86, global step 2958: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 87, global step 2992: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 88, global step 3026: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 89, global step 3060: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 90, global step 3094: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 91, global step 3128: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 92, global step 3162: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 93, global step 3196: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 94, global step 3230: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 95, global step 3264: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(96): metric=0.5759 > best_metric=0.5706, log val results..\n",
      "Epoch 96, global step 3298: 'val_Metric' reached 0.57585 (best 0.57585), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=96-val_Metric=0.576.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 97, global step 3332: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 98, global step 3366: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 99, global step 3400: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 100, global step 3434: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 101, global step 3468: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 102, global step 3502: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 103, global step 3536: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 104, global step 3570: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 105, global step 3604: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 106, global step 3638: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 107, global step 3672: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 108, global step 3706: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 109, global step 3740: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 110, global step 3774: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 111, global step 3808: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 112, global step 3842: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 113, global step 3876: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 114, global step 3910: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 115, global step 3944: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 116, global step 3978: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 117, global step 4012: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 118, global step 4046: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 119, global step 4080: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 120, global step 4114: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 121, global step 4148: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 122, global step 4182: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(123): metric=0.5806 > best_metric=0.5759, log val results..\n",
      "Epoch 123, global step 4216: 'val_Metric' reached 0.58063 (best 0.58063), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=123-val_Metric=0.581.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 124, global step 4250: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(125): metric=0.5831 > best_metric=0.5806, log val results..\n",
      "Epoch 125, global step 4284: 'val_Metric' reached 0.58307 (best 0.58307), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=125-val_Metric=0.583.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 126, global step 4318: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 127, global step 4352: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 128, global step 4386: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 129, global step 4420: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 130, global step 4454: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 131, global step 4488: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 132, global step 4522: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 133, global step 4556: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 134, global step 4590: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 135, global step 4624: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 136, global step 4658: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 137, global step 4692: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 138, global step 4726: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 139, global step 4760: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 140, global step 4794: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 141, global step 4828: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 142, global step 4862: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 143, global step 4896: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 144, global step 4930: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 145, global step 4964: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 146, global step 4998: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 147, global step 5032: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 148, global step 5066: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 149, global step 5100: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 150, global step 5134: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 151, global step 5168: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 152, global step 5202: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 153, global step 5236: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 154, global step 5270: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 155, global step 5304: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 156, global step 5338: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 157, global step 5372: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(158): metric=0.5878 > best_metric=0.5831, log val results..\n",
      "Epoch 158, global step 5406: 'val_Metric' reached 0.58780 (best 0.58780), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=158-val_Metric=0.588.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 159, global step 5440: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 160, global step 5474: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 161, global step 5508: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 162, global step 5542: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 163, global step 5576: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 164, global step 5610: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 165, global step 5644: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 166, global step 5678: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 167, global step 5712: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 168, global step 5746: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 169, global step 5780: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 170, global step 5814: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 171, global step 5848: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 172, global step 5882: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 173, global step 5916: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 174, global step 5950: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 175, global step 5984: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 176, global step 6018: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 177, global step 6052: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 178, global step 6086: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 179, global step 6120: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 180, global step 6154: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 181, global step 6188: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 182, global step 6222: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 183, global step 6256: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 184, global step 6290: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 185, global step 6324: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 186, global step 6358: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 187, global step 6392: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 188, global step 6426: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 189, global step 6460: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 190, global step 6494: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 191, global step 6528: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 192, global step 6562: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 193, global step 6596: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 194, global step 6630: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 195, global step 6664: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 196, global step 6698: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 197, global step 6732: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 198, global step 6766: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 199, global step 6800: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 200, global step 6834: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 201, global step 6868: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 202, global step 6902: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 203, global step 6936: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 204, global step 6970: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 205, global step 7004: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 206, global step 7038: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 207, global step 7072: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 208, global step 7106: 'val_Metric' was not in top 1\n",
      "Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=158-val_Metric=0.588.ckpt\n",
      "##################################################best\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=158-val_Metric=0.588.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=158-val_Metric=0.588.ckpt\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m       SSD/val_MulticlassAUROC       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7912647128105164         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/val_MulticlassAccuracy      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7242063283920288         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_MulticlassF1Score      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7242063283920288         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m SSD/val_MulticlassMatthewsCorrCoef  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.43955177068710327         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         SSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.3054261207580566         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanAbsoluteError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         50.86927032470703          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m TSD/val_MeanAbsolutePercentageError \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.1385197788476944         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanSquaredError       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          4236.1357421875           \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           TSD/val_R2Score           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4187631905078888         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         TSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5335073471069336         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_acid/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7755101919174194         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7857142686843872         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7857142686843872         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6324555277824402         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_acid/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.3623249530792236         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_base/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.16250000894069672         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5208333730697632         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5208333730697632         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         -0.191287100315094         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_base/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         4.812127113342285          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_boiling/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6545138955116272         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5416666865348816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5416666865348816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/val_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.10259783267974854         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_boiling/val_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.450604200363159          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4920210838317871         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7821180820465088         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7821180820465088         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/val_MulticlassMatthewsCor\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5968881249427795         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_water/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6411851644515991         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water4/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7472113966941833         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5295966267585754         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5295966267585754         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/val_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.33927446603775024         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water4/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.8507819175720215         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m       val_MergedMetric_epoch        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5809434652328491         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m             val_Metric              \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5878015764116997         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           val_loss_epoch            \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.948915719985962          \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/val_loss : tensor(0.5335)\n",
      "TSD/val_loss_epoch : tensor(0.5335)\n",
      "TSD/val_loss_weight : tensor(2.5558)\n",
      "TSD/val_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/val_R2Score : tensor(0.4188)\n",
      "TSD/val_MeanAbsoluteError : tensor(50.8693)\n",
      "TSD/val_MeanAbsolutePercentageError : tensor(0.1385)\n",
      "TSD/val_MeanSquaredError : tensor(4236.1357)\n",
      "val_loss : tensor(2.9489)\n",
      "val_loss_epoch : tensor(2.9489)\n",
      "val_MergedMetric : tensor(0.5809)\n",
      "val_MergedMetric_epoch : tensor(0.5809)\n",
      "SSD/val_loss : tensor(1.3054)\n",
      "SSD/val_loss_epoch : tensor(1.3054)\n",
      "SSD/val_loss_weight : tensor(1.6995)\n",
      "SSD/val_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/val_MulticlassAccuracy : tensor(0.7242)\n",
      "SSD/val_MulticlassMatthewsCorrCoef : tensor(0.4396)\n",
      "SSD/val_MulticlassF1Score : tensor(0.7242)\n",
      "SSD/val_MulticlassAUROC : tensor(0.7913)\n",
      "WS24_water/val_loss : tensor(1.6412)\n",
      "WS24_water/val_loss_epoch : tensor(1.6412)\n",
      "WS24_water/val_loss_weight : tensor(1.1472)\n",
      "WS24_water/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/val_MulticlassAccuracy : tensor(0.7821)\n",
      "WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.5969)\n",
      "WS24_water/val_MulticlassF1Score : tensor(0.7821)\n",
      "WS24_water/val_MulticlassAUROC : tensor(0.4920)\n",
      "WS24_water4/val_loss : tensor(3.8508)\n",
      "WS24_water4/val_loss_epoch : tensor(3.8508)\n",
      "WS24_water4/val_loss_weight : tensor(1.1472)\n",
      "WS24_water4/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/val_MulticlassAccuracy : tensor(0.5296)\n",
      "WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.3393)\n",
      "WS24_water4/val_MulticlassF1Score : tensor(0.5296)\n",
      "WS24_water4/val_MulticlassAUROC : tensor(0.7472)\n",
      "WS24_acid/val_loss : tensor(2.3623)\n",
      "WS24_acid/val_loss_epoch : tensor(2.3623)\n",
      "WS24_acid/val_loss_weight : tensor(0.1841)\n",
      "WS24_acid/val_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/val_MulticlassAccuracy : tensor(0.7857)\n",
      "WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.6325)\n",
      "WS24_acid/val_MulticlassF1Score : tensor(0.7857)\n",
      "WS24_acid/val_MulticlassAUROC : tensor(0.7755)\n",
      "WS24_base/val_loss : tensor(4.8121)\n",
      "WS24_base/val_loss_epoch : tensor(4.8121)\n",
      "WS24_base/val_loss_weight : tensor(0.1315)\n",
      "WS24_base/val_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/val_MulticlassAccuracy : tensor(0.5208)\n",
      "WS24_base/val_MulticlassMatthewsCorrCoef : tensor(-0.1913)\n",
      "WS24_base/val_MulticlassF1Score : tensor(0.5208)\n",
      "WS24_base/val_MulticlassAUROC : tensor(0.1625)\n",
      "WS24_boiling/val_loss : tensor(3.4506)\n",
      "WS24_boiling/val_loss_epoch : tensor(3.4506)\n",
      "WS24_boiling/val_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/val_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/val_MulticlassAccuracy : tensor(0.5417)\n",
      "WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.1026)\n",
      "WS24_boiling/val_MulticlassF1Score : tensor(0.5417)\n",
      "WS24_boiling/val_MulticlassAUROC : tensor(0.6545)\n",
      "val_Metric : tensor(0.5878, dtype=torch.float64)\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=158-val_Metric=0.588.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_29/checkpoints/best-epoch=158-val_Metric=0.588.ckpt\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m            Test metric             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0             \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/test_MulticlassAUROC      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6975405812263489          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    SSD/test_MulticlassAccuracy     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6688368320465088          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_MulticlassF1Score     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6688368320465088          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mSSD/test_MulticlassMatthewsCorrCoef \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3026069700717926          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        SSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.7294480800628662          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanAbsoluteError     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          49.25938415527344          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mTSD/test_MeanAbsolutePercentageError\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.1505245715379715          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanSquaredError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           4628.541015625            \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          TSD/test_R2Score          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.34904417395591736         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        TSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5829277038574219          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8240740299224854          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_acid/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7222222089767456          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7222222089767456          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4558423161506653          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_acid/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6248462200164795          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4583333432674408          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_base/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.9318181872367859          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.9318181872367859          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8651483654975891          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_base/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4259789288043976          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5961538553237915          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassAccuracy\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5384615659713745          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5384615659713745          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassMatthew\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.07784989476203918         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_boiling/test_loss_epoch    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.7006876468658447          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7719242572784424          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6843546628952026          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6843546628952026          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/test_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4011678099632263          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.9320896863937378          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7920114994049072          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5769097208976746          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5769097208976746          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassMatthews\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3605947196483612          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_water4/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.8336825370788574          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m            test_Metric             \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5496675486892061          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          test_loss_epoch           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.6577157974243164          \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/test_loss : tensor(0.5829)\n",
      "TSD/test_loss_epoch : tensor(0.5829)\n",
      "TSD/test_loss_weight : tensor(2.5558)\n",
      "TSD/test_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/test_R2Score : tensor(0.3490)\n",
      "TSD/test_MeanAbsoluteError : tensor(49.2594)\n",
      "TSD/test_MeanAbsolutePercentageError : tensor(0.1505)\n",
      "TSD/test_MeanSquaredError : tensor(4628.5410)\n",
      "test_loss : tensor(2.6577)\n",
      "test_loss_epoch : tensor(2.6577)\n",
      "SSD/test_loss : tensor(1.7294)\n",
      "SSD/test_loss_epoch : tensor(1.7294)\n",
      "SSD/test_loss_weight : tensor(1.6995)\n",
      "SSD/test_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/test_MulticlassAccuracy : tensor(0.6688)\n",
      "SSD/test_MulticlassMatthewsCorrCoef : tensor(0.3026)\n",
      "SSD/test_MulticlassF1Score : tensor(0.6688)\n",
      "SSD/test_MulticlassAUROC : tensor(0.6975)\n",
      "WS24_water/test_loss : tensor(1.9321)\n",
      "WS24_water/test_loss_epoch : tensor(1.9321)\n",
      "WS24_water/test_loss_weight : tensor(1.1472)\n",
      "WS24_water/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/test_MulticlassAccuracy : tensor(0.6844)\n",
      "WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4012)\n",
      "WS24_water/test_MulticlassF1Score : tensor(0.6844)\n",
      "WS24_water/test_MulticlassAUROC : tensor(0.7719)\n",
      "WS24_water4/test_loss : tensor(1.8337)\n",
      "WS24_water4/test_loss_epoch : tensor(1.8337)\n",
      "WS24_water4/test_loss_weight : tensor(1.1472)\n",
      "WS24_water4/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/test_MulticlassAccuracy : tensor(0.5769)\n",
      "WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3606)\n",
      "WS24_water4/test_MulticlassF1Score : tensor(0.5769)\n",
      "WS24_water4/test_MulticlassAUROC : tensor(0.7920)\n",
      "WS24_acid/test_loss : tensor(1.6248)\n",
      "WS24_acid/test_loss_epoch : tensor(1.6248)\n",
      "WS24_acid/test_loss_weight : tensor(0.1841)\n",
      "WS24_acid/test_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/test_MulticlassAccuracy : tensor(0.7222)\n",
      "WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.4558)\n",
      "WS24_acid/test_MulticlassF1Score : tensor(0.7222)\n",
      "WS24_acid/test_MulticlassAUROC : tensor(0.8241)\n",
      "WS24_base/test_loss : tensor(0.4260)\n",
      "WS24_base/test_loss_epoch : tensor(0.4260)\n",
      "WS24_base/test_loss_weight : tensor(0.1315)\n",
      "WS24_base/test_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/test_MulticlassAccuracy : tensor(0.9318)\n",
      "WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.8651)\n",
      "WS24_base/test_MulticlassF1Score : tensor(0.9318)\n",
      "WS24_base/test_MulticlassAUROC : tensor(0.4583)\n",
      "WS24_boiling/test_loss : tensor(2.7007)\n",
      "WS24_boiling/test_loss_epoch : tensor(2.7007)\n",
      "WS24_boiling/test_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/test_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/test_MulticlassAccuracy : tensor(0.5385)\n",
      "WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.0778)\n",
      "WS24_boiling/test_MulticlassF1Score : tensor(0.5385)\n",
      "WS24_boiling/test_MulticlassAUROC : tensor(0.5962)\n",
      "test_Metric : tensor(0.5497, dtype=torch.float64)\n",
      "[I 2025-12-03 20:43:05,993] Trial 31 finished with value: 0.5457939406220258 and parameters: {'atom_fea_len': 48, 'h_fea_len': 112, 'n_conv': 4, 'n_h': 1, 'lr_mult': 3, 'extra_fea_len': 12, 'dropout': 0.35000000000000003}. Best is trial 31 with value: 0.5457939406220258.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 1\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 272\n",
      "extra_fea_len : 4\n",
      "h_fea_len : 96\n",
      "n_conv : 10\n",
      "n_h : 4\n",
      "att_S : 64\n",
      "dropout_prob : 0.35000000000000003\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=48, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-3): 4 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=137, out_features=96, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=12, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=60, out_features=112, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.35000000000000003, inplace=False)\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=112, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=112, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=112, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=112, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((112,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=112, out_features=112, bias=True)\n",
      "      (key): Linear(in_features=112, out_features=112, bias=True)\n",
      "      (value): Linear(in_features=112, out_features=112, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781ef40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781ea30>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781ef70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781ed00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781e940>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781e0d0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781edf0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 3.5 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 25.3 K | [2304, 92]                                | [2304, 272]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 544    | [2304, 272]                               | [2304, 272]\n",
      "3   | model.convs                     | ModuleList          | 3.2 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "5   | model.convs.0.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "11  | model.convs.1                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "12  | model.convs.1.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "18  | model.convs.2                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "19  | model.convs.2.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "25  | model.convs.3                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "26  | model.convs.3.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "32  | model.convs.4                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "33  | model.convs.4.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "39  | model.convs.5                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "40  | model.convs.5.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "42  | model.convs.5.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "43  | model.convs.5.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "44  | model.convs.5.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "45  | model.convs.5.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "46  | model.convs.6                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "47  | model.convs.6.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "49  | model.convs.6.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "50  | model.convs.6.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "51  | model.convs.6.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "52  | model.convs.6.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "53  | model.convs.7                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "54  | model.convs.7.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "56  | model.convs.7.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "57  | model.convs.7.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "58  | model.convs.7.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "59  | model.convs.7.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "60  | model.convs.8                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "61  | model.convs.8.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "62  | model.convs.8.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "63  | model.convs.8.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "64  | model.convs.8.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "65  | model.convs.8.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "66  | model.convs.8.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "67  | model.convs.9                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "68  | model.convs.9.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "69  | model.convs.9.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "70  | model.convs.9.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "71  | model.convs.9.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "72  | model.convs.9.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "73  | model.convs.9.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "74  | model.embedding_extra           | Linear              | 28     | [128, 6]                                  | [128, 4]\n",
      "75  | model.embedding_extra_norm      | BatchNorm1d         | 8      | [128, 4]                                  | [128, 4]\n",
      "76  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 4]                                  | [128, 4]\n",
      "77  | model.conv_to_fc                | Linear              | 26.6 K | [128, 276]                                | [128, 96]\n",
      "78  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "79  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "80  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "81  | model.fcs                       | ModuleList          | 27.9 K | ?                                         | ?\n",
      "82  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "83  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "84  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "85  | model.norms                     | ModuleList          | 576    | ?                                         | ?\n",
      "86  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "87  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "88  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "89  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "90  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "91  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "92  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "93  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "94  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "95  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "96  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "97  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "98  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "99  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "100 | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "101 | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "102 | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "103 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "104 | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "105 | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "106 | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "107 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "108 | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "109 | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "110 | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "111 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "112 | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "113 | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "114 | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "115 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "116 | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "117 | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "118 | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "119 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "120 | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "121 | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "125 | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "129 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "130 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "134 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "135 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "136 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "137 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "138 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "139 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "140 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "141 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "142 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "143 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "144 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "145 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "146 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "147 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "148 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "149 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "150 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "151 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "152 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "153 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "154 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "155 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "156 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "157 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "158 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "159 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "160 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "161 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "162 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "163 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "13.935    Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_30\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'convs.8.fc_full.weight', 'convs.9.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'convs.8.fc_full.bias', 'convs.8.bn1.weight', 'convs.8.bn1.bias', 'convs.8.bn2.weight', 'convs.8.bn2.bias', 'convs.9.fc_full.bias', 'convs.9.bn1.weight', 'convs.9.bn1.bias', 'convs.9.bn2.weight', 'convs.9.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 1 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 3.5 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "13.935    Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 20:43:16,384] Trial 32 failed with parameters: {'atom_fea_len': 272, 'h_fea_len': 96, 'n_conv': 10, 'n_h': 4, 'lr_mult': 1, 'extra_fea_len': 4, 'dropout': 0.35000000000000003} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 992.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 716.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.13 GiB memory in use. Of the allocated memory 19.45 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 87, in forward\n",
      "    total_nbr_fea = torch.cat(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 992.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 716.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.13 GiB memory in use. Of the allocated memory 19.45 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 20:43:16,384] Trial 32 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 1\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 80\n",
      "extra_fea_len : 4\n",
      "h_fea_len : 112\n",
      "n_conv : 10\n",
      "n_h : 4\n",
      "att_S : 64\n",
      "dropout_prob : 0.35000000000000003\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=272, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((272,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-9): 10 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=585, out_features=544, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=276, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.35000000000000003, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-2): 3 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-2): 3 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6749cc10>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6749c940>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6749c8e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6749cf40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6749cac0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6749c640>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6749ce80>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                 | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 653 K  | ?                                        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112]]]\n",
      "1   | model.embedding_atom            | Linear              | 7.4 K  | [2304, 92]                               | [2304, 80]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 160    | [2304, 80]                               | [2304, 80]\n",
      "3   | model.convs                     | ModuleList          | 328 K  | ?                                        | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "5   | model.convs.0.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "11  | model.convs.1                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "12  | model.convs.1.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "18  | model.convs.2                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "19  | model.convs.2.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "25  | model.convs.3                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "26  | model.convs.3.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "32  | model.convs.4                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "33  | model.convs.4.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "39  | model.convs.5                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "40  | model.convs.5.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "42  | model.convs.5.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "43  | model.convs.5.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "44  | model.convs.5.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "45  | model.convs.5.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "46  | model.convs.6                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "47  | model.convs.6.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "49  | model.convs.6.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "50  | model.convs.6.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "51  | model.convs.6.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "52  | model.convs.6.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "53  | model.convs.7                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "54  | model.convs.7.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "56  | model.convs.7.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "57  | model.convs.7.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "58  | model.convs.7.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "59  | model.convs.7.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "60  | model.convs.8                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "61  | model.convs.8.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "62  | model.convs.8.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "63  | model.convs.8.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "64  | model.convs.8.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "65  | model.convs.8.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "66  | model.convs.8.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "67  | model.convs.9                   | ConvLayer           | 32.8 K | [[2304, 80], [2304, 10, 41], [2304, 10]] | [2304, 80]\n",
      "68  | model.convs.9.fc_full           | Linear              | 32.3 K | [2304, 10, 201]                          | [2304, 10, 160]\n",
      "69  | model.convs.9.sigmoid           | Sigmoid             | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "70  | model.convs.9.softplus1         | Softplus            | 0      | [2304, 10, 80]                           | [2304, 10, 80]\n",
      "71  | model.convs.9.bn1               | BatchNorm1d         | 320    | [23040, 160]                             | [23040, 160]\n",
      "72  | model.convs.9.bn2               | BatchNorm1d         | 160    | [2304, 80]                               | [2304, 80]\n",
      "73  | model.convs.9.softplus2         | Softplus            | 0      | [2304, 80]                               | [2304, 80]\n",
      "74  | model.embedding_extra           | Linear              | 28     | [128, 6]                                 | [128, 4]\n",
      "75  | model.embedding_extra_norm      | BatchNorm1d         | 8      | [128, 4]                                 | [128, 4]\n",
      "76  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 4]                                 | [128, 4]\n",
      "77  | model.conv_to_fc                | Linear              | 9.5 K  | [128, 84]                                | [128, 112]\n",
      "78  | model.conv_to_fc_norm           | BatchNorm1d         | 224    | [128, 112]                               | [128, 112]\n",
      "79  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 112]                               | [128, 112]\n",
      "80  | model.dropout                   | Dropout             | 0      | [128, 112]                               | [128, 112]\n",
      "81  | model.fcs                       | ModuleList          | 38.0 K | ?                                        | ?\n",
      "82  | model.fcs.0                     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "83  | model.fcs.1                     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "84  | model.fcs.2                     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "85  | model.norms                     | ModuleList          | 672    | ?                                        | ?\n",
      "86  | model.norms.0                   | BatchNorm1d         | 224    | [128, 112]                               | [128, 112]\n",
      "87  | model.norms.1                   | BatchNorm1d         | 224    | [128, 112]                               | [128, 112]\n",
      "88  | model.norms.2                   | BatchNorm1d         | 224    | [128, 112]                               | [128, 112]\n",
      "89  | model.softpluses                | ModuleList          | 0      | ?                                        | ?\n",
      "90  | model.softpluses.0              | Softplus            | 0      | [128, 112]                               | [128, 112]\n",
      "91  | model.softpluses.1              | Softplus            | 0      | [128, 112]                               | [128, 112]\n",
      "92  | model.softpluses.2              | Softplus            | 0      | [128, 112]                               | [128, 112]\n",
      "93  | model.fc_outs                   | ModuleList          | 1.7 K  | ?                                        | ?\n",
      "94  | model.fc_outs.0                 | OutputLayer         | 113    | [128, 112]                               | [128, 1]\n",
      "95  | model.fc_outs.0.fc              | Linear              | 113    | [128, 112]                               | [128, 1]\n",
      "96  | model.fc_outs.1                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "97  | model.fc_outs.1.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "98  | model.fc_outs.1.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "99  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "100 | model.fc_outs.2                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "101 | model.fc_outs.2.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "102 | model.fc_outs.2.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "103 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "104 | model.fc_outs.3                 | OutputLayer         | 452    | [128, 112]                               | [128, 4]\n",
      "105 | model.fc_outs.3.fc              | Sequential          | 452    | [128, 112]                               | [128, 4]\n",
      "106 | model.fc_outs.3.fc.0            | Linear              | 452    | [128, 112]                               | [128, 4]\n",
      "107 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                 | [128, 4]\n",
      "108 | model.fc_outs.4                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "109 | model.fc_outs.4.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "110 | model.fc_outs.4.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "111 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "112 | model.fc_outs.5                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "113 | model.fc_outs.5.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "114 | model.fc_outs.5.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "115 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "116 | model.fc_outs.6                 | OutputLayer         | 226    | [128, 112]                               | [128, 2]\n",
      "117 | model.fc_outs.6.fc              | Sequential          | 226    | [128, 112]                               | [128, 2]\n",
      "118 | model.fc_outs.6.fc.0            | Linear              | 226    | [128, 112]                               | [128, 2]\n",
      "119 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "120 | model.task_norms                | ModuleList          | 1.6 K  | ?                                        | ?\n",
      "121 | model.task_norms.0              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "122 | model.task_norms.1              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "123 | model.task_norms.2              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "124 | model.task_norms.3              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "125 | model.task_norms.4              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "126 | model.task_norms.5              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "127 | model.task_norms.6              | LayerNorm           | 224    | [128, 112]                               | [128, 112]\n",
      "128 | model.task_attentions           | ModuleList          | 265 K  | ?                                        | ?\n",
      "129 | model.task_attentions.0         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "130 | model.task_attentions.0.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "131 | model.task_attentions.0.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "132 | model.task_attentions.0.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "133 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "134 | model.task_attentions.1         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "135 | model.task_attentions.1.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "136 | model.task_attentions.1.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "137 | model.task_attentions.1.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "138 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "139 | model.task_attentions.2         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "140 | model.task_attentions.2.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "141 | model.task_attentions.2.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "142 | model.task_attentions.2.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "143 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "144 | model.task_attentions.3         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "145 | model.task_attentions.3.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "146 | model.task_attentions.3.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "147 | model.task_attentions.3.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "148 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "149 | model.task_attentions.4         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "150 | model.task_attentions.4.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "151 | model.task_attentions.4.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "152 | model.task_attentions.4.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "153 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "154 | model.task_attentions.5         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "155 | model.task_attentions.5.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "156 | model.task_attentions.5.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "157 | model.task_attentions.5.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "158 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "159 | model.task_attentions.6         | SelfAttention       | 38.0 K | [128, 112]                               | [128, 112]\n",
      "160 | model.task_attentions.6.query   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "161 | model.task_attentions.6.key     | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "162 | model.task_attentions.6.value   | Linear              | 12.7 K | [128, 112]                               | [128, 112]\n",
      "163 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "653 K     Trainable params\n",
      "0         Non-trainable params\n",
      "653 K     Total params\n",
      "2.612     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'convs.8.fc_full.weight', 'convs.9.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'convs.8.fc_full.bias', 'convs.8.bn1.weight', 'convs.8.bn1.bias', 'convs.8.bn2.weight', 'convs.8.bn2.bias', 'convs.9.fc_full.bias', 'convs.9.bn1.weight', 'convs.9.bn1.bias', 'convs.9.bn2.weight', 'convs.9.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 1 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 653 K  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112], [128, 112]]]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "653 K     Trainable params\n",
      "0         Non-trainable params\n",
      "653 K     Total params\n",
      "2.612     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(0): metric=0.3334 > best_metric=0.0000, log val results..\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "Epoch 0, global step 34: 'val_Metric' reached 0.33336 (best 0.33336), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=00-val_Metric=0.333.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(1): metric=0.4022 > best_metric=0.3334, log val results..\n",
      "Epoch 1, global step 68: 'val_Metric' reached 0.40225 (best 0.40225), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=01-val_Metric=0.402.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 2, global step 102: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(3): metric=0.4284 > best_metric=0.4022, log val results..\n",
      "Epoch 3, global step 136: 'val_Metric' reached 0.42843 (best 0.42843), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=03-val_Metric=0.428.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 4, global step 170: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 5, global step 204: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(6): metric=0.4519 > best_metric=0.4284, log val results..\n",
      "Epoch 6, global step 238: 'val_Metric' reached 0.45189 (best 0.45189), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=06-val_Metric=0.452.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(7): metric=0.4784 > best_metric=0.4519, log val results..\n",
      "Epoch 7, global step 272: 'val_Metric' reached 0.47842 (best 0.47842), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=07-val_Metric=0.478.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 8, global step 306: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 9, global step 340: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(10): metric=0.4908 > best_metric=0.4784, log val results..\n",
      "Epoch 10, global step 374: 'val_Metric' reached 0.49082 (best 0.49082), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=10-val_Metric=0.491.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 11, global step 408: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(12): metric=0.5094 > best_metric=0.4908, log val results..\n",
      "Epoch 12, global step 442: 'val_Metric' reached 0.50944 (best 0.50944), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=12-val_Metric=0.509.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 13, global step 476: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(14): metric=0.5221 > best_metric=0.5094, log val results..\n",
      "Epoch 14, global step 510: 'val_Metric' reached 0.52211 (best 0.52211), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=14-val_Metric=0.522.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 15, global step 544: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 16, global step 578: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 17, global step 612: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 18, global step 646: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(19): metric=0.5412 > best_metric=0.5221, log val results..\n",
      "Epoch 19, global step 680: 'val_Metric' reached 0.54121 (best 0.54121), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=19-val_Metric=0.541.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 20, global step 714: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 21, global step 748: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 22, global step 782: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 23, global step 816: 'val_Metric' reached 0.54148 (best 0.54148), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=23-val_Metric=0.541.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 24, global step 850: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 25, global step 884: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 26, global step 918: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 27, global step 952: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 28, global step 986: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 29, global step 1020: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 30, global step 1054: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 31, global step 1088: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 32, global step 1122: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(33): metric=0.5787 > best_metric=0.5412, log val results..\n",
      "Epoch 33, global step 1156: 'val_Metric' reached 0.57867 (best 0.57867), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=33-val_Metric=0.579.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 34, global step 1190: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 35, global step 1224: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 36, global step 1258: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 37, global step 1292: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 38, global step 1326: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 39, global step 1360: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 40, global step 1394: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 41, global step 1428: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 42, global step 1462: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 43, global step 1496: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 44, global step 1530: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 45, global step 1564: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 46, global step 1598: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 47, global step 1632: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 48, global step 1666: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 49, global step 1700: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 50, global step 1734: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 51, global step 1768: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 52, global step 1802: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 53, global step 1836: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 54, global step 1870: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(55): metric=0.5937 > best_metric=0.5787, log val results..\n",
      "Epoch 55, global step 1904: 'val_Metric' reached 0.59373 (best 0.59373), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=55-val_Metric=0.594.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 56, global step 1938: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 57, global step 1972: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 58, global step 2006: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 59, global step 2040: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 60, global step 2074: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 61, global step 2108: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 62, global step 2142: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 63, global step 2176: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 64, global step 2210: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 65, global step 2244: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 66, global step 2278: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 67, global step 2312: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 68, global step 2346: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 69, global step 2380: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 70, global step 2414: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 71, global step 2448: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 72, global step 2482: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 73, global step 2516: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 74, global step 2550: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 75, global step 2584: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 76, global step 2618: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 77, global step 2652: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 78, global step 2686: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 79, global step 2720: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 80, global step 2754: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 81, global step 2788: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 82, global step 2822: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 83, global step 2856: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 84, global step 2890: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 85, global step 2924: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 86, global step 2958: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 87, global step 2992: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 88, global step 3026: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 89, global step 3060: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 90, global step 3094: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 91, global step 3128: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 92, global step 3162: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 93, global step 3196: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 94, global step 3230: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 95, global step 3264: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 96, global step 3298: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 97, global step 3332: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 98, global step 3366: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 99, global step 3400: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 100, global step 3434: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 101, global step 3468: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 102, global step 3502: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 103, global step 3536: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 104, global step 3570: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 105, global step 3604: 'val_Metric' was not in top 1\n",
      "Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=55-val_Metric=0.594.ckpt\n",
      "##################################################best\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=55-val_Metric=0.594.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=55-val_Metric=0.594.ckpt\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m       SSD/val_MulticlassAUROC       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7690726518630981         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/val_MulticlassAccuracy      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7204941511154175         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_MulticlassF1Score      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7204941511154175         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m SSD/val_MulticlassMatthewsCorrCoef  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.42851465940475464         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         SSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.9208879470825195         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanAbsoluteError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         45.82213592529297          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m TSD/val_MeanAbsolutePercentageError \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.12807469069957733         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanSquaredError       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          3809.40478515625          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           TSD/val_R2Score           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.48840218782424927         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         TSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.47976401448249817         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_acid/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8724490404129028         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                0.75                \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                0.75                \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5353033542633057         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_acid/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6703482866287231         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_base/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.22500000894069672         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5416666269302368         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5416666269302368         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.037796445190906525        \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_base/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.452415704727173          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_boiling/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5972222089767456         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m               0.625                \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m               0.625                \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/val_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.2750095725059509         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_boiling/val_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6841120719909668         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5424632430076599         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8199653029441833         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8199653029441833         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/val_MulticlassMatthewsCor\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6351215243339539         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_water/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7615949511528015         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water4/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8057075142860413         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6688711643218994         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6688711643218994         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/val_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4488013982772827         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water4/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.7696086168289185         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m       val_MergedMetric_epoch        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6053234934806824         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m             val_Metric              \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5937264288736578         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           val_loss_epoch            \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.745707392692566          \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/val_loss : tensor(0.4798)\n",
      "TSD/val_loss_epoch : tensor(0.4798)\n",
      "TSD/val_loss_weight : tensor(2.5558)\n",
      "TSD/val_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/val_R2Score : tensor(0.4884)\n",
      "TSD/val_MeanAbsoluteError : tensor(45.8221)\n",
      "TSD/val_MeanAbsolutePercentageError : tensor(0.1281)\n",
      "TSD/val_MeanSquaredError : tensor(3809.4048)\n",
      "val_loss : tensor(1.7457)\n",
      "val_loss_epoch : tensor(1.7457)\n",
      "val_MergedMetric : tensor(0.6053)\n",
      "val_MergedMetric_epoch : tensor(0.6053)\n",
      "SSD/val_loss : tensor(0.9209)\n",
      "SSD/val_loss_epoch : tensor(0.9209)\n",
      "SSD/val_loss_weight : tensor(1.6995)\n",
      "SSD/val_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/val_MulticlassAccuracy : tensor(0.7205)\n",
      "SSD/val_MulticlassMatthewsCorrCoef : tensor(0.4285)\n",
      "SSD/val_MulticlassF1Score : tensor(0.7205)\n",
      "SSD/val_MulticlassAUROC : tensor(0.7691)\n",
      "WS24_water/val_loss : tensor(0.7616)\n",
      "WS24_water/val_loss_epoch : tensor(0.7616)\n",
      "WS24_water/val_loss_weight : tensor(1.1472)\n",
      "WS24_water/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/val_MulticlassAccuracy : tensor(0.8200)\n",
      "WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.6351)\n",
      "WS24_water/val_MulticlassF1Score : tensor(0.8200)\n",
      "WS24_water/val_MulticlassAUROC : tensor(0.5425)\n",
      "WS24_water4/val_loss : tensor(1.7696)\n",
      "WS24_water4/val_loss_epoch : tensor(1.7696)\n",
      "WS24_water4/val_loss_weight : tensor(1.1472)\n",
      "WS24_water4/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/val_MulticlassAccuracy : tensor(0.6689)\n",
      "WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.4488)\n",
      "WS24_water4/val_MulticlassF1Score : tensor(0.6689)\n",
      "WS24_water4/val_MulticlassAUROC : tensor(0.8057)\n",
      "WS24_acid/val_loss : tensor(0.6703)\n",
      "WS24_acid/val_loss_epoch : tensor(0.6703)\n",
      "WS24_acid/val_loss_weight : tensor(0.1841)\n",
      "WS24_acid/val_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/val_MulticlassAccuracy : tensor(0.7500)\n",
      "WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.5353)\n",
      "WS24_acid/val_MulticlassF1Score : tensor(0.7500)\n",
      "WS24_acid/val_MulticlassAUROC : tensor(0.8724)\n",
      "WS24_base/val_loss : tensor(2.4524)\n",
      "WS24_base/val_loss_epoch : tensor(2.4524)\n",
      "WS24_base/val_loss_weight : tensor(0.1315)\n",
      "WS24_base/val_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/val_MulticlassAccuracy : tensor(0.5417)\n",
      "WS24_base/val_MulticlassMatthewsCorrCoef : tensor(0.0378)\n",
      "WS24_base/val_MulticlassF1Score : tensor(0.5417)\n",
      "WS24_base/val_MulticlassAUROC : tensor(0.2250)\n",
      "WS24_boiling/val_loss : tensor(1.6841)\n",
      "WS24_boiling/val_loss_epoch : tensor(1.6841)\n",
      "WS24_boiling/val_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/val_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/val_MulticlassAccuracy : tensor(0.6250)\n",
      "WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.2750)\n",
      "WS24_boiling/val_MulticlassF1Score : tensor(0.6250)\n",
      "WS24_boiling/val_MulticlassAUROC : tensor(0.5972)\n",
      "val_Metric : tensor(0.5937, dtype=torch.float64)\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=55-val_Metric=0.594.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_31/checkpoints/best-epoch=55-val_Metric=0.594.ckpt\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m            Test metric             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0             \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/test_MulticlassAUROC      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7052807807922363          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    SSD/test_MulticlassAccuracy     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6857638955116272          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_MulticlassF1Score     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6857638955116272          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mSSD/test_MulticlassMatthewsCorrCoef \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3236832916736603          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        SSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.9804109334945679          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanAbsoluteError     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         50.872047424316406          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mTSD/test_MeanAbsolutePercentageError\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.15873074531555176         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanSquaredError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m            4792.59765625            \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          TSD/test_R2Score          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.32443296909332275         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        TSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6035892367362976          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.9197530746459961          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_acid/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8611111044883728          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8611111044883728          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          0.732466995716095          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_acid/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5488946437835693          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.40416669845581055         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_base/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8181818127632141          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8181818127632141          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6333333253860474          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_base/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.44871827960014343         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6508876085281372          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassAccuracy\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6538461446762085          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6538461446762085          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassMatthew\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.30860671401023865         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_boiling/test_loss_epoch    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.3459035158157349          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8086115121841431          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7538942098617554          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7538942098617554          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/test_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.49455803632736206         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          1.121644139289856          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8222429752349854          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6754339933395386          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6754339933395386          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassMatthews\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4522477388381958          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_water4/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          5.234615325927734          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m            test_Metric             \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5501747415620548          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          test_loss_epoch           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          3.074991464614868          \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/test_loss : tensor(0.6036)\n",
      "TSD/test_loss_epoch : tensor(0.6036)\n",
      "TSD/test_loss_weight : tensor(2.5558)\n",
      "TSD/test_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/test_R2Score : tensor(0.3244)\n",
      "TSD/test_MeanAbsoluteError : tensor(50.8720)\n",
      "TSD/test_MeanAbsolutePercentageError : tensor(0.1587)\n",
      "TSD/test_MeanSquaredError : tensor(4792.5977)\n",
      "test_loss : tensor(3.0750)\n",
      "test_loss_epoch : tensor(3.0750)\n",
      "SSD/test_loss : tensor(0.9804)\n",
      "SSD/test_loss_epoch : tensor(0.9804)\n",
      "SSD/test_loss_weight : tensor(1.6995)\n",
      "SSD/test_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/test_MulticlassAccuracy : tensor(0.6858)\n",
      "SSD/test_MulticlassMatthewsCorrCoef : tensor(0.3237)\n",
      "SSD/test_MulticlassF1Score : tensor(0.6858)\n",
      "SSD/test_MulticlassAUROC : tensor(0.7053)\n",
      "WS24_water/test_loss : tensor(1.1216)\n",
      "WS24_water/test_loss_epoch : tensor(1.1216)\n",
      "WS24_water/test_loss_weight : tensor(1.1472)\n",
      "WS24_water/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/test_MulticlassAccuracy : tensor(0.7539)\n",
      "WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4946)\n",
      "WS24_water/test_MulticlassF1Score : tensor(0.7539)\n",
      "WS24_water/test_MulticlassAUROC : tensor(0.8086)\n",
      "WS24_water4/test_loss : tensor(5.2346)\n",
      "WS24_water4/test_loss_epoch : tensor(5.2346)\n",
      "WS24_water4/test_loss_weight : tensor(1.1472)\n",
      "WS24_water4/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/test_MulticlassAccuracy : tensor(0.6754)\n",
      "WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.4522)\n",
      "WS24_water4/test_MulticlassF1Score : tensor(0.6754)\n",
      "WS24_water4/test_MulticlassAUROC : tensor(0.8222)\n",
      "WS24_acid/test_loss : tensor(0.5489)\n",
      "WS24_acid/test_loss_epoch : tensor(0.5489)\n",
      "WS24_acid/test_loss_weight : tensor(0.1841)\n",
      "WS24_acid/test_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/test_MulticlassAccuracy : tensor(0.8611)\n",
      "WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.7325)\n",
      "WS24_acid/test_MulticlassF1Score : tensor(0.8611)\n",
      "WS24_acid/test_MulticlassAUROC : tensor(0.9198)\n",
      "WS24_base/test_loss : tensor(0.4487)\n",
      "WS24_base/test_loss_epoch : tensor(0.4487)\n",
      "WS24_base/test_loss_weight : tensor(0.1315)\n",
      "WS24_base/test_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/test_MulticlassAccuracy : tensor(0.8182)\n",
      "WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.6333)\n",
      "WS24_base/test_MulticlassF1Score : tensor(0.8182)\n",
      "WS24_base/test_MulticlassAUROC : tensor(0.4042)\n",
      "WS24_boiling/test_loss : tensor(1.3459)\n",
      "WS24_boiling/test_loss_epoch : tensor(1.3459)\n",
      "WS24_boiling/test_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/test_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/test_MulticlassAccuracy : tensor(0.6538)\n",
      "WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.3086)\n",
      "WS24_boiling/test_MulticlassF1Score : tensor(0.6538)\n",
      "WS24_boiling/test_MulticlassAUROC : tensor(0.6509)\n",
      "test_Metric : tensor(0.5502, dtype=torch.float64)\n",
      "[I 2025-12-03 21:23:45,690] Trial 33 finished with value: 0.5149399067566554 and parameters: {'atom_fea_len': 80, 'h_fea_len': 112, 'n_conv': 10, 'n_h': 4, 'lr_mult': 1, 'extra_fea_len': 4, 'dropout': 0.35000000000000003}. Best is trial 31 with value: 0.5457939406220258.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 15\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 256\n",
      "extra_fea_len : 52\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=80, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-9): 10 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=201, out_features=160, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=84, out_features=112, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.35000000000000003, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=112, out_features=112, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-2): 3 x BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-2): 3 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=112, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=112, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=112, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=112, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((112,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=112, out_features=112, bias=True)\n",
      "      (key): Linear(in_features=112, out_features=112, bias=True)\n",
      "      (value): Linear(in_features=112, out_features=112, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6756b910>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6756b940>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6756b790>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6756bdc0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6756b340>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6756b4c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6756be80>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.7 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 23.8 K | [2304, 92]                                | [2304, 256]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 512    | [2304, 256]                               | [2304, 256]\n",
      "3   | model.convs                     | ModuleList          | 1.4 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "5   | model.convs.0.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "11  | model.convs.1                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "12  | model.convs.1.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "18  | model.convs.2                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "19  | model.convs.2.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "25  | model.convs.3                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "26  | model.convs.3.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "32  | model.convs.4                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "33  | model.convs.4.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "39  | model.embedding_extra           | Linear              | 364    | [128, 6]                                  | [128, 52]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 104    | [128, 52]                                 | [128, 52]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 52]                                 | [128, 52]\n",
      "42  | model.conv_to_fc                | Linear              | 29.7 K | [128, 308]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.906     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_32\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 15 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.7 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.906     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:24:05,796] Trial 34 failed with parameters: {'atom_fea_len': 256, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 15, 'extra_fea_len': 52, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 492.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 434.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.40 GiB memory in use. Of the allocated memory 20.70 GiB is allocated by PyTorch, and 481.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 96, in forward\n",
      "    nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 492.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 434.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.40 GiB memory in use. Of the allocated memory 20.70 GiB is allocated by PyTorch, and 481.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:24:05,797] Trial 34 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 256\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=256, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=553, out_features=512, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=52, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=308, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef6781e190>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e439dc0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e439850>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e439340>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e439880>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e439580>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e439430>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.7 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 23.8 K | [2304, 92]                                | [2304, 256]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 512    | [2304, 256]                               | [2304, 256]\n",
      "3   | model.convs                     | ModuleList          | 1.4 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "5   | model.convs.0.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "11  | model.convs.1                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "12  | model.convs.1.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "18  | model.convs.2                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "19  | model.convs.2.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "25  | model.convs.3                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "26  | model.convs.3.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "32  | model.convs.4                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "33  | model.convs.4.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 30.0 K | [128, 312]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_33\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.7 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:24:23,563] Trial 35 failed with parameters: {'atom_fea_len': 256, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 56, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 91, in forward\n",
      "    total_gated_fea = self.bn1(total_gated_fea.view(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:24:23,564] Trial 35 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 272\n",
      "extra_fea_len : 52\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 5\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=256, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=553, out_features=512, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=312, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e26b7c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e26b820>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e26bbe0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e26bf70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e26bfa0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e26bf10>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef5e26b1c0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.9 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 25.3 K | [2304, 92]                                | [2304, 272]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 544    | [2304, 272]                               | [2304, 272]\n",
      "3   | model.convs                     | ModuleList          | 1.6 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "5   | model.convs.0.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "11  | model.convs.1                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "12  | model.convs.1.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "18  | model.convs.2                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "19  | model.convs.2.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "25  | model.convs.3                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "26  | model.convs.3.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "32  | model.convs.4                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "33  | model.convs.4.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "39  | model.embedding_extra           | Linear              | 364    | [128, 6]                                  | [128, 52]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 104    | [128, 52]                                 | [128, 52]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 52]                                 | [128, 52]\n",
      "42  | model.conv_to_fc                | Linear              | 31.2 K | [128, 324]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 37.2 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.norms                     | ModuleList          | 768    | ?                                         | ?\n",
      "52  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "53  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "57  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "59  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "62  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "63  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "64  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "65  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "66  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "67  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "68  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "71  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "72  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "73  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "74  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "75  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "76  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "77  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "78  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "79  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "80  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "83  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "84  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "87  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "88  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "89  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "90  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "91  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "92  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "97  | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "100 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "102 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "105 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "107 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "110 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "112 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "115 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "117 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "120 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "122 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "125 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "127 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "130 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.585     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_34\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.9 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.585     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:24:33,278] Trial 36 failed with parameters: {'atom_fea_len': 272, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 5, 'lr_mult': 16, 'extra_fea_len': 52, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 460.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 202.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.63 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 2.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 96, in forward\n",
      "    nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 460.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 202.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.63 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 2.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:24:33,279] Trial 36 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 17\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 288\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=272, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((272,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=585, out_features=544, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=52, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=324, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-3): 4 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-3): 4 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-3): 4 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66981520>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66981c40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66981460>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66981fd0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66981640>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66981bb0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66981790>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 2.1 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 26.8 K | [2304, 92]                                | [2304, 288]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 576    | [2304, 288]                               | [2304, 288]\n",
      "3   | model.convs                     | ModuleList          | 1.8 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "5   | model.convs.0.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "11  | model.convs.1                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "12  | model.convs.1.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "18  | model.convs.2                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "19  | model.convs.2.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "25  | model.convs.3                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "26  | model.convs.3.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "32  | model.convs.4                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "33  | model.convs.4.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 33.1 K | [128, 344]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.382     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_35\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 17 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 2.1 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.382     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:24:42,838] Trial 37 failed with parameters: {'atom_fea_len': 288, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 17, 'extra_fea_len': 56, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacity of 22.03 GiB of which 132.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 20.99 GiB is allocated by PyTorch, and 489.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 91, in forward\n",
      "    total_gated_fea = self.bn1(total_gated_fea.view(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacity of 22.03 GiB of which 132.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 20.99 GiB is allocated by PyTorch, and 489.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:24:42,839] Trial 37 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 272\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=288, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=617, out_features=576, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=344, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef645934c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef64593a30>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef645932e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef64593940>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef64593a00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef64593c70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef64593ca0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.9 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 25.3 K | [2304, 92]                                | [2304, 272]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 544    | [2304, 272]                               | [2304, 272]\n",
      "3   | model.convs                     | ModuleList          | 1.6 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "5   | model.convs.0.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "11  | model.convs.1                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "12  | model.convs.1.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "18  | model.convs.2                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "19  | model.convs.2.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "25  | model.convs.3                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "26  | model.convs.3.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "32  | model.convs.4                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "33  | model.convs.4.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 31.6 K | [128, 328]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.624     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_36\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.9 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.624     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:25:09,409] Trial 38 failed with parameters: {'atom_fea_len': 272, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 56, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 450.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 278.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.55 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 2.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 96, in forward\n",
      "    nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 450.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 278.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.55 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 2.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:25:09,410] Trial 38 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 256\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.5\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=272, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((272,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=585, out_features=544, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=328, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef845575b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef845576a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84557790>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84557640>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84557160>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef845578e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef845579d0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.7 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 23.8 K | [2304, 92]                                | [2304, 256]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 512    | [2304, 256]                               | [2304, 256]\n",
      "3   | model.convs                     | ModuleList          | 1.4 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "5   | model.convs.0.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "11  | model.convs.1                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "12  | model.convs.1.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "18  | model.convs.2                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "19  | model.convs.2.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "25  | model.convs.3                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "26  | model.convs.3.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "32  | model.convs.4                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "33  | model.convs.4.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 30.0 K | [128, 312]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_37\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.7 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:25:25,730] Trial 39 failed with parameters: {'atom_fea_len': 256, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 56, 'dropout': 0.5} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 91, in forward\n",
      "    total_gated_fea = self.bn1(total_gated_fea.view(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:25:25,731] Trial 39 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 288\n",
      "extra_fea_len : 52\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=256, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=553, out_features=512, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=312, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07a00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07cd0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a077f0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07760>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07df0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07250>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a071f0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 2.1 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 26.8 K | [2304, 92]                                | [2304, 288]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 576    | [2304, 288]                               | [2304, 288]\n",
      "3   | model.convs                     | ModuleList          | 1.8 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "5   | model.convs.0.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "11  | model.convs.1                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "12  | model.convs.1.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "18  | model.convs.2                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "19  | model.convs.2.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "25  | model.convs.3                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "26  | model.convs.3.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "32  | model.convs.4                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "33  | model.convs.4.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "39  | model.embedding_extra           | Linear              | 364    | [128, 6]                                  | [128, 52]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 104    | [128, 52]                                 | [128, 52]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 52]                                 | [128, 52]\n",
      "42  | model.conv_to_fc                | Linear              | 32.7 K | [128, 340]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.380     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_38\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 2.1 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.380     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:25:36,368] Trial 40 failed with parameters: {'atom_fea_len': 288, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 52, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 496.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 234.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.60 GiB memory in use. Of the allocated memory 20.78 GiB is allocated by PyTorch, and 601.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 96, in forward\n",
      "    nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 496.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 234.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.60 GiB memory in use. Of the allocated memory 20.78 GiB is allocated by PyTorch, and 601.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:25:36,369] Trial 40 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 256\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=288, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=617, out_features=576, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=52, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=340, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef644e5b50>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef644e5b80>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef644e5cd0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef644e5280>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66970e50>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef669708e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef66970310>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.7 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 23.8 K | [2304, 92]                                | [2304, 256]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 512    | [2304, 256]                               | [2304, 256]\n",
      "3   | model.convs                     | ModuleList          | 1.4 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "5   | model.convs.0.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "11  | model.convs.1                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "12  | model.convs.1.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "18  | model.convs.2                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "19  | model.convs.2.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "25  | model.convs.3                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "26  | model.convs.3.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "32  | model.convs.4                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "33  | model.convs.4.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 30.0 K | [128, 312]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_39\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.7 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:25:53,509] Trial 41 failed with parameters: {'atom_fea_len': 256, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 56, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 91, in forward\n",
      "    total_gated_fea = self.bn1(total_gated_fea.view(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:25:53,510] Trial 41 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 17\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 288\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 80\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=256, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=553, out_features=512, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=312, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84179220>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84179ee0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef841798e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef841798b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84179280>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84179100>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef84179850>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 2.0 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80]]]\n",
      "1   | model.embedding_atom            | Linear              | 26.8 K | [2304, 92]                                | [2304, 288]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 576    | [2304, 288]                               | [2304, 288]\n",
      "3   | model.convs                     | ModuleList          | 1.8 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "5   | model.convs.0.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "11  | model.convs.1                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "12  | model.convs.1.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "18  | model.convs.2                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "19  | model.convs.2.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "25  | model.convs.3                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "26  | model.convs.3.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "32  | model.convs.4                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "33  | model.convs.4.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 27.6 K | [128, 344]                                | [128, 80]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 80]                                 | [128, 80]\n",
      "46  | model.fcs                       | ModuleList          | 32.4 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "48  | model.fcs.1                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "49  | model.fcs.2                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "50  | model.fcs.3                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "51  | model.fcs.4                     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "52  | model.norms                     | ModuleList          | 800    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 160    | [128, 80]                                 | [128, 80]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 80]                                 | [128, 80]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.2 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 81     | [128, 80]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 81     | [128, 80]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 324    | [128, 80]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 324    | [128, 80]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 324    | [128, 80]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 162    | [128, 80]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 162    | [128, 80]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 162    | [128, 80]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.1 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "93  | model.task_norms.1              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "94  | model.task_norms.2              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "95  | model.task_norms.3              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "96  | model.task_norms.4              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "97  | model.task_norms.5              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "98  | model.task_norms.6              | LayerNorm           | 160    | [128, 80]                                 | [128, 80]\n",
      "99  | model.task_attentions           | ModuleList          | 136 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "101 | model.task_attentions.0.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "102 | model.task_attentions.0.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "103 | model.task_attentions.0.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "106 | model.task_attentions.1.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "107 | model.task_attentions.1.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "108 | model.task_attentions.1.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "111 | model.task_attentions.2.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "112 | model.task_attentions.2.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "113 | model.task_attentions.2.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "116 | model.task_attentions.3.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "117 | model.task_attentions.3.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "118 | model.task_attentions.3.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "121 | model.task_attentions.4.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "122 | model.task_attentions.4.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "123 | model.task_attentions.4.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "126 | model.task_attentions.5.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "127 | model.task_attentions.5.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "128 | model.task_attentions.5.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 19.4 K | [128, 80]                                 | [128, 80]\n",
      "131 | model.task_attentions.6.query   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "132 | model.task_attentions.6.key     | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "133 | model.task_attentions.6.value   | Linear              | 6.5 K  | [128, 80]                                 | [128, 80]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.063     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_40\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 17 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 2.0 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80], [128, 80]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.063     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:26:11,809] Trial 42 failed with parameters: {'atom_fea_len': 288, 'h_fea_len': 80, 'n_conv': 5, 'n_h': 6, 'lr_mult': 17, 'extra_fea_len': 56, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 494.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 322.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.51 GiB memory in use. Of the allocated memory 20.74 GiB is allocated by PyTorch, and 555.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 96, in forward\n",
      "    nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 494.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 322.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.51 GiB memory in use. Of the allocated memory 20.74 GiB is allocated by PyTorch, and 555.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:26:11,810] Trial 42 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 256\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=288, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=617, out_features=576, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=344, out_features=80, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=80, out_features=80, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=80, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=80, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=80, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=80, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=80, out_features=80, bias=True)\n",
      "      (key): Linear(in_features=80, out_features=80, bias=True)\n",
      "      (value): Linear(in_features=80, out_features=80, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef845576a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07190>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07100>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07820>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a075b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a073a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65a07700>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.7 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 23.8 K | [2304, 92]                                | [2304, 256]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 512    | [2304, 256]                               | [2304, 256]\n",
      "3   | model.convs                     | ModuleList          | 1.4 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "5   | model.convs.0.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "11  | model.convs.1                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "12  | model.convs.1.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "18  | model.convs.2                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "19  | model.convs.2.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "25  | model.convs.3                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "26  | model.convs.3.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "32  | model.convs.4                   | ConvLayer           | 285 K  | [[2304, 256], [2304, 10, 41], [2304, 10]] | [2304, 256]\n",
      "33  | model.convs.4.fc_full           | Linear              | 283 K  | [2304, 10, 553]                           | [2304, 10, 512]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 256]                           | [2304, 10, 256]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.0 K  | [23040, 512]                              | [23040, 512]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 512    | [2304, 256]                               | [2304, 256]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 256]                               | [2304, 256]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 30.0 K | [128, 312]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_41\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.7 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.907     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:26:29,400] Trial 43 failed with parameters: {'atom_fea_len': 256, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 56, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 91, in forward\n",
      "    total_gated_fea = self.bn1(total_gated_fea.view(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 996.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 952.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.90 GiB memory in use. Of the allocated memory 19.02 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:26:29,401] Trial 43 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 15\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 288\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.45\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=256, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=553, out_features=512, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=312, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef7c1c6fa0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef7c1c6160>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef7c1c6a60>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef7c1c63a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef7c1c6b50>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef7c1c6dc0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef7c1c62b0>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 2.1 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 26.8 K | [2304, 92]                                | [2304, 288]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 576    | [2304, 288]                               | [2304, 288]\n",
      "3   | model.convs                     | ModuleList          | 1.8 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "5   | model.convs.0.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "11  | model.convs.1                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "12  | model.convs.1.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "18  | model.convs.2                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "19  | model.convs.2.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "25  | model.convs.3                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "26  | model.convs.3.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "32  | model.convs.4                   | ConvLayer           | 357 K  | [[2304, 288], [2304, 10, 41], [2304, 10]] | [2304, 288]\n",
      "33  | model.convs.4.fc_full           | Linear              | 355 K  | [2304, 10, 617]                           | [2304, 10, 576]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 288]                           | [2304, 10, 288]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.2 K  | [23040, 576]                              | [23040, 576]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 576    | [2304, 288]                               | [2304, 288]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 288]                               | [2304, 288]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                  | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                 | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                 | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 33.1 K | [128, 344]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.382     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 15 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 2.1 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.382     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:26:39,295] Trial 44 failed with parameters: {'atom_fea_len': 288, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 15, 'extra_fea_len': 56, 'dropout': 0.45} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacity of 22.03 GiB of which 132.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 20.99 GiB is allocated by PyTorch, and 489.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 91, in forward\n",
      "    total_gated_fea = self.bn1(total_gated_fea.view(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.08 GiB. GPU 0 has a total capacity of 22.03 GiB of which 132.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 20.99 GiB is allocated by PyTorch, and 489.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:26:39,296] Trial 44 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 272\n",
      "extra_fea_len : 52\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.8\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=288, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=617, out_features=576, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=56, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=344, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.45, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65e337c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65e33310>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65e331f0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65e33ac0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65e33f40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65e338e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65e33130>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                  | Out sizes\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 1.9 M  | ?                                         | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 25.3 K | [2304, 92]                                | [2304, 272]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 544    | [2304, 272]                               | [2304, 272]\n",
      "3   | model.convs                     | ModuleList          | 1.6 M  | ?                                         | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "5   | model.convs.0.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "11  | model.convs.1                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "12  | model.convs.1.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "18  | model.convs.2                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "19  | model.convs.2.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "25  | model.convs.3                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "26  | model.convs.3.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "32  | model.convs.4                   | ConvLayer           | 320 K  | [[2304, 272], [2304, 10, 41], [2304, 10]] | [2304, 272]\n",
      "33  | model.convs.4.fc_full           | Linear              | 318 K  | [2304, 10, 585]                           | [2304, 10, 544]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 272]                           | [2304, 10, 272]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 1.1 K  | [23040, 544]                              | [23040, 544]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 544    | [2304, 272]                               | [2304, 272]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 272]                               | [2304, 272]\n",
      "39  | model.embedding_extra           | Linear              | 364    | [128, 6]                                  | [128, 52]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 104    | [128, 52]                                 | [128, 52]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 52]                                 | [128, 52]\n",
      "42  | model.conv_to_fc                | Linear              | 31.2 K | [128, 324]                                | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                 | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                         | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                         | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                 | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                         | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                 | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                 | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                 | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                 | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                 | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                 | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                  | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                 | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                 | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                 | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                  | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                 | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                 | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                 | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                               | [128, 1, 1]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.623     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_43\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 1.9 M  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.623     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "[W 2025-12-03 21:26:54,702] Trial 45 failed with parameters: {'atom_fea_len': 272, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 52, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 524.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 144.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.69 GiB memory in use. Of the allocated memory 20.95 GiB is allocated by PyTorch, and 513.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py\", line 174, in objective\n",
      "    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py\", line 161, in main\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 532, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 571, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 980, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1023, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 355, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 219, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 188, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 266, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 146, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1276, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 161, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 231, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 116, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 516, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 81, in _use_grad\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py\", line 226, in step\n",
      "    loss = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 103, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 142, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 128, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 294, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 380, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 143, in training_step\n",
      "    loss = self._step(batch, batch_idx, split='train')\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py\", line 188, in _step\n",
      "    outputs, last_layer_feas = self.model(**batch)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py\", line 115, in forward\n",
      "    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py\", line 94, in forward\n",
      "    nbr_filter = self.sigmoid(nbr_filter)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 329, in forward\n",
      "    return torch.sigmoid(input)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 524.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 144.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.69 GiB memory in use. Of the allocated memory 20.95 GiB is allocated by PyTorch, and 513.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[W 2025-12-03 21:26:54,703] Trial 45 failed with value None.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].\n",
      "  warnings.warn(\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].\n",
      "  warnings.warn(\n",
      "Global seed set to 42\n",
      "final_train: False\n",
      "dl_sampler:  random\n",
      "prop_cols: ['Label']\n",
      "Number of TSD training data: 1555\n",
      "prop_cols: ['Label']\n",
      "Number of SSD training data: 1034\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water training data: 698\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 training data: 698\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid training data: 112\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base training data: 80\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling training data: 82\n",
      "Number of total training data: 4259\n",
      "prop_cols: ['Label']\n",
      "Number of TSD validation data: 388\n",
      "prop_cols: ['Label']\n",
      "Number of SSD validation data: 250\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water validation data: 175\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 validation data: 175\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid validation data: 28\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base validation data: 20\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling validation data: 24\n",
      "Number of total validation data: 1060\n",
      "prop_cols: ['Label']\n",
      "Number of TSD test data: 480\n",
      "prop_cols: ['Label']\n",
      "Number of SSD test data: 324\n",
      "prop_cols: ['water_label']\n",
      "Number of WS24_water test data: 219\n",
      "prop_cols: ['water4_label']\n",
      "Number of WS24_water4 test data: 219\n",
      "prop_cols: ['acid_label']\n",
      "Number of WS24_acid test data: 36\n",
      "prop_cols: ['base_label']\n",
      "Number of WS24_base test data: 24\n",
      "prop_cols: ['boiling_label']\n",
      "Number of WS24_boiling test data: 26\n",
      "Number of total test data: 1328\n",
      "##################################################args\n",
      "batch_size : 128\n",
      "num_workers : 14\n",
      "random_seed : 42\n",
      "accelerator : gpu\n",
      "devices : 1\n",
      "max_epochs : 500\n",
      "limit_train_batches : None\n",
      "limit_val_batches : None\n",
      "auto_lr_bs_find : False\n",
      "progress_bar : False\n",
      "focal_alpha : 0.25\n",
      "focal_gamma : 2\n",
      "optim : adam\n",
      "lr : 0.001\n",
      "weight_decay : 1e-05\n",
      "momentum : 0.9\n",
      "optim_config : fine\n",
      "group_lr : True\n",
      "lr_mult : 16\n",
      "lr_scheduler : reduce_on_plateau\n",
      "lr_decay_steps : 20\n",
      "lr_milestones : [10, 20, 30, 50]\n",
      "lr_decay_rate : 0.8\n",
      "lr_decay_min_lr : 1e-06\n",
      "max_steps : -1\n",
      "decay_power : 1\n",
      "warmup_steps : 2\n",
      "load_best : False\n",
      "load_dir : None\n",
      "load_ver : None\n",
      "load_v_num : None\n",
      "log_dir : logs\n",
      "patience : 50\n",
      "min_delta : 0.001\n",
      "monitor : val_Metric\n",
      "mode : max\n",
      "eval_freq : 10\n",
      "max_num_nbr : 10\n",
      "radius : 8\n",
      "dmin : 0\n",
      "step : 0.2\n",
      "use_cell_params : True\n",
      "use_extra_fea : False\n",
      "task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]\n",
      "augment : False\n",
      "max_sample_size : {'train': 2004, 'val': 501}\n",
      "model_name : att_cgcnn\n",
      "atom_fea_len : 64\n",
      "extra_fea_len : 56\n",
      "h_fea_len : 96\n",
      "n_conv : 5\n",
      "n_h : 6\n",
      "att_S : 64\n",
      "dropout_prob : 0.5\n",
      "att_pooling : False\n",
      "task_norm : True\n",
      "dwa_temp : 2.0\n",
      "dwa_alpha : 0.8\n",
      "atom_layer_norm : True\n",
      "task_att_type : self\n",
      "data_dir : ./data\n",
      "tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']\n",
      "task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "dl_sampler : random\n",
      "loss_aggregation : fixed_weight_sum\n",
      "model_cfg : att_cgcnn\n",
      "max_graph_len : 200\n",
      "reconstruct : False\n",
      "task_cfg : tsd_ssd_ws24\n",
      "pruning : False\n",
      "optuna_name : optuna\n",
      "dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>\n",
      "orig_extra_fea_len : 6\n",
      "orig_atom_fea_len : 92\n",
      "nbr_fea_len : 41\n",
      "model : CrystalGraphConvNet(\n",
      "  (embedding_atom): Linear(in_features=92, out_features=272, bias=True)\n",
      "  (embedding_atom_norm): LayerNorm((272,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0-4): 5 x ConvLayer(\n",
      "      (fc_full): Linear(in_features=585, out_features=544, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "      (softplus1): Softplus(beta=1.0, threshold=20.0)\n",
      "      (bn1): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (softplus2): Softplus(beta=1.0, threshold=20.0)\n",
      "    )\n",
      "  )\n",
      "  (embedding_extra): Linear(in_features=6, out_features=52, bias=True)\n",
      "  (embedding_extra_norm): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (conv_to_fc): Linear(in_features=324, out_features=96, bias=True)\n",
      "  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (fcs): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (softpluses): ModuleList(\n",
      "    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (fc_outs): ModuleList(\n",
      "    (0): OutputLayer(\n",
      "      (fc): Linear(in_features=96, out_features=1, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (3): OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=4, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "    (4-6): 3 x OutputLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=96, out_features=2, bias=True)\n",
      "        (1): LogSoftmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (task_norms): ModuleList(\n",
      "    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (task_attentions): ModuleList(\n",
      "    (0-6): 7 x SelfAttention(\n",
      "      (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65d04880>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65d04520>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65d04100>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65d04790>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65d04ac0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65d048b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x75ef65d04940>]\n",
      "ckpt_path : None\n",
      "strategy : auto\n",
      "##################################################args\n",
      "task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']\n",
      "    | Name                            | Type                | Params | In sizes                                 | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                           | CrystalGraphConvNet | 374 K  | ?                                        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "1   | model.embedding_atom            | Linear              | 6.0 K  | [2304, 92]                               | [2304, 64]\n",
      "2   | model.embedding_atom_norm       | LayerNorm           | 128    | [2304, 64]                               | [2304, 64]\n",
      "3   | model.convs                     | ModuleList          | 110 K  | ?                                        | ?\n",
      "4   | model.convs.0                   | ConvLayer           | 22.1 K | [[2304, 64], [2304, 10, 41], [2304, 10]] | [2304, 64]\n",
      "5   | model.convs.0.fc_full           | Linear              | 21.8 K | [2304, 10, 169]                          | [2304, 10, 128]\n",
      "6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "7   | model.convs.0.softplus1         | Softplus            | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "8   | model.convs.0.bn1               | BatchNorm1d         | 256    | [23040, 128]                             | [23040, 128]\n",
      "9   | model.convs.0.bn2               | BatchNorm1d         | 128    | [2304, 64]                               | [2304, 64]\n",
      "10  | model.convs.0.softplus2         | Softplus            | 0      | [2304, 64]                               | [2304, 64]\n",
      "11  | model.convs.1                   | ConvLayer           | 22.1 K | [[2304, 64], [2304, 10, 41], [2304, 10]] | [2304, 64]\n",
      "12  | model.convs.1.fc_full           | Linear              | 21.8 K | [2304, 10, 169]                          | [2304, 10, 128]\n",
      "13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "14  | model.convs.1.softplus1         | Softplus            | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "15  | model.convs.1.bn1               | BatchNorm1d         | 256    | [23040, 128]                             | [23040, 128]\n",
      "16  | model.convs.1.bn2               | BatchNorm1d         | 128    | [2304, 64]                               | [2304, 64]\n",
      "17  | model.convs.1.softplus2         | Softplus            | 0      | [2304, 64]                               | [2304, 64]\n",
      "18  | model.convs.2                   | ConvLayer           | 22.1 K | [[2304, 64], [2304, 10, 41], [2304, 10]] | [2304, 64]\n",
      "19  | model.convs.2.fc_full           | Linear              | 21.8 K | [2304, 10, 169]                          | [2304, 10, 128]\n",
      "20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "21  | model.convs.2.softplus1         | Softplus            | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "22  | model.convs.2.bn1               | BatchNorm1d         | 256    | [23040, 128]                             | [23040, 128]\n",
      "23  | model.convs.2.bn2               | BatchNorm1d         | 128    | [2304, 64]                               | [2304, 64]\n",
      "24  | model.convs.2.softplus2         | Softplus            | 0      | [2304, 64]                               | [2304, 64]\n",
      "25  | model.convs.3                   | ConvLayer           | 22.1 K | [[2304, 64], [2304, 10, 41], [2304, 10]] | [2304, 64]\n",
      "26  | model.convs.3.fc_full           | Linear              | 21.8 K | [2304, 10, 169]                          | [2304, 10, 128]\n",
      "27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "28  | model.convs.3.softplus1         | Softplus            | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "29  | model.convs.3.bn1               | BatchNorm1d         | 256    | [23040, 128]                             | [23040, 128]\n",
      "30  | model.convs.3.bn2               | BatchNorm1d         | 128    | [2304, 64]                               | [2304, 64]\n",
      "31  | model.convs.3.softplus2         | Softplus            | 0      | [2304, 64]                               | [2304, 64]\n",
      "32  | model.convs.4                   | ConvLayer           | 22.1 K | [[2304, 64], [2304, 10, 41], [2304, 10]] | [2304, 64]\n",
      "33  | model.convs.4.fc_full           | Linear              | 21.8 K | [2304, 10, 169]                          | [2304, 10, 128]\n",
      "34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "35  | model.convs.4.softplus1         | Softplus            | 0      | [2304, 10, 64]                           | [2304, 10, 64]\n",
      "36  | model.convs.4.bn1               | BatchNorm1d         | 256    | [23040, 128]                             | [23040, 128]\n",
      "37  | model.convs.4.bn2               | BatchNorm1d         | 128    | [2304, 64]                               | [2304, 64]\n",
      "38  | model.convs.4.softplus2         | Softplus            | 0      | [2304, 64]                               | [2304, 64]\n",
      "39  | model.embedding_extra           | Linear              | 392    | [128, 6]                                 | [128, 56]\n",
      "40  | model.embedding_extra_norm      | BatchNorm1d         | 112    | [128, 56]                                | [128, 56]\n",
      "41  | model.embedding_extra_softplus  | Softplus            | 0      | [128, 56]                                | [128, 56]\n",
      "42  | model.conv_to_fc                | Linear              | 11.6 K | [128, 120]                               | [128, 96]\n",
      "43  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [128, 96]                                | [128, 96]\n",
      "44  | model.conv_to_fc_softplus       | Softplus            | 0      | [128, 96]                                | [128, 96]\n",
      "45  | model.dropout                   | Dropout             | 0      | [128, 96]                                | [128, 96]\n",
      "46  | model.fcs                       | ModuleList          | 46.6 K | ?                                        | ?\n",
      "47  | model.fcs.0                     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "48  | model.fcs.1                     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "49  | model.fcs.2                     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "50  | model.fcs.3                     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "51  | model.fcs.4                     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "52  | model.norms                     | ModuleList          | 960    | ?                                        | ?\n",
      "53  | model.norms.0                   | BatchNorm1d         | 192    | [128, 96]                                | [128, 96]\n",
      "54  | model.norms.1                   | BatchNorm1d         | 192    | [128, 96]                                | [128, 96]\n",
      "55  | model.norms.2                   | BatchNorm1d         | 192    | [128, 96]                                | [128, 96]\n",
      "56  | model.norms.3                   | BatchNorm1d         | 192    | [128, 96]                                | [128, 96]\n",
      "57  | model.norms.4                   | BatchNorm1d         | 192    | [128, 96]                                | [128, 96]\n",
      "58  | model.softpluses                | ModuleList          | 0      | ?                                        | ?\n",
      "59  | model.softpluses.0              | Softplus            | 0      | [128, 96]                                | [128, 96]\n",
      "60  | model.softpluses.1              | Softplus            | 0      | [128, 96]                                | [128, 96]\n",
      "61  | model.softpluses.2              | Softplus            | 0      | [128, 96]                                | [128, 96]\n",
      "62  | model.softpluses.3              | Softplus            | 0      | [128, 96]                                | [128, 96]\n",
      "63  | model.softpluses.4              | Softplus            | 0      | [128, 96]                                | [128, 96]\n",
      "64  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                        | ?\n",
      "65  | model.fc_outs.0                 | OutputLayer         | 97     | [128, 96]                                | [128, 1]\n",
      "66  | model.fc_outs.0.fc              | Linear              | 97     | [128, 96]                                | [128, 1]\n",
      "67  | model.fc_outs.1                 | OutputLayer         | 194    | [128, 96]                                | [128, 2]\n",
      "68  | model.fc_outs.1.fc              | Sequential          | 194    | [128, 96]                                | [128, 2]\n",
      "69  | model.fc_outs.1.fc.0            | Linear              | 194    | [128, 96]                                | [128, 2]\n",
      "70  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "71  | model.fc_outs.2                 | OutputLayer         | 194    | [128, 96]                                | [128, 2]\n",
      "72  | model.fc_outs.2.fc              | Sequential          | 194    | [128, 96]                                | [128, 2]\n",
      "73  | model.fc_outs.2.fc.0            | Linear              | 194    | [128, 96]                                | [128, 2]\n",
      "74  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "75  | model.fc_outs.3                 | OutputLayer         | 388    | [128, 96]                                | [128, 4]\n",
      "76  | model.fc_outs.3.fc              | Sequential          | 388    | [128, 96]                                | [128, 4]\n",
      "77  | model.fc_outs.3.fc.0            | Linear              | 388    | [128, 96]                                | [128, 4]\n",
      "78  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [128, 4]                                 | [128, 4]\n",
      "79  | model.fc_outs.4                 | OutputLayer         | 194    | [128, 96]                                | [128, 2]\n",
      "80  | model.fc_outs.4.fc              | Sequential          | 194    | [128, 96]                                | [128, 2]\n",
      "81  | model.fc_outs.4.fc.0            | Linear              | 194    | [128, 96]                                | [128, 2]\n",
      "82  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "83  | model.fc_outs.5                 | OutputLayer         | 194    | [128, 96]                                | [128, 2]\n",
      "84  | model.fc_outs.5.fc              | Sequential          | 194    | [128, 96]                                | [128, 2]\n",
      "85  | model.fc_outs.5.fc.0            | Linear              | 194    | [128, 96]                                | [128, 2]\n",
      "86  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "87  | model.fc_outs.6                 | OutputLayer         | 194    | [128, 96]                                | [128, 2]\n",
      "88  | model.fc_outs.6.fc              | Sequential          | 194    | [128, 96]                                | [128, 2]\n",
      "89  | model.fc_outs.6.fc.0            | Linear              | 194    | [128, 96]                                | [128, 2]\n",
      "90  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [128, 2]                                 | [128, 2]\n",
      "91  | model.task_norms                | ModuleList          | 1.3 K  | ?                                        | ?\n",
      "92  | model.task_norms.0              | LayerNorm           | 192    | [128, 96]                                | [128, 96]\n",
      "93  | model.task_norms.1              | LayerNorm           | 192    | [128, 96]                                | [128, 96]\n",
      "94  | model.task_norms.2              | LayerNorm           | 192    | [128, 96]                                | [128, 96]\n",
      "95  | model.task_norms.3              | LayerNorm           | 192    | [128, 96]                                | [128, 96]\n",
      "96  | model.task_norms.4              | LayerNorm           | 192    | [128, 96]                                | [128, 96]\n",
      "97  | model.task_norms.5              | LayerNorm           | 192    | [128, 96]                                | [128, 96]\n",
      "98  | model.task_norms.6              | LayerNorm           | 192    | [128, 96]                                | [128, 96]\n",
      "99  | model.task_attentions           | ModuleList          | 195 K  | ?                                        | ?\n",
      "100 | model.task_attentions.0         | SelfAttention       | 27.9 K | [128, 96]                                | [128, 96]\n",
      "101 | model.task_attentions.0.query   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "102 | model.task_attentions.0.key     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "103 | model.task_attentions.0.value   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "104 | model.task_attentions.0.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "105 | model.task_attentions.1         | SelfAttention       | 27.9 K | [128, 96]                                | [128, 96]\n",
      "106 | model.task_attentions.1.query   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "107 | model.task_attentions.1.key     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "108 | model.task_attentions.1.value   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "109 | model.task_attentions.1.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "110 | model.task_attentions.2         | SelfAttention       | 27.9 K | [128, 96]                                | [128, 96]\n",
      "111 | model.task_attentions.2.query   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "112 | model.task_attentions.2.key     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "113 | model.task_attentions.2.value   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "114 | model.task_attentions.2.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "115 | model.task_attentions.3         | SelfAttention       | 27.9 K | [128, 96]                                | [128, 96]\n",
      "116 | model.task_attentions.3.query   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "117 | model.task_attentions.3.key     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "118 | model.task_attentions.3.value   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "119 | model.task_attentions.3.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "120 | model.task_attentions.4         | SelfAttention       | 27.9 K | [128, 96]                                | [128, 96]\n",
      "121 | model.task_attentions.4.query   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "122 | model.task_attentions.4.key     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "123 | model.task_attentions.4.value   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "124 | model.task_attentions.4.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "125 | model.task_attentions.5         | SelfAttention       | 27.9 K | [128, 96]                                | [128, 96]\n",
      "126 | model.task_attentions.5.query   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "127 | model.task_attentions.5.key     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "128 | model.task_attentions.5.value   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "129 | model.task_attentions.5.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "130 | model.task_attentions.6         | SelfAttention       | 27.9 K | [128, 96]                                | [128, 96]\n",
      "131 | model.task_attentions.6.query   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "132 | model.task_attentions.6.key     | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "133 | model.task_attentions.6.value   | Linear              | 9.3 K  | [128, 96]                                | [128, 96]\n",
      "134 | model.task_attentions.6.softmax | Softmax             | 0      | [128, 1, 1]                              | [128, 1, 1]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "374 K     Trainable params\n",
      "0         Non-trainable params\n",
      "374 K     Total params\n",
      "1.500     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "==================================================\n",
      "normal_decay\n",
      "['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']\n",
      "==================================================\n",
      "normal_no_decay\n",
      "['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']\n",
      "==================================================\n",
      "head_decay\n",
      "['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']\n",
      "==================================================\n",
      "head_no_decay\n",
      "['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']\n",
      "==================================================\n",
      "log_vars\n",
      "[]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using random sampler for training data.\n",
      "max_epochs: 500 | max_steps: 17000 | warmup_steps : 2 lr_mult : 16 | weight_decay : 1e-05 | decay_power : 1\n",
      "\n",
      "  | Name  | Type                | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | CrystalGraphConvNet | 374 K  | ?        | [[[128, 1], [128, 2], [128, 2], [128, 4], [128, 2], [128, 2], [128, 2]], [[128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96], [128, 96]]]\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "374 K     Trainable params\n",
      "0         Non-trainable params\n",
      "374 K     Total params\n",
      "1.500     Total estimated model params size (MB)\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(0): metric=0.3079 > best_metric=0.0000, log val results..\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "Epoch 0, global step 34: 'val_Metric' reached 0.30795 (best 0.30795), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=00-val_Metric=0.308.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(1): metric=0.3487 > best_metric=0.3079, log val results..\n",
      "Epoch 1, global step 68: 'val_Metric' reached 0.34875 (best 0.34875), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=01-val_Metric=0.349.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(2): metric=0.4201 > best_metric=0.3487, log val results..\n",
      "Epoch 2, global step 102: 'val_Metric' reached 0.42006 (best 0.42006), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=02-val_Metric=0.420.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(3): metric=0.4356 > best_metric=0.4201, log val results..\n",
      "Epoch 3, global step 136: 'val_Metric' reached 0.43556 (best 0.43556), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=03-val_Metric=0.436.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 4, global step 170: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 5, global step 204: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 6, global step 238: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(7): metric=0.4959 > best_metric=0.4356, log val results..\n",
      "Epoch 7, global step 272: 'val_Metric' reached 0.49591 (best 0.49591), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=07-val_Metric=0.496.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 8, global step 306: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(9): metric=0.5002 > best_metric=0.4959, log val results..\n",
      "Epoch 9, global step 340: 'val_Metric' reached 0.50020 (best 0.50020), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=09-val_Metric=0.500.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 10, global step 374: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(11): metric=0.5080 > best_metric=0.5002, log val results..\n",
      "Epoch 11, global step 408: 'val_Metric' reached 0.50804 (best 0.50804), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=11-val_Metric=0.508.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 12, global step 442: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 13, global step 476: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 14, global step 510: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 15, global step 544: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 16, global step 578: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(17): metric=0.5356 > best_metric=0.5080, log val results..\n",
      "Epoch 17, global step 612: 'val_Metric' reached 0.53557 (best 0.53557), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=17-val_Metric=0.536.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 18, global step 646: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 19, global step 680: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 20, global step 714: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 21, global step 748: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 22, global step 782: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 23, global step 816: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(24): metric=0.5391 > best_metric=0.5356, log val results..\n",
      "Epoch 24, global step 850: 'val_Metric' reached 0.53911 (best 0.53911), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=24-val_Metric=0.539.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 25, global step 884: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 26, global step 918: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 27, global step 952: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 28, global step 986: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 29, global step 1020: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 30, global step 1054: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 31, global step 1088: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 32, global step 1122: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 33, global step 1156: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 34, global step 1190: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 35, global step 1224: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 36, global step 1258: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 37, global step 1292: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 38, global step 1326: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 39, global step 1360: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(40): metric=0.5441 > best_metric=0.5391, log val results..\n",
      "Epoch 40, global step 1394: 'val_Metric' reached 0.54414 (best 0.54414), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=40-val_Metric=0.544.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 41, global step 1428: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 42, global step 1462: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 43, global step 1496: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 44, global step 1530: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 45, global step 1564: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 46, global step 1598: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 47, global step 1632: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 48, global step 1666: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 49, global step 1700: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 50, global step 1734: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 51, global step 1768: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 52, global step 1802: 'val_Metric' reached 0.54472 (best 0.54472), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=52-val_Metric=0.545.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 53, global step 1836: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 54, global step 1870: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 55, global step 1904: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 56, global step 1938: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 57, global step 1972: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 58, global step 2006: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 59, global step 2040: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 60, global step 2074: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 61, global step 2108: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 62, global step 2142: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 63, global step 2176: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 64, global step 2210: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(65): metric=0.5471 > best_metric=0.5441, log val results..\n",
      "Epoch 65, global step 2244: 'val_Metric' reached 0.54712 (best 0.54712), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=65-val_Metric=0.547.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(66): metric=0.5504 > best_metric=0.5471, log val results..\n",
      "Epoch 66, global step 2278: 'val_Metric' reached 0.55038 (best 0.55038), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=66-val_Metric=0.550.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 67, global step 2312: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 68, global step 2346: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 69, global step 2380: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 70, global step 2414: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(71): metric=0.5602 > best_metric=0.5504, log val results..\n",
      "Epoch 71, global step 2448: 'val_Metric' reached 0.56021 (best 0.56021), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=71-val_Metric=0.560.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 72, global step 2482: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 73, global step 2516: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 74, global step 2550: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 75, global step 2584: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 76, global step 2618: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 77, global step 2652: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 78, global step 2686: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 79, global step 2720: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 80, global step 2754: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 81, global step 2788: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 82, global step 2822: 'val_Metric' reached 0.56079 (best 0.56079), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=82-val_Metric=0.561.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 83, global step 2856: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 84, global step 2890: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 85, global step 2924: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 86, global step 2958: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 87, global step 2992: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 88, global step 3026: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 89, global step 3060: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 90, global step 3094: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 91, global step 3128: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 92, global step 3162: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 93, global step 3196: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 94, global step 3230: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 95, global step 3264: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 96, global step 3298: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 97, global step 3332: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 98, global step 3366: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 99, global step 3400: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 100, global step 3434: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 101, global step 3468: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 102, global step 3502: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "current_epoch(103): metric=0.5635 > best_metric=0.5602, log val results..\n",
      "Epoch 103, global step 3536: 'val_Metric' reached 0.56354 (best 0.56354), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=103-val_Metric=0.564.ckpt' as top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 104, global step 3570: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 105, global step 3604: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 106, global step 3638: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 107, global step 3672: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 108, global step 3706: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 109, global step 3740: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 110, global step 3774: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 111, global step 3808: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 112, global step 3842: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 113, global step 3876: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 114, global step 3910: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 115, global step 3944: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 116, global step 3978: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 117, global step 4012: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 118, global step 4046: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 119, global step 4080: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 120, global step 4114: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 121, global step 4148: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 122, global step 4182: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 123, global step 4216: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 124, global step 4250: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 125, global step 4284: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 126, global step 4318: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 127, global step 4352: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 128, global step 4386: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 129, global step 4420: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 130, global step 4454: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 131, global step 4488: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 132, global step 4522: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 133, global step 4556: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 134, global step 4590: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 135, global step 4624: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 136, global step 4658: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 137, global step 4692: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 138, global step 4726: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 139, global step 4760: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 140, global step 4794: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 141, global step 4828: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 142, global step 4862: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 143, global step 4896: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 144, global step 4930: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 145, global step 4964: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 146, global step 4998: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 147, global step 5032: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 148, global step 5066: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 149, global step 5100: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 150, global step 5134: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 151, global step 5168: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 152, global step 5202: 'val_Metric' was not in top 1\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 153, global step 5236: 'val_Metric' was not in top 1\n",
      "Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=103-val_Metric=0.564.ckpt\n",
      "##################################################best\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=103-val_Metric=0.564.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=103-val_Metric=0.564.ckpt\n",
      "Using no sampler for validation data.\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m           Validate metric           \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0            \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m       SSD/val_MulticlassAUROC       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7534701824188232         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/val_MulticlassAccuracy      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7163978815078735         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_MulticlassF1Score      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7163978815078735         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m SSD/val_MulticlassMatthewsCorrCoef  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.41651487350463867         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         SSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.592759370803833          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanAbsoluteError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         53.806068420410156         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m TSD/val_MeanAbsolutePercentageError \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.14407163858413696         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_MeanSquaredError       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          5453.6103515625           \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           TSD/val_R2Score           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.23811551928520203         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m         TSD/val_loss_epoch          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6868385076522827         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      TSD/val_loss_weight_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_acid/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6785714626312256         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6428571343421936         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6428571343421936         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.2981424033641815         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_acid/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.0384461879730225         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_base/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.07500000298023224         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/val_MulticlassAccuracy   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                0.5                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m                0.5                 \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/val_MulticlassMatthewsCorr\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        -0.2715441584587097         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_base/val_loss_epoch       \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         4.280521869659424          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_boiling/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5902777910232544         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6666666865348816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6666666865348816         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/val_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3535534143447876         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_boiling/val_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         3.726133346557617          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water/val_MulticlassAUROC    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5574365258216858         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8421874642372131         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_MulticlassF1Score   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8421874642372131         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/val_MulticlassMatthewsCor\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7101826667785645         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m      WS24_water/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.0158964395523071         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/val_loss_weight_epoch   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_water4/val_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7662608623504639         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/val_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6290596723556519         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6290596723556519         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/val_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m        0.42427337169647217         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water4/val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.7600154876708984         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/val_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m       val_MergedMetric_epoch        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5875674486160278         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m             val_Metric              \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5635437736940767         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m           val_loss_epoch            \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.7168283462524414         \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/val_loss : tensor(0.6868)\n",
      "TSD/val_loss_epoch : tensor(0.6868)\n",
      "TSD/val_loss_weight : tensor(2.5558)\n",
      "TSD/val_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/val_R2Score : tensor(0.2381)\n",
      "TSD/val_MeanAbsoluteError : tensor(53.8061)\n",
      "TSD/val_MeanAbsolutePercentageError : tensor(0.1441)\n",
      "TSD/val_MeanSquaredError : tensor(5453.6104)\n",
      "val_loss : tensor(2.7168)\n",
      "val_loss_epoch : tensor(2.7168)\n",
      "val_MergedMetric : tensor(0.5876)\n",
      "val_MergedMetric_epoch : tensor(0.5876)\n",
      "SSD/val_loss : tensor(1.5928)\n",
      "SSD/val_loss_epoch : tensor(1.5928)\n",
      "SSD/val_loss_weight : tensor(1.6995)\n",
      "SSD/val_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/val_MulticlassAccuracy : tensor(0.7164)\n",
      "SSD/val_MulticlassMatthewsCorrCoef : tensor(0.4165)\n",
      "SSD/val_MulticlassF1Score : tensor(0.7164)\n",
      "SSD/val_MulticlassAUROC : tensor(0.7535)\n",
      "WS24_water/val_loss : tensor(1.0159)\n",
      "WS24_water/val_loss_epoch : tensor(1.0159)\n",
      "WS24_water/val_loss_weight : tensor(1.1472)\n",
      "WS24_water/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/val_MulticlassAccuracy : tensor(0.8422)\n",
      "WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.7102)\n",
      "WS24_water/val_MulticlassF1Score : tensor(0.8422)\n",
      "WS24_water/val_MulticlassAUROC : tensor(0.5574)\n",
      "WS24_water4/val_loss : tensor(2.7600)\n",
      "WS24_water4/val_loss_epoch : tensor(2.7600)\n",
      "WS24_water4/val_loss_weight : tensor(1.1472)\n",
      "WS24_water4/val_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/val_MulticlassAccuracy : tensor(0.6291)\n",
      "WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.4243)\n",
      "WS24_water4/val_MulticlassF1Score : tensor(0.6291)\n",
      "WS24_water4/val_MulticlassAUROC : tensor(0.7663)\n",
      "WS24_acid/val_loss : tensor(3.0384)\n",
      "WS24_acid/val_loss_epoch : tensor(3.0384)\n",
      "WS24_acid/val_loss_weight : tensor(0.1841)\n",
      "WS24_acid/val_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/val_MulticlassAccuracy : tensor(0.6429)\n",
      "WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.2981)\n",
      "WS24_acid/val_MulticlassF1Score : tensor(0.6429)\n",
      "WS24_acid/val_MulticlassAUROC : tensor(0.6786)\n",
      "WS24_base/val_loss : tensor(4.2805)\n",
      "WS24_base/val_loss_epoch : tensor(4.2805)\n",
      "WS24_base/val_loss_weight : tensor(0.1315)\n",
      "WS24_base/val_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/val_MulticlassAccuracy : tensor(0.5000)\n",
      "WS24_base/val_MulticlassMatthewsCorrCoef : tensor(-0.2715)\n",
      "WS24_base/val_MulticlassF1Score : tensor(0.5000)\n",
      "WS24_base/val_MulticlassAUROC : tensor(0.0750)\n",
      "WS24_boiling/val_loss : tensor(3.7261)\n",
      "WS24_boiling/val_loss_epoch : tensor(3.7261)\n",
      "WS24_boiling/val_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/val_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/val_MulticlassAccuracy : tensor(0.6667)\n",
      "WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.3536)\n",
      "WS24_boiling/val_MulticlassF1Score : tensor(0.6667)\n",
      "WS24_boiling/val_MulticlassAUROC : tensor(0.5903)\n",
      "val_Metric : tensor(0.5635, dtype=torch.float64)\n",
      "Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=103-val_Metric=0.564.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_44/checkpoints/best-epoch=103-val_Metric=0.564.ckpt\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\u001b[1m \u001b[0m\u001b[1m            Test metric             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m            DataLoader 0             \u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "\u001b[36m \u001b[0m\u001b[36m      SSD/test_MulticlassAUROC      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7384626865386963          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    SSD/test_MulticlassAccuracy     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7061631679534912          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_MulticlassF1Score     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7061631679534912          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mSSD/test_MulticlassMatthewsCorrCoef \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.3562229871749878          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        SSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.4720425605773926          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     SSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6994599103927612          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanAbsoluteError     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          49.17760467529297          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mTSD/test_MeanAbsolutePercentageError\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.1483585387468338          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_MeanSquaredError      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          4341.39111328125           \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          TSD/test_R2Score          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.39257562160491943         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m        TSD/test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5467634201049805          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     TSD/test_loss_weight_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5557641983032227          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_acid/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          0.854938268661499          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_acid/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7777777910232544          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7777777910232544          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_acid/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          0.55901700258255           \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_acid/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          1.613312005996704          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_acid/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.18408076465129852         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m   WS24_base/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4124999940395355          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_base/test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6590908765792847          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6590908765792847          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_base/test_MulticlassMatthewsCo\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.32499998807907104         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_base/test_loss_epoch      \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1148700714111328          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_base/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13148626685142517         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_boiling/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7514793276786804          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassAccuracy\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6538461446762085          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6538461446762085          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_MulticlassMatthew\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.30860671401023865         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_boiling/test_loss_epoch    \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         2.5649781227111816          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_boiling/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.13477341830730438         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water/test_MulticlassAUROC   \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.7842771410942078          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6956093311309814          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_MulticlassF1Score  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.6956093311309814          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water/test_MulticlassMatthewsC\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.4016405940055847          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m     WS24_water/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.6668710708618164          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water/test_loss_weight_epoch  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m  WS24_water4/test_MulticlassAUROC  \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.8072141408920288          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassAccuracy \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5763020515441895          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_MulticlassF1Score \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5763020515441895          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36mWS24_water4/test_MulticlassMatthews\u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.34393376111984253         \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m    WS24_water4/test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          4.848077297210693          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m WS24_water4/test_loss_weight_epoch \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         1.1472176313400269          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m            test_Metric             \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m         0.5597776077205666          \u001b[0m\u001b[35m \u001b[0m\n",
      "\u001b[36m \u001b[0m\u001b[36m          test_loss_epoch           \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          3.367461919784546          \u001b[0m\u001b[35m \u001b[0m\n",
      "\n",
      "TSD/test_loss : tensor(0.5468)\n",
      "TSD/test_loss_epoch : tensor(0.5468)\n",
      "TSD/test_loss_weight : tensor(2.5558)\n",
      "TSD/test_loss_weight_epoch : tensor(2.5558)\n",
      "TSD/test_R2Score : tensor(0.3926)\n",
      "TSD/test_MeanAbsoluteError : tensor(49.1776)\n",
      "TSD/test_MeanAbsolutePercentageError : tensor(0.1484)\n",
      "TSD/test_MeanSquaredError : tensor(4341.3911)\n",
      "test_loss : tensor(3.3675)\n",
      "test_loss_epoch : tensor(3.3675)\n",
      "SSD/test_loss : tensor(1.4720)\n",
      "SSD/test_loss_epoch : tensor(1.4720)\n",
      "SSD/test_loss_weight : tensor(1.6995)\n",
      "SSD/test_loss_weight_epoch : tensor(1.6995)\n",
      "SSD/test_MulticlassAccuracy : tensor(0.7062)\n",
      "SSD/test_MulticlassMatthewsCorrCoef : tensor(0.3562)\n",
      "SSD/test_MulticlassF1Score : tensor(0.7062)\n",
      "SSD/test_MulticlassAUROC : tensor(0.7385)\n",
      "WS24_water/test_loss : tensor(1.6669)\n",
      "WS24_water/test_loss_epoch : tensor(1.6669)\n",
      "WS24_water/test_loss_weight : tensor(1.1472)\n",
      "WS24_water/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water/test_MulticlassAccuracy : tensor(0.6956)\n",
      "WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4016)\n",
      "WS24_water/test_MulticlassF1Score : tensor(0.6956)\n",
      "WS24_water/test_MulticlassAUROC : tensor(0.7843)\n",
      "WS24_water4/test_loss : tensor(4.8481)\n",
      "WS24_water4/test_loss_epoch : tensor(4.8481)\n",
      "WS24_water4/test_loss_weight : tensor(1.1472)\n",
      "WS24_water4/test_loss_weight_epoch : tensor(1.1472)\n",
      "WS24_water4/test_MulticlassAccuracy : tensor(0.5763)\n",
      "WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3439)\n",
      "WS24_water4/test_MulticlassF1Score : tensor(0.5763)\n",
      "WS24_water4/test_MulticlassAUROC : tensor(0.8072)\n",
      "WS24_acid/test_loss : tensor(1.6133)\n",
      "WS24_acid/test_loss_epoch : tensor(1.6133)\n",
      "WS24_acid/test_loss_weight : tensor(0.1841)\n",
      "WS24_acid/test_loss_weight_epoch : tensor(0.1841)\n",
      "WS24_acid/test_MulticlassAccuracy : tensor(0.7778)\n",
      "WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.5590)\n",
      "WS24_acid/test_MulticlassF1Score : tensor(0.7778)\n",
      "WS24_acid/test_MulticlassAUROC : tensor(0.8549)\n",
      "WS24_base/test_loss : tensor(1.1149)\n",
      "WS24_base/test_loss_epoch : tensor(1.1149)\n",
      "WS24_base/test_loss_weight : tensor(0.1315)\n",
      "WS24_base/test_loss_weight_epoch : tensor(0.1315)\n",
      "WS24_base/test_MulticlassAccuracy : tensor(0.6591)\n",
      "WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.3250)\n",
      "WS24_base/test_MulticlassF1Score : tensor(0.6591)\n",
      "WS24_base/test_MulticlassAUROC : tensor(0.4125)\n",
      "WS24_boiling/test_loss : tensor(2.5650)\n",
      "WS24_boiling/test_loss_epoch : tensor(2.5650)\n",
      "WS24_boiling/test_loss_weight : tensor(0.1348)\n",
      "WS24_boiling/test_loss_weight_epoch : tensor(0.1348)\n",
      "WS24_boiling/test_MulticlassAccuracy : tensor(0.6538)\n",
      "WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.3086)\n",
      "WS24_boiling/test_MulticlassF1Score : tensor(0.6538)\n",
      "WS24_boiling/test_MulticlassAUROC : tensor(0.7515)\n",
      "test_Metric : tensor(0.5598, dtype=torch.float64)\n",
      "[I 2025-12-03 22:04:51,802] Trial 46 finished with value: 0.5492861115241812 and parameters: {'atom_fea_len': 64, 'h_fea_len': 96, 'n_conv': 5, 'n_h': 6, 'lr_mult': 16, 'extra_fea_len': 56, 'dropout': 0.5}. Best is trial 46 with value: 0.5492861115241812.\n",
      "Number of finished trials: 47\n",
      "Best trial:\n",
      "  Value: 0.5492861115241812\n",
      "  Params:\n",
      "    atom_fea_len: 64\n",
      "    h_fea_len: 96\n",
      "    n_conv: 5\n",
      "    n_h: 6\n",
      "    lr_mult: 16\n",
      "    extra_fea_len: 56\n",
      "    dropout: 0.5\n",
      "Training completed with return code: 0\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "work_dir = Path(\"./CGCNN_MT\").absolute()\n",
    "\n",
    "task_configs = [\n",
    "    \"tsd_ssd_ws24\",\n",
    "]\n",
    "\n",
    "model_configs = [\n",
    "    \"att_cgcnn\",\n",
    "]\n",
    "\n",
    "py_executor = \"hyperopt.py\"\n",
    "\n",
    "model_conf = {\n",
    "    'batch_size': 32,\n",
    "    'max_epochs': 500,\n",
    "    'max_graph_len': 200,\n",
    "    'atom_fea_len': 256,\n",
    "    'extra_fea_len': 16,\n",
    "    'h_fea_len': 128,\n",
    "    'n_conv': 6,\n",
    "    'n_h': 4,\n",
    "    'dropout_prob': 0.5,\n",
    "    'use_extra_fea': False,\n",
    "    'use_cell_params': True,\n",
    "    'atom_layer_norm': True,\n",
    "    'loss_aggregation': \"fixed_weight_sum\",\n",
    "    'dl_sampler': 'random',\n",
    "    'task_att_type': 'self',\n",
    "    'augment': False,\n",
    "    'lr': 0.001,\n",
    "    'lr_mult': 10,\n",
    "    'group_lr': True,\n",
    "    'optim_config': \"fine\",\n",
    "    'auto_lr_bs_find': False,\n",
    "    'patience': 50,\n",
    "    'task_norm': True,\n",
    "    'log_dir': \"logs\",\n",
    "    'optuna_name': \"optuna\",\n",
    "}\n",
    "\n",
    "# Use many workers to exploit CPUs (but not all, keep a couple free)\n",
    "num_workers = max(10, multiprocessing.cpu_count() - 2)\n",
    "\n",
    "for task_config in task_configs:\n",
    "    for model_config in model_configs:\n",
    "        job_name = f\"{task_config.replace('_config', '')}_{model_config.replace('_config', '')}\"\n",
    "        if py_executor == \"hyperopt.py\":\n",
    "            job_name = \"opt_\" + job_name\n",
    "\n",
    "        # Build the command line: python hyperopt.py --progress_bar ...\n",
    "        cmd = [\n",
    "            \"python\",\n",
    "            \"-u\",\n",
    "            py_executor,\n",
    "            \"--progress_bar\",\n",
    "            \"--task_cfg\",\n",
    "            task_config,\n",
    "            \"--model_cfg\",\n",
    "            model_config,\n",
    "            \"--num_workers\",\n",
    "            str(num_workers),\n",
    "        ]\n",
    "\n",
    "        # Append model_conf as CLI args\n",
    "        for key, value in model_conf.items():\n",
    "            cli_key = f\"--{key}\"\n",
    "            if isinstance(value, bool):\n",
    "                if value:\n",
    "                    cmd.append(cli_key)\n",
    "                continue\n",
    "            cmd.extend([cli_key, str(value)])\n",
    "\n",
    "        print(\"Launching:\", \" \".join(cmd))\n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            cwd=str(work_dir),\n",
    "            env=os.environ.copy(),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "        )\n",
    "\n",
    "        # Stream output live (training logs will appear here)\n",
    "        while True:\n",
    "            line = process.stdout.readline()\n",
    "            if not line and process.poll() is not None:\n",
    "                break\n",
    "            if line:\n",
    "                print(line.decode().rstrip())\n",
    "\n",
    "        print(f\"Training completed with return code: {process.returncode}\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mofsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
