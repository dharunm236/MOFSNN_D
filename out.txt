Launching: python -u hyperopt.py --progress_bar --task_cfg tsd_ssd_ws24 --model_cfg att_cgcnn --num_workers 14 --batch_size 256 --max_epochs 500 --max_graph_len 200 --atom_fea_len 256 --extra_fea_len 16 --h_fea_len 128 --n_conv 6 --n_h 4 --dropout_prob 0.5 --use_cell_params --atom_layer_norm --loss_aggregation fixed_weight_sum --dl_sampler random --task_att_type self --lr 0.001 --lr_mult 10 --group_lr --optim_config fine --patience 50 --task_norm --log_dir logs --optuna_name optuna
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/lightning_fabric/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  __import__("pkg_resources").declare_namespace(__name__)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
2025-12-03 14:22:56.907929: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-12-03 14:22:56.979736: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-12-03 14:22:58.562714: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[I 2025-12-03 14:23:00,415] Using an existing study with name 'tsd_ssd_ws24_att_cgcnn_fixed_weight_sum' instead of creating a new one.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 8
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : None
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 32
extra_fea_len : 40
h_fea_len : 208
n_conv : 2
n_h : 1
att_S : 64
dropout_prob : 0.15000000000000002
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
Using task_weights from trainset: [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
   | Name                            | Type                | Params | In sizes                                 | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0  | model                           | CrystalGraphConvNet | 951 K  | ?                                        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 208], [256, 208], [256, 208], [256, 208], [256, 208], [256, 208], [256, 208]]]
1  | model.embedding_atom            | Linear              | 3.0 K  | [4608, 92]                               | [4608, 32]
2  | model.embedding_atom_norm       | LayerNorm           | 64     | [4608, 32]                               | [4608, 32]
3  | model.convs                     | ModuleList          | 14.0 K | ?                                        | ?
4  | model.convs.0                   | ConvLayer           | 7.0 K  | [[4608, 32], [4608, 10, 41], [4608, 10]] | [4608, 32]
5  | model.convs.0.fc_full           | Linear              | 6.8 K  | [4608, 10, 105]                          | [4608, 10, 64]
6  | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 32]                           | [4608, 10, 32]
7  | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 32]                           | [4608, 10, 32]
8  | model.convs.0.bn1               | BatchNorm1d         | 128    | [46080, 64]                              | [46080, 64]
9  | model.convs.0.bn2               | BatchNorm1d         | 64     | [4608, 32]                               | [4608, 32]
10 | model.convs.0.softplus2         | Softplus            | 0      | [4608, 32]                               | [4608, 32]
11 | model.convs.1                   | ConvLayer           | 7.0 K  | [[4608, 32], [4608, 10, 41], [4608, 10]] | [4608, 32]
12 | model.convs.1.fc_full           | Linear              | 6.8 K  | [4608, 10, 105]                          | [4608, 10, 64]
13 | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 32]                           | [4608, 10, 32]
14 | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 32]                           | [4608, 10, 32]
15 | model.convs.1.bn1               | BatchNorm1d         | 128    | [46080, 64]                              | [46080, 64]
16 | model.convs.1.bn2               | BatchNorm1d         | 64     | [4608, 32]                               | [4608, 32]
17 | model.convs.1.softplus2         | Softplus            | 0      | [4608, 32]                               | [4608, 32]
18 | model.embedding_extra           | Linear              | 280    | [256, 6]                                 | [256, 40]
19 | model.embedding_extra_norm      | BatchNorm1d         | 80     | [256, 40]                                | [256, 40]
20 | model.embedding_extra_softplus  | Softplus            | 0      | [256, 40]                                | [256, 40]
21 | model.conv_to_fc                | Linear              | 15.2 K | [256, 72]                                | [256, 208]
22 | model.conv_to_fc_norm           | BatchNorm1d         | 416    | [256, 208]                               | [256, 208]
23 | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 208]                               | [256, 208]
24 | model.dropout                   | Dropout             | 0      | [256, 208]                               | [256, 208]
25 | model.fc_outs                   | ModuleList          | 3.1 K  | ?                                        | ?
26 | model.fc_outs.0                 | OutputLayer         | 209    | [256, 208]                               | [256, 1]
27 | model.fc_outs.0.fc              | Linear              | 209    | [256, 208]                               | [256, 1]
28 | model.fc_outs.1                 | OutputLayer         | 418    | [256, 208]                               | [256, 2]
29 | model.fc_outs.1.fc              | Sequential          | 418    | [256, 208]                               | [256, 2]
30 | model.fc_outs.1.fc.0            | Linear              | 418    | [256, 208]                               | [256, 2]
31 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
32 | model.fc_outs.2                 | OutputLayer         | 418    | [256, 208]                               | [256, 2]
33 | model.fc_outs.2.fc              | Sequential          | 418    | [256, 208]                               | [256, 2]
34 | model.fc_outs.2.fc.0            | Linear              | 418    | [256, 208]                               | [256, 2]
35 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
36 | model.fc_outs.3                 | OutputLayer         | 836    | [256, 208]                               | [256, 4]
37 | model.fc_outs.3.fc              | Sequential          | 836    | [256, 208]                               | [256, 4]
38 | model.fc_outs.3.fc.0            | Linear              | 836    | [256, 208]                               | [256, 4]
39 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                 | [256, 4]
40 | model.fc_outs.4                 | OutputLayer         | 418    | [256, 208]                               | [256, 2]
41 | model.fc_outs.4.fc              | Sequential          | 418    | [256, 208]                               | [256, 2]
42 | model.fc_outs.4.fc.0            | Linear              | 418    | [256, 208]                               | [256, 2]
43 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
44 | model.fc_outs.5                 | OutputLayer         | 418    | [256, 208]                               | [256, 2]
45 | model.fc_outs.5.fc              | Sequential          | 418    | [256, 208]                               | [256, 2]
46 | model.fc_outs.5.fc.0            | Linear              | 418    | [256, 208]                               | [256, 2]
47 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
48 | model.fc_outs.6                 | OutputLayer         | 418    | [256, 208]                               | [256, 2]
49 | model.fc_outs.6.fc              | Sequential          | 418    | [256, 208]                               | [256, 2]
50 | model.fc_outs.6.fc.0            | Linear              | 418    | [256, 208]                               | [256, 2]
51 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
52 | model.task_norms                | ModuleList          | 2.9 K  | ?                                        | ?
53 | model.task_norms.0              | LayerNorm           | 416    | [256, 208]                               | [256, 208]
54 | model.task_norms.1              | LayerNorm           | 416    | [256, 208]                               | [256, 208]
55 | model.task_norms.2              | LayerNorm           | 416    | [256, 208]                               | [256, 208]
56 | model.task_norms.3              | LayerNorm           | 416    | [256, 208]                               | [256, 208]
57 | model.task_norms.4              | LayerNorm           | 416    | [256, 208]                               | [256, 208]
58 | model.task_norms.5              | LayerNorm           | 416    | [256, 208]                               | [256, 208]
59 | model.task_norms.6              | LayerNorm           | 416    | [256, 208]                               | [256, 208]
60 | model.task_attentions           | ModuleList          | 912 K  | ?                                        | ?
61 | model.task_attentions.0         | SelfAttention       | 130 K  | [256, 208]                               | [256, 208]
62 | model.task_attentions.0.query   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
63 | model.task_attentions.0.key     | Linear              | 43.5 K | [256, 208]                               | [256, 208]
64 | model.task_attentions.0.value   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
65 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
66 | model.task_attentions.1         | SelfAttention       | 130 K  | [256, 208]                               | [256, 208]
67 | model.task_attentions.1.query   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
68 | model.task_attentions.1.key     | Linear              | 43.5 K | [256, 208]                               | [256, 208]
69 | model.task_attentions.1.value   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
70 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
71 | model.task_attentions.2         | SelfAttention       | 130 K  | [256, 208]                               | [256, 208]
72 | model.task_attentions.2.query   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
73 | model.task_attentions.2.key     | Linear              | 43.5 K | [256, 208]                               | [256, 208]
74 | model.task_attentions.2.value   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
75 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
76 | model.task_attentions.3         | SelfAttention       | 130 K  | [256, 208]                               | [256, 208]
77 | model.task_attentions.3.query   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
78 | model.task_attentions.3.key     | Linear              | 43.5 K | [256, 208]                               | [256, 208]
79 | model.task_attentions.3.value   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
80 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
81 | model.task_attentions.4         | SelfAttention       | 130 K  | [256, 208]                               | [256, 208]
82 | model.task_attentions.4.query   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
83 | model.task_attentions.4.key     | Linear              | 43.5 K | [256, 208]                               | [256, 208]
84 | model.task_attentions.4.value   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
85 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
86 | model.task_attentions.5         | SelfAttention       | 130 K  | [256, 208]                               | [256, 208]
87 | model.task_attentions.5.query   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
88 | model.task_attentions.5.key     | Linear              | 43.5 K | [256, 208]                               | [256, 208]
89 | model.task_attentions.5.value   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
90 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
91 | model.task_attentions.6         | SelfAttention       | 130 K  | [256, 208]                               | [256, 208]
92 | model.task_attentions.6.query   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
93 | model.task_attentions.6.key     | Linear              | 43.5 K | [256, 208]                               | [256, 208]
94 | model.task_attentions.6.value   | Linear              | 43.5 K | [256, 208]                               | [256, 208]
95 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
951 K     Trainable params
0         Non-trainable params
951 K     Total params
3.808     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 8 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 951 K  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 208], [256, 208], [256, 208], [256, 208], [256, 208], [256, 208], [256, 208]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
951 K     Trainable params
0         Non-trainable params
951 K     Total params
3.808     Total estimated model params size (MB)
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(0): metric=0.2842 > best_metric=0.0000, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Epoch 0, global step 17: 'val_Metric' reached 0.28422 (best 0.28422), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=00-val_Metric=0.284.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 1, global step 34: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 2, global step 51: 'val_Metric' reached 0.28433 (best 0.28433), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=02-val_Metric=0.284.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(3): metric=0.2967 > best_metric=0.2842, log val results..
Epoch 3, global step 68: 'val_Metric' reached 0.29673 (best 0.29673), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=03-val_Metric=0.297.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(4): metric=0.3431 > best_metric=0.2967, log val results..
Epoch 4, global step 85: 'val_Metric' reached 0.34310 (best 0.34310), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=04-val_Metric=0.343.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(5): metric=0.3809 > best_metric=0.3431, log val results..
Epoch 5, global step 102: 'val_Metric' reached 0.38091 (best 0.38091), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=05-val_Metric=0.381.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(6): metric=0.3970 > best_metric=0.3809, log val results..
Epoch 6, global step 119: 'val_Metric' reached 0.39700 (best 0.39700), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=06-val_Metric=0.397.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(7): metric=0.4156 > best_metric=0.3970, log val results..
Epoch 7, global step 136: 'val_Metric' reached 0.41559 (best 0.41559), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=07-val_Metric=0.416.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(8): metric=0.4322 > best_metric=0.4156, log val results..
Epoch 8, global step 153: 'val_Metric' reached 0.43225 (best 0.43225), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=08-val_Metric=0.432.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 9, global step 170: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(10): metric=0.4352 > best_metric=0.4322, log val results..
Epoch 10, global step 187: 'val_Metric' reached 0.43523 (best 0.43523), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=10-val_Metric=0.435.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(11): metric=0.4512 > best_metric=0.4352, log val results..
Epoch 11, global step 204: 'val_Metric' reached 0.45119 (best 0.45119), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=11-val_Metric=0.451.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(12): metric=0.4642 > best_metric=0.4512, log val results..
Epoch 12, global step 221: 'val_Metric' reached 0.46419 (best 0.46419), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=12-val_Metric=0.464.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 13, global step 238: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 14, global step 255: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(15): metric=0.4721 > best_metric=0.4642, log val results..
Epoch 15, global step 272: 'val_Metric' reached 0.47213 (best 0.47213), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=15-val_Metric=0.472.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(16): metric=0.4755 > best_metric=0.4721, log val results..
Epoch 16, global step 289: 'val_Metric' reached 0.47551 (best 0.47551), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=16-val_Metric=0.476.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(17): metric=0.4883 > best_metric=0.4755, log val results..
Epoch 17, global step 306: 'val_Metric' reached 0.48833 (best 0.48833), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=17-val_Metric=0.488.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 18, global step 323: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 19, global step 340: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(20): metric=0.4946 > best_metric=0.4883, log val results..
Epoch 20, global step 357: 'val_Metric' reached 0.49461 (best 0.49461), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=20-val_Metric=0.495.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 21, global step 374: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(22): metric=0.4986 > best_metric=0.4946, log val results..
Epoch 22, global step 391: 'val_Metric' reached 0.49860 (best 0.49860), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=22-val_Metric=0.499.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 23, global step 408: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 24, global step 425: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 25, global step 442: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(26): metric=0.5036 > best_metric=0.4986, log val results..
Epoch 26, global step 459: 'val_Metric' reached 0.50356 (best 0.50356), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=26-val_Metric=0.504.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 27, global step 476: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 28, global step 493: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 29, global step 510: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 30, global step 527: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 31, global step 544: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 32, global step 561: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 33, global step 578: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 34, global step 595: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(35): metric=0.5225 > best_metric=0.5036, log val results..
Epoch 35, global step 612: 'val_Metric' reached 0.52248 (best 0.52248), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=35-val_Metric=0.522.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 36, global step 629: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 37, global step 646: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 38, global step 663: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 39, global step 680: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 40, global step 697: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 41, global step 714: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 42, global step 731: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 43, global step 748: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 44, global step 765: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 45, global step 782: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(46): metric=0.5277 > best_metric=0.5225, log val results..
Epoch 46, global step 799: 'val_Metric' reached 0.52774 (best 0.52774), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=46-val_Metric=0.528.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 47, global step 816: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(48): metric=0.5297 > best_metric=0.5277, log val results..
Epoch 48, global step 833: 'val_Metric' reached 0.52975 (best 0.52975), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=48-val_Metric=0.530.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 49, global step 850: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 50, global step 867: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 51, global step 884: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 52, global step 901: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(53): metric=0.5350 > best_metric=0.5297, log val results..
Epoch 53, global step 918: 'val_Metric' reached 0.53505 (best 0.53505), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=53-val_Metric=0.535.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 54, global step 935: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 55, global step 952: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 56, global step 969: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(57): metric=0.5443 > best_metric=0.5350, log val results..
Epoch 57, global step 986: 'val_Metric' reached 0.54430 (best 0.54430), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=57-val_Metric=0.544.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 58, global step 1003: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 59, global step 1020: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 60, global step 1037: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 61, global step 1054: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 62, global step 1071: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 63, global step 1088: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 64, global step 1105: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 65, global step 1122: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 66, global step 1139: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 67, global step 1156: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 68, global step 1173: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 69, global step 1190: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 70, global step 1207: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 71, global step 1224: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 72, global step 1241: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 73, global step 1258: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 74, global step 1275: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 75, global step 1292: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 76, global step 1309: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 77, global step 1326: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 78, global step 1343: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 79, global step 1360: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 80, global step 1377: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 81, global step 1394: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 82, global step 1411: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 83, global step 1428: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 84, global step 1445: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 85, global step 1462: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 86, global step 1479: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 87, global step 1496: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 88, global step 1513: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 89, global step 1530: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 90, global step 1547: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 91, global step 1564: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 92, global step 1581: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 93, global step 1598: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 94, global step 1615: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 95, global step 1632: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 96, global step 1649: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 97, global step 1666: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 98, global step 1683: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 99, global step 1700: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 100, global step 1717: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 101, global step 1734: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 102, global step 1751: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 103, global step 1768: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 104, global step 1785: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 105, global step 1802: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 106, global step 1819: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 107, global step 1836: 'val_Metric' was not in top 1
Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=57-val_Metric=0.544.ckpt
##################################################best
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=57-val_Metric=0.544.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=57-val_Metric=0.544.ckpt
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m           Validate metric           [0m[1m [0m[1m [0m[1m            DataLoader 0            [0m[1m [0m

[36m [0m[36m       SSD/val_MulticlassAUROC       [0m[36m [0m[35m [0m[35m         0.7277729511260986         [0m[35m [0m
[36m [0m[36m     SSD/val_MulticlassAccuracy      [0m[36m [0m[35m [0m[35m         0.6881080269813538         [0m[35m [0m
[36m [0m[36m      SSD/val_MulticlassF1Score      [0m[36m [0m[35m [0m[35m         0.6881080269813538         [0m[35m [0m
[36m [0m[36m SSD/val_MulticlassMatthewsCorrCoef  [0m[36m [0m[35m [0m[35m         0.3619857430458069         [0m[35m [0m
[36m [0m[36m         SSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.7846050262451172         [0m[35m [0m
[36m [0m[36m      SSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         1.6994599103927612         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanAbsoluteError      [0m[36m [0m[35m [0m[35m         51.312652587890625         [0m[35m [0m
[36m [0m[36m TSD/val_MeanAbsolutePercentageError [0m[36m [0m[35m [0m[35m        0.15380814671516418         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanSquaredError       [0m[36m [0m[35m [0m[35m          4340.73974609375          [0m[35m [0m
[36m [0m[36m           TSD/val_R2Score           [0m[36m [0m[35m [0m[35m        0.43624868988990784         [0m[35m [0m
[36m [0m[36m         TSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.5466814041137695         [0m[35m [0m
[36m [0m[36m      TSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         2.5557641983032227         [0m[35m [0m
[36m [0m[36m    WS24_acid/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7193877696990967         [0m[35m [0m
[36m [0m[36m  WS24_acid/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.7142857313156128         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7142857313156128         [0m[35m [0m
[36m [0m[36mWS24_acid/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m         0.4330127239227295         [0m[35m [0m
[36m [0m[36m      WS24_acid/val_loss_epoch       [0m[36m [0m[35m [0m[35m         1.636086106300354          [0m[35m [0m
[36m [0m[36m   WS24_acid/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.18408076465129852         [0m[35m [0m
[36m [0m[36m    WS24_base/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m        0.23125000298023224         [0m[35m [0m
[36m [0m[36m  WS24_base/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m                0.5                 [0m[35m [0m
[36m [0m[36m   WS24_base/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m                0.5                 [0m[35m [0m
[36m [0m[36mWS24_base/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m                0.0                 [0m[35m [0m
[36m [0m[36m      WS24_base/val_loss_epoch       [0m[36m [0m[35m [0m[35m          5.70656681060791          [0m[35m [0m
[36m [0m[36m   WS24_base/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.13148626685142517         [0m[35m [0m
[36m [0m[36m  WS24_boiling/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m               0.625                [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassAccuracy [0m[36m [0m[35m [0m[35m               0.625                [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m               0.625                [0m[35m [0m
[36m [0m[36mWS24_boiling/val_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.2508726119995117         [0m[35m [0m
[36m [0m[36m     WS24_boiling/val_loss_epoch     [0m[36m [0m[35m [0m[35m         2.8072566986083984         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m        0.13477341830730438         [0m[35m [0m
[36m [0m[36m   WS24_water/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m          0.74427729845047          [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7094017267227173         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7094017267227173         [0m[35m [0m
[36m [0m[36mWS24_water/val_MulticlassMatthewsCor[0m[36m [0m[35m [0m[35m         0.3976694345474243         [0m[35m [0m
[36m [0m[36m      WS24_water/val_loss_epoch      [0m[36m [0m[35m [0m[35m         1.0504130125045776         [0m[35m [0m
[36m [0m[36m  WS24_water/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m   WS24_water4/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7095972299575806         [0m[35m [0m
[36m [0m[36m WS24_water4/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.5257142782211304         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5257142782211304         [0m[35m [0m
[36m [0m[36mWS24_water4/val_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.295731782913208          [0m[35m [0m
[36m [0m[36m     WS24_water4/val_loss_epoch      [0m[36m [0m[35m [0m[35m         2.0451977252960205         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m       val_MergedMetric_epoch        [0m[36m [0m[35m [0m[35m         0.5624187588691711         [0m[35m [0m
[36m [0m[36m             val_Metric              [0m[36m [0m[35m [0m[35m         0.544301137448247          [0m[35m [0m
[36m [0m[36m           val_loss_epoch            [0m[36m [0m[35m [0m[35m         2.479552745819092          [0m[35m [0m

TSD/val_loss : tensor(0.5467)
TSD/val_loss_epoch : tensor(0.5467)
TSD/val_loss_weight : tensor(2.5558)
TSD/val_loss_weight_epoch : tensor(2.5558)
TSD/val_R2Score : tensor(0.4362)
TSD/val_MeanAbsoluteError : tensor(51.3127)
TSD/val_MeanAbsolutePercentageError : tensor(0.1538)
TSD/val_MeanSquaredError : tensor(4340.7397)
val_loss : tensor(2.4796)
val_loss_epoch : tensor(2.4796)
val_MergedMetric : tensor(0.5624)
val_MergedMetric_epoch : tensor(0.5624)
SSD/val_loss : tensor(0.7846)
SSD/val_loss_epoch : tensor(0.7846)
SSD/val_loss_weight : tensor(1.6995)
SSD/val_loss_weight_epoch : tensor(1.6995)
SSD/val_MulticlassAccuracy : tensor(0.6881)
SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3620)
SSD/val_MulticlassF1Score : tensor(0.6881)
SSD/val_MulticlassAUROC : tensor(0.7278)
WS24_water/val_loss : tensor(1.0504)
WS24_water/val_loss_epoch : tensor(1.0504)
WS24_water/val_loss_weight : tensor(1.1472)
WS24_water/val_loss_weight_epoch : tensor(1.1472)
WS24_water/val_MulticlassAccuracy : tensor(0.7094)
WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.3977)
WS24_water/val_MulticlassF1Score : tensor(0.7094)
WS24_water/val_MulticlassAUROC : tensor(0.7443)
WS24_water4/val_loss : tensor(2.0452)
WS24_water4/val_loss_epoch : tensor(2.0452)
WS24_water4/val_loss_weight : tensor(1.1472)
WS24_water4/val_loss_weight_epoch : tensor(1.1472)
WS24_water4/val_MulticlassAccuracy : tensor(0.5257)
WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.2957)
WS24_water4/val_MulticlassF1Score : tensor(0.5257)
WS24_water4/val_MulticlassAUROC : tensor(0.7096)
WS24_acid/val_loss : tensor(1.6361)
WS24_acid/val_loss_epoch : tensor(1.6361)
WS24_acid/val_loss_weight : tensor(0.1841)
WS24_acid/val_loss_weight_epoch : tensor(0.1841)
WS24_acid/val_MulticlassAccuracy : tensor(0.7143)
WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.4330)
WS24_acid/val_MulticlassF1Score : tensor(0.7143)
WS24_acid/val_MulticlassAUROC : tensor(0.7194)
WS24_base/val_loss : tensor(5.7066)
WS24_base/val_loss_epoch : tensor(5.7066)
WS24_base/val_loss_weight : tensor(0.1315)
WS24_base/val_loss_weight_epoch : tensor(0.1315)
WS24_base/val_MulticlassAccuracy : tensor(0.5000)
WS24_base/val_MulticlassMatthewsCorrCoef : tensor(0.)
WS24_base/val_MulticlassF1Score : tensor(0.5000)
WS24_base/val_MulticlassAUROC : tensor(0.2313)
WS24_boiling/val_loss : tensor(2.8073)
WS24_boiling/val_loss_epoch : tensor(2.8073)
WS24_boiling/val_loss_weight : tensor(0.1348)
WS24_boiling/val_loss_weight_epoch : tensor(0.1348)
WS24_boiling/val_MulticlassAccuracy : tensor(0.6250)
WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.2509)
WS24_boiling/val_MulticlassF1Score : tensor(0.6250)
WS24_boiling/val_MulticlassAUROC : tensor(0.6250)
val_Metric : tensor(0.5443, dtype=torch.float64)
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=57-val_Metric=0.544.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_5/checkpoints/best-epoch=57-val_Metric=0.544.ckpt
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m            Test metric             [0m[1m [0m[1m [0m[1m            DataLoader 0             [0m[1m [0m

[36m [0m[36m      SSD/test_MulticlassAUROC      [0m[36m [0m[35m [0m[35m          0.62248295545578           [0m[35m [0m
[36m [0m[36m    SSD/test_MulticlassAccuracy     [0m[36m [0m[35m [0m[35m         0.6756365895271301          [0m[35m [0m
[36m [0m[36m     SSD/test_MulticlassF1Score     [0m[36m [0m[35m [0m[35m         0.6756365895271301          [0m[35m [0m
[36m [0m[36mSSD/test_MulticlassMatthewsCorrCoef [0m[36m [0m[35m [0m[35m         0.2228737622499466          [0m[35m [0m
[36m [0m[36m        SSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.8429579138755798          [0m[35m [0m
[36m [0m[36m     SSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         1.6994599103927612          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanAbsoluteError     [0m[36m [0m[35m [0m[35m          53.83582305908203          [0m[35m [0m
[36m [0m[36mTSD/test_MeanAbsolutePercentageError[0m[36m [0m[35m [0m[35m         0.16534864902496338         [0m[35m [0m
[36m [0m[36m     TSD/test_MeanSquaredError      [0m[36m [0m[35m [0m[35m            4767.4609375             [0m[35m [0m
[36m [0m[36m          TSD/test_R2Score          [0m[36m [0m[35m [0m[35m         0.3327849805355072          [0m[35m [0m
[36m [0m[36m        TSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.6004234552383423          [0m[35m [0m
[36m [0m[36m     TSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         2.5557641983032227          [0m[35m [0m
[36m [0m[36m   WS24_acid/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8703703880310059          [0m[35m [0m
[36m [0m[36m WS24_acid/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m                0.75                 [0m[35m [0m
[36m [0m[36m  WS24_acid/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m                0.75                 [0m[35m [0m
[36m [0m[36mWS24_acid/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.5070925354957581          [0m[35m [0m
[36m [0m[36m     WS24_acid/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.6410742998123169          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.18408076465129852         [0m[35m [0m
[36m [0m[36m   WS24_base/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.44583332538604736         [0m[35m [0m
[36m [0m[36m WS24_base/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.8409091234207153          [0m[35m [0m
[36m [0m[36m  WS24_base/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.8409091234207153          [0m[35m [0m
[36m [0m[36mWS24_base/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.7138090133666992          [0m[35m [0m
[36m [0m[36m     WS24_base/test_loss_epoch      [0m[36m [0m[35m [0m[35m         1.6526098251342773          [0m[35m [0m
[36m [0m[36m  WS24_base/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.13148626685142517         [0m[35m [0m
[36m [0m[36m WS24_boiling/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.7692307233810425          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassAccuracy[0m[36m [0m[35m [0m[35m          0.692307710647583          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m          0.692307710647583          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassMatthew[0m[36m [0m[35m [0m[35m         0.40422603487968445         [0m[35m [0m
[36m [0m[36m    WS24_boiling/test_loss_epoch    [0m[36m [0m[35m [0m[35m         1.4713677167892456          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         0.13477341830730438         [0m[35m [0m
[36m [0m[36m  WS24_water/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7621443271636963          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.7351598143577576          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7351598143577576          [0m[35m [0m
[36m [0m[36mWS24_water/test_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.4420533776283264          [0m[35m [0m
[36m [0m[36m     WS24_water/test_loss_epoch     [0m[36m [0m[35m [0m[35m         0.8873140811920166          [0m[35m [0m
[36m [0m[36m WS24_water/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m  WS24_water4/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m          0.792185366153717          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.5733944773674011          [0m[35m [0m
[36m [0m[36m WS24_water4/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.5733944773674011          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassMatthews[0m[36m [0m[35m [0m[35m         0.36853304505348206         [0m[35m [0m
[36m [0m[36m    WS24_water4/test_loss_epoch     [0m[36m [0m[35m [0m[35m         2.4665369987487793          [0m[35m [0m
[36m [0m[36m WS24_water4/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m            test_Metric             [0m[36m [0m[35m [0m[35m         0.5250382661805796          [0m[35m [0m
[36m [0m[36m          test_loss_epoch           [0m[36m [0m[35m [0m[35m         2.4658257961273193          [0m[35m [0m

TSD/test_loss : tensor(0.6004)
TSD/test_loss_epoch : tensor(0.6004)
TSD/test_loss_weight : tensor(2.5558)
TSD/test_loss_weight_epoch : tensor(2.5558)
TSD/test_R2Score : tensor(0.3328)
TSD/test_MeanAbsoluteError : tensor(53.8358)
TSD/test_MeanAbsolutePercentageError : tensor(0.1653)
TSD/test_MeanSquaredError : tensor(4767.4609)
test_loss : tensor(2.4658)
test_loss_epoch : tensor(2.4658)
SSD/test_loss : tensor(0.8430)
SSD/test_loss_epoch : tensor(0.8430)
SSD/test_loss_weight : tensor(1.6995)
SSD/test_loss_weight_epoch : tensor(1.6995)
SSD/test_MulticlassAccuracy : tensor(0.6756)
SSD/test_MulticlassMatthewsCorrCoef : tensor(0.2229)
SSD/test_MulticlassF1Score : tensor(0.6756)
SSD/test_MulticlassAUROC : tensor(0.6225)
WS24_water/test_loss : tensor(0.8873)
WS24_water/test_loss_epoch : tensor(0.8873)
WS24_water/test_loss_weight : tensor(1.1472)
WS24_water/test_loss_weight_epoch : tensor(1.1472)
WS24_water/test_MulticlassAccuracy : tensor(0.7352)
WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4421)
WS24_water/test_MulticlassF1Score : tensor(0.7352)
WS24_water/test_MulticlassAUROC : tensor(0.7621)
WS24_water4/test_loss : tensor(2.4665)
WS24_water4/test_loss_epoch : tensor(2.4665)
WS24_water4/test_loss_weight : tensor(1.1472)
WS24_water4/test_loss_weight_epoch : tensor(1.1472)
WS24_water4/test_MulticlassAccuracy : tensor(0.5734)
WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3685)
WS24_water4/test_MulticlassF1Score : tensor(0.5734)
WS24_water4/test_MulticlassAUROC : tensor(0.7922)
WS24_acid/test_loss : tensor(0.6411)
WS24_acid/test_loss_epoch : tensor(0.6411)
WS24_acid/test_loss_weight : tensor(0.1841)
WS24_acid/test_loss_weight_epoch : tensor(0.1841)
WS24_acid/test_MulticlassAccuracy : tensor(0.7500)
WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.5071)
WS24_acid/test_MulticlassF1Score : tensor(0.7500)
WS24_acid/test_MulticlassAUROC : tensor(0.8704)
WS24_base/test_loss : tensor(1.6526)
WS24_base/test_loss_epoch : tensor(1.6526)
WS24_base/test_loss_weight : tensor(0.1315)
WS24_base/test_loss_weight_epoch : tensor(0.1315)
WS24_base/test_MulticlassAccuracy : tensor(0.8409)
WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.7138)
WS24_base/test_MulticlassF1Score : tensor(0.8409)
WS24_base/test_MulticlassAUROC : tensor(0.4458)
WS24_boiling/test_loss : tensor(1.4714)
WS24_boiling/test_loss_epoch : tensor(1.4714)
WS24_boiling/test_loss_weight : tensor(0.1348)
WS24_boiling/test_loss_weight_epoch : tensor(0.1348)
WS24_boiling/test_MulticlassAccuracy : tensor(0.6923)
WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.4042)
WS24_boiling/test_MulticlassF1Score : tensor(0.6923)
WS24_boiling/test_MulticlassAUROC : tensor(0.7692)
test_Metric : tensor(0.5250, dtype=torch.float64)
[I 2025-12-03 14:46:01,954] Trial 7 finished with value: 0.49956205695142836 and parameters: {'atom_fea_len': 32, 'h_fea_len': 208, 'n_conv': 2, 'n_h': 1, 'lr_mult': 8, 'extra_fea_len': 40, 'dropout': 0.15000000000000002}. Best is trial 7 with value: 0.49956205695142836.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 13
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 48
extra_fea_len : 52
h_fea_len : 96
n_conv : 4
n_h : 6
att_S : 64
dropout_prob : 0.75
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=32, bias=True)
  (embedding_atom_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-1): 2 x ConvLayer(
      (fc_full): Linear(in_features=105, out_features=64, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=40, bias=True)
  (embedding_extra_norm): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=72, out_features=208, bias=True)
  (conv_to_fc_norm): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.15000000000000002, inplace=False)
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=208, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=208, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=208, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=208, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((208,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=208, out_features=208, bias=True)
      (key): Linear(in_features=208, out_features=208, bias=True)
      (value): Linear(in_features=208, out_features=208, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4849d60>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4849b50>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4849f40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4849fa0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa48490d0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa48496a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4849130>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                 | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 314 K  | ?                                        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96]]]
1   | model.embedding_atom            | Linear              | 4.5 K  | [4608, 92]                               | [4608, 48]
2   | model.embedding_atom_norm       | LayerNorm           | 96     | [4608, 48]                               | [4608, 48]
3   | model.convs                     | ModuleList          | 54.1 K | ?                                        | ?
4   | model.convs.0                   | ConvLayer           | 13.5 K | [[4608, 48], [4608, 10, 41], [4608, 10]] | [4608, 48]
5   | model.convs.0.fc_full           | Linear              | 13.2 K | [4608, 10, 137]                          | [4608, 10, 96]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 48]                           | [4608, 10, 48]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 48]                           | [4608, 10, 48]
8   | model.convs.0.bn1               | BatchNorm1d         | 192    | [46080, 96]                              | [46080, 96]
9   | model.convs.0.bn2               | BatchNorm1d         | 96     | [4608, 48]                               | [4608, 48]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 48]                               | [4608, 48]
11  | model.convs.1                   | ConvLayer           | 13.5 K | [[4608, 48], [4608, 10, 41], [4608, 10]] | [4608, 48]
12  | model.convs.1.fc_full           | Linear              | 13.2 K | [4608, 10, 137]                          | [4608, 10, 96]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 48]                           | [4608, 10, 48]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 48]                           | [4608, 10, 48]
15  | model.convs.1.bn1               | BatchNorm1d         | 192    | [46080, 96]                              | [46080, 96]
16  | model.convs.1.bn2               | BatchNorm1d         | 96     | [4608, 48]                               | [4608, 48]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 48]                               | [4608, 48]
18  | model.convs.2                   | ConvLayer           | 13.5 K | [[4608, 48], [4608, 10, 41], [4608, 10]] | [4608, 48]
19  | model.convs.2.fc_full           | Linear              | 13.2 K | [4608, 10, 137]                          | [4608, 10, 96]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 48]                           | [4608, 10, 48]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 48]                           | [4608, 10, 48]
22  | model.convs.2.bn1               | BatchNorm1d         | 192    | [46080, 96]                              | [46080, 96]
23  | model.convs.2.bn2               | BatchNorm1d         | 96     | [4608, 48]                               | [4608, 48]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 48]                               | [4608, 48]
25  | model.convs.3                   | ConvLayer           | 13.5 K | [[4608, 48], [4608, 10, 41], [4608, 10]] | [4608, 48]
26  | model.convs.3.fc_full           | Linear              | 13.2 K | [4608, 10, 137]                          | [4608, 10, 96]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 48]                           | [4608, 10, 48]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 48]                           | [4608, 10, 48]
29  | model.convs.3.bn1               | BatchNorm1d         | 192    | [46080, 96]                              | [46080, 96]
30  | model.convs.3.bn2               | BatchNorm1d         | 96     | [4608, 48]                               | [4608, 48]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 48]                               | [4608, 48]
32  | model.embedding_extra           | Linear              | 364    | [256, 6]                                 | [256, 52]
33  | model.embedding_extra_norm      | BatchNorm1d         | 104    | [256, 52]                                | [256, 52]
34  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 52]                                | [256, 52]
35  | model.conv_to_fc                | Linear              | 9.7 K  | [256, 100]                               | [256, 96]
36  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [256, 96]                                | [256, 96]
37  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 96]                                | [256, 96]
38  | model.dropout                   | Dropout             | 0      | [256, 96]                                | [256, 96]
39  | model.fcs                       | ModuleList          | 46.6 K | ?                                        | ?
40  | model.fcs.0                     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
41  | model.fcs.1                     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
42  | model.fcs.2                     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
43  | model.fcs.3                     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
44  | model.fcs.4                     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
45  | model.norms                     | ModuleList          | 960    | ?                                        | ?
46  | model.norms.0                   | BatchNorm1d         | 192    | [256, 96]                                | [256, 96]
47  | model.norms.1                   | BatchNorm1d         | 192    | [256, 96]                                | [256, 96]
48  | model.norms.2                   | BatchNorm1d         | 192    | [256, 96]                                | [256, 96]
49  | model.norms.3                   | BatchNorm1d         | 192    | [256, 96]                                | [256, 96]
50  | model.norms.4                   | BatchNorm1d         | 192    | [256, 96]                                | [256, 96]
51  | model.softpluses                | ModuleList          | 0      | ?                                        | ?
52  | model.softpluses.0              | Softplus            | 0      | [256, 96]                                | [256, 96]
53  | model.softpluses.1              | Softplus            | 0      | [256, 96]                                | [256, 96]
54  | model.softpluses.2              | Softplus            | 0      | [256, 96]                                | [256, 96]
55  | model.softpluses.3              | Softplus            | 0      | [256, 96]                                | [256, 96]
56  | model.softpluses.4              | Softplus            | 0      | [256, 96]                                | [256, 96]
57  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                        | ?
58  | model.fc_outs.0                 | OutputLayer         | 97     | [256, 96]                                | [256, 1]
59  | model.fc_outs.0.fc              | Linear              | 97     | [256, 96]                                | [256, 1]
60  | model.fc_outs.1                 | OutputLayer         | 194    | [256, 96]                                | [256, 2]
61  | model.fc_outs.1.fc              | Sequential          | 194    | [256, 96]                                | [256, 2]
62  | model.fc_outs.1.fc.0            | Linear              | 194    | [256, 96]                                | [256, 2]
63  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
64  | model.fc_outs.2                 | OutputLayer         | 194    | [256, 96]                                | [256, 2]
65  | model.fc_outs.2.fc              | Sequential          | 194    | [256, 96]                                | [256, 2]
66  | model.fc_outs.2.fc.0            | Linear              | 194    | [256, 96]                                | [256, 2]
67  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
68  | model.fc_outs.3                 | OutputLayer         | 388    | [256, 96]                                | [256, 4]
69  | model.fc_outs.3.fc              | Sequential          | 388    | [256, 96]                                | [256, 4]
70  | model.fc_outs.3.fc.0            | Linear              | 388    | [256, 96]                                | [256, 4]
71  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                 | [256, 4]
72  | model.fc_outs.4                 | OutputLayer         | 194    | [256, 96]                                | [256, 2]
73  | model.fc_outs.4.fc              | Sequential          | 194    | [256, 96]                                | [256, 2]
74  | model.fc_outs.4.fc.0            | Linear              | 194    | [256, 96]                                | [256, 2]
75  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
76  | model.fc_outs.5                 | OutputLayer         | 194    | [256, 96]                                | [256, 2]
77  | model.fc_outs.5.fc              | Sequential          | 194    | [256, 96]                                | [256, 2]
78  | model.fc_outs.5.fc.0            | Linear              | 194    | [256, 96]                                | [256, 2]
79  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
80  | model.fc_outs.6                 | OutputLayer         | 194    | [256, 96]                                | [256, 2]
81  | model.fc_outs.6.fc              | Sequential          | 194    | [256, 96]                                | [256, 2]
82  | model.fc_outs.6.fc.0            | Linear              | 194    | [256, 96]                                | [256, 2]
83  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
84  | model.task_norms                | ModuleList          | 1.3 K  | ?                                        | ?
85  | model.task_norms.0              | LayerNorm           | 192    | [256, 96]                                | [256, 96]
86  | model.task_norms.1              | LayerNorm           | 192    | [256, 96]                                | [256, 96]
87  | model.task_norms.2              | LayerNorm           | 192    | [256, 96]                                | [256, 96]
88  | model.task_norms.3              | LayerNorm           | 192    | [256, 96]                                | [256, 96]
89  | model.task_norms.4              | LayerNorm           | 192    | [256, 96]                                | [256, 96]
90  | model.task_norms.5              | LayerNorm           | 192    | [256, 96]                                | [256, 96]
91  | model.task_norms.6              | LayerNorm           | 192    | [256, 96]                                | [256, 96]
92  | model.task_attentions           | ModuleList          | 195 K  | ?                                        | ?
93  | model.task_attentions.0         | SelfAttention       | 27.9 K | [256, 96]                                | [256, 96]
94  | model.task_attentions.0.query   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
95  | model.task_attentions.0.key     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
96  | model.task_attentions.0.value   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
97  | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
98  | model.task_attentions.1         | SelfAttention       | 27.9 K | [256, 96]                                | [256, 96]
99  | model.task_attentions.1.query   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
100 | model.task_attentions.1.key     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
101 | model.task_attentions.1.value   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
102 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
103 | model.task_attentions.2         | SelfAttention       | 27.9 K | [256, 96]                                | [256, 96]
104 | model.task_attentions.2.query   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
105 | model.task_attentions.2.key     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
106 | model.task_attentions.2.value   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
107 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
108 | model.task_attentions.3         | SelfAttention       | 27.9 K | [256, 96]                                | [256, 96]
109 | model.task_attentions.3.query   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
110 | model.task_attentions.3.key     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
111 | model.task_attentions.3.value   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
112 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
113 | model.task_attentions.4         | SelfAttention       | 27.9 K | [256, 96]                                | [256, 96]
114 | model.task_attentions.4.query   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
115 | model.task_attentions.4.key     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
116 | model.task_attentions.4.value   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
117 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
118 | model.task_attentions.5         | SelfAttention       | 27.9 K | [256, 96]                                | [256, 96]
119 | model.task_attentions.5.query   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
120 | model.task_attentions.5.key     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
121 | model.task_attentions.5.value   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
122 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
123 | model.task_attentions.6         | SelfAttention       | 27.9 K | [256, 96]                                | [256, 96]
124 | model.task_attentions.6.query   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
125 | model.task_attentions.6.key     | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
126 | model.task_attentions.6.value   | Linear              | 9.3 K  | [256, 96]                                | [256, 96]
127 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
314 K     Trainable params
0         Non-trainable params
314 K     Total params
1.260     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 13 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 314 K  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96]]]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
314 K     Trainable params
0         Non-trainable params
314 K     Total params
1.260     Total estimated model params size (MB)
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(0): metric=0.2235 > best_metric=0.0000, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Epoch 0, global step 17: 'val_Metric' reached 0.22355 (best 0.22355), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=00-val_Metric=0.224.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(1): metric=0.3261 > best_metric=0.2235, log val results..
Epoch 1, global step 34: 'val_Metric' reached 0.32612 (best 0.32612), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=01-val_Metric=0.326.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(2): metric=0.3476 > best_metric=0.3261, log val results..
Epoch 2, global step 51: 'val_Metric' reached 0.34758 (best 0.34758), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=02-val_Metric=0.348.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(3): metric=0.3710 > best_metric=0.3476, log val results..
Epoch 3, global step 68: 'val_Metric' reached 0.37103 (best 0.37103), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=03-val_Metric=0.371.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(4): metric=0.3721 > best_metric=0.3710, log val results..
Epoch 4, global step 85: 'val_Metric' reached 0.37205 (best 0.37205), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=04-val_Metric=0.372.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 5, global step 102: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(6): metric=0.4018 > best_metric=0.3721, log val results..
Epoch 6, global step 119: 'val_Metric' reached 0.40182 (best 0.40182), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=06-val_Metric=0.402.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 7, global step 136: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(8): metric=0.4246 > best_metric=0.4018, log val results..
Epoch 8, global step 153: 'val_Metric' reached 0.42463 (best 0.42463), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=08-val_Metric=0.425.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(9): metric=0.4555 > best_metric=0.4246, log val results..
Epoch 9, global step 170: 'val_Metric' reached 0.45548 (best 0.45548), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=09-val_Metric=0.455.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 10, global step 187: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 11, global step 204: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 12, global step 221: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(13): metric=0.4616 > best_metric=0.4555, log val results..
Epoch 13, global step 238: 'val_Metric' reached 0.46161 (best 0.46161), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=13-val_Metric=0.462.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 14, global step 255: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(15): metric=0.4745 > best_metric=0.4616, log val results..
Epoch 15, global step 272: 'val_Metric' reached 0.47455 (best 0.47455), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=15-val_Metric=0.475.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 16, global step 289: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 17, global step 306: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(18): metric=0.4912 > best_metric=0.4745, log val results..
Epoch 18, global step 323: 'val_Metric' reached 0.49118 (best 0.49118), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=18-val_Metric=0.491.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 19, global step 340: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 20, global step 357: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 21, global step 374: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 22, global step 391: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 23, global step 408: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 24, global step 425: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 25, global step 442: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 26, global step 459: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(27): metric=0.5038 > best_metric=0.4912, log val results..
Epoch 27, global step 476: 'val_Metric' reached 0.50380 (best 0.50380), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=27-val_Metric=0.504.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 28, global step 493: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 29, global step 510: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 30, global step 527: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 31, global step 544: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 32, global step 561: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 33, global step 578: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 34, global step 595: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 35, global step 612: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 36, global step 629: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 37, global step 646: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 38, global step 663: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(39): metric=0.5273 > best_metric=0.5038, log val results..
Epoch 39, global step 680: 'val_Metric' reached 0.52727 (best 0.52727), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=39-val_Metric=0.527.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 40, global step 697: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 41, global step 714: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 42, global step 731: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 43, global step 748: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 44, global step 765: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 45, global step 782: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 46, global step 799: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 47, global step 816: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 48, global step 833: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 49, global step 850: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 50, global step 867: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(51): metric=0.5400 > best_metric=0.5273, log val results..
Epoch 51, global step 884: 'val_Metric' reached 0.54003 (best 0.54003), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=51-val_Metric=0.540.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 52, global step 901: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 53, global step 918: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 54, global step 935: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 55, global step 952: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 56, global step 969: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 57, global step 986: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 58, global step 1003: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 59, global step 1020: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 60, global step 1037: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 61, global step 1054: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 62, global step 1071: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(63): metric=0.5466 > best_metric=0.5400, log val results..
Epoch 63, global step 1088: 'val_Metric' reached 0.54663 (best 0.54663), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=63-val_Metric=0.547.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 64, global step 1105: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 65, global step 1122: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 66, global step 1139: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 67, global step 1156: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 68, global step 1173: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 69, global step 1190: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 70, global step 1207: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 71, global step 1224: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 72, global step 1241: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 73, global step 1258: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 74, global step 1275: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 75, global step 1292: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 76, global step 1309: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 77, global step 1326: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 78, global step 1343: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 79, global step 1360: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 80, global step 1377: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 81, global step 1394: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 82, global step 1411: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 83, global step 1428: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 84, global step 1445: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 85, global step 1462: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 86, global step 1479: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 87, global step 1496: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 88, global step 1513: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 89, global step 1530: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 90, global step 1547: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 91, global step 1564: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 92, global step 1581: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 93, global step 1598: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 94, global step 1615: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 95, global step 1632: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 96, global step 1649: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 97, global step 1666: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 98, global step 1683: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 99, global step 1700: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 100, global step 1717: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 101, global step 1734: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 102, global step 1751: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 103, global step 1768: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 104, global step 1785: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 105, global step 1802: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 106, global step 1819: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 107, global step 1836: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 108, global step 1853: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 109, global step 1870: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 110, global step 1887: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 111, global step 1904: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 112, global step 1921: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 113, global step 1938: 'val_Metric' was not in top 1
Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=63-val_Metric=0.547.ckpt
##################################################best
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=63-val_Metric=0.547.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=63-val_Metric=0.547.ckpt
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m           Validate metric           [0m[1m [0m[1m [0m[1m            DataLoader 0            [0m[1m [0m

[36m [0m[36m       SSD/val_MulticlassAUROC       [0m[36m [0m[35m [0m[35m         0.744520366191864          [0m[35m [0m
[36m [0m[36m     SSD/val_MulticlassAccuracy      [0m[36m [0m[35m [0m[35m         0.6886200904846191         [0m[35m [0m
[36m [0m[36m      SSD/val_MulticlassF1Score      [0m[36m [0m[35m [0m[35m         0.6886200904846191         [0m[35m [0m
[36m [0m[36m SSD/val_MulticlassMatthewsCorrCoef  [0m[36m [0m[35m [0m[35m        0.34975796937942505         [0m[35m [0m
[36m [0m[36m         SSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         1.3773243427276611         [0m[35m [0m
[36m [0m[36m      SSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         1.6994599103927612         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanAbsoluteError      [0m[36m [0m[35m [0m[35m         50.355323791503906         [0m[35m [0m
[36m [0m[36m TSD/val_MeanAbsolutePercentageError [0m[36m [0m[35m [0m[35m        0.14326563477516174         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanSquaredError       [0m[36m [0m[35m [0m[35m           4326.619140625           [0m[35m [0m
[36m [0m[36m           TSD/val_R2Score           [0m[36m [0m[35m [0m[35m         0.4381886124610901         [0m[35m [0m
[36m [0m[36m         TSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.544903039932251          [0m[35m [0m
[36m [0m[36m      TSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         2.5557641983032227         [0m[35m [0m
[36m [0m[36m    WS24_acid/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7244898080825806         [0m[35m [0m
[36m [0m[36m  WS24_acid/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.6785714030265808         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.6785714030265808         [0m[35m [0m
[36m [0m[36mWS24_acid/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m          0.35805743932724          [0m[35m [0m
[36m [0m[36m      WS24_acid/val_loss_epoch       [0m[36m [0m[35m [0m[35m         1.5458537340164185         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.18408076465129852         [0m[35m [0m
[36m [0m[36m    WS24_base/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m        0.15000000596046448         [0m[35m [0m
[36m [0m[36m  WS24_base/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m               0.5625               [0m[35m [0m
[36m [0m[36m   WS24_base/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m               0.5625               [0m[35m [0m
[36m [0m[36mWS24_base/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m        -0.06682679057121277        [0m[35m [0m
[36m [0m[36m      WS24_base/val_loss_epoch       [0m[36m [0m[35m [0m[35m         2.912017345428467          [0m[35m [0m
[36m [0m[36m   WS24_base/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.13148626685142517         [0m[35m [0m
[36m [0m[36m  WS24_boiling/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.6944444179534912         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.5833333134651184         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5833333134651184         [0m[35m [0m
[36m [0m[36mWS24_boiling/val_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m        0.16903084516525269         [0m[35m [0m
[36m [0m[36m     WS24_boiling/val_loss_epoch     [0m[36m [0m[35m [0m[35m         2.231745481491089          [0m[35m [0m
[36m [0m[36m WS24_boiling/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m        0.13477341830730438         [0m[35m [0m
[36m [0m[36m   WS24_water/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.774471640586853          [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7393162250518799         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7393162250518799         [0m[35m [0m
[36m [0m[36mWS24_water/val_MulticlassMatthewsCor[0m[36m [0m[35m [0m[35m         0.4484602212905884         [0m[35m [0m
[36m [0m[36m      WS24_water/val_loss_epoch      [0m[36m [0m[35m [0m[35m         1.5924317836761475         [0m[35m [0m
[36m [0m[36m  WS24_water/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m   WS24_water4/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7408373355865479         [0m[35m [0m
[36m [0m[36m WS24_water4/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.5828571319580078         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5828571319580078         [0m[35m [0m
[36m [0m[36mWS24_water4/val_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m        0.31942856311798096         [0m[35m [0m
[36m [0m[36m     WS24_water4/val_loss_epoch      [0m[36m [0m[35m [0m[35m         2.583834409713745          [0m[35m [0m
[36m [0m[36m  WS24_water4/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m       val_MergedMetric_epoch        [0m[36m [0m[35m [0m[35m         0.5703683495521545         [0m[35m [0m
[36m [0m[36m             val_Metric              [0m[36m [0m[35m [0m[35m         0.5466325960099789         [0m[35m [0m
[36m [0m[36m           val_loss_epoch            [0m[36m [0m[35m [0m[35m         3.0871551036834717         [0m[35m [0m

TSD/val_loss : tensor(0.5449)
TSD/val_loss_epoch : tensor(0.5449)
TSD/val_loss_weight : tensor(2.5558)
TSD/val_loss_weight_epoch : tensor(2.5558)
TSD/val_R2Score : tensor(0.4382)
TSD/val_MeanAbsoluteError : tensor(50.3553)
TSD/val_MeanAbsolutePercentageError : tensor(0.1433)
TSD/val_MeanSquaredError : tensor(4326.6191)
val_loss : tensor(3.0872)
val_loss_epoch : tensor(3.0872)
val_MergedMetric : tensor(0.5704)
val_MergedMetric_epoch : tensor(0.5704)
SSD/val_loss : tensor(1.3773)
SSD/val_loss_epoch : tensor(1.3773)
SSD/val_loss_weight : tensor(1.6995)
SSD/val_loss_weight_epoch : tensor(1.6995)
SSD/val_MulticlassAccuracy : tensor(0.6886)
SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3498)
SSD/val_MulticlassF1Score : tensor(0.6886)
SSD/val_MulticlassAUROC : tensor(0.7445)
WS24_water/val_loss : tensor(1.5924)
WS24_water/val_loss_epoch : tensor(1.5924)
WS24_water/val_loss_weight : tensor(1.1472)
WS24_water/val_loss_weight_epoch : tensor(1.1472)
WS24_water/val_MulticlassAccuracy : tensor(0.7393)
WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.4485)
WS24_water/val_MulticlassF1Score : tensor(0.7393)
WS24_water/val_MulticlassAUROC : tensor(0.7745)
WS24_water4/val_loss : tensor(2.5838)
WS24_water4/val_loss_epoch : tensor(2.5838)
WS24_water4/val_loss_weight : tensor(1.1472)
WS24_water4/val_loss_weight_epoch : tensor(1.1472)
WS24_water4/val_MulticlassAccuracy : tensor(0.5829)
WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.3194)
WS24_water4/val_MulticlassF1Score : tensor(0.5829)
WS24_water4/val_MulticlassAUROC : tensor(0.7408)
WS24_acid/val_loss : tensor(1.5459)
WS24_acid/val_loss_epoch : tensor(1.5459)
WS24_acid/val_loss_weight : tensor(0.1841)
WS24_acid/val_loss_weight_epoch : tensor(0.1841)
WS24_acid/val_MulticlassAccuracy : tensor(0.6786)
WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.3581)
WS24_acid/val_MulticlassF1Score : tensor(0.6786)
WS24_acid/val_MulticlassAUROC : tensor(0.7245)
WS24_base/val_loss : tensor(2.9120)
WS24_base/val_loss_epoch : tensor(2.9120)
WS24_base/val_loss_weight : tensor(0.1315)
WS24_base/val_loss_weight_epoch : tensor(0.1315)
WS24_base/val_MulticlassAccuracy : tensor(0.5625)
WS24_base/val_MulticlassMatthewsCorrCoef : tensor(-0.0668)
WS24_base/val_MulticlassF1Score : tensor(0.5625)
WS24_base/val_MulticlassAUROC : tensor(0.1500)
WS24_boiling/val_loss : tensor(2.2317)
WS24_boiling/val_loss_epoch : tensor(2.2317)
WS24_boiling/val_loss_weight : tensor(0.1348)
WS24_boiling/val_loss_weight_epoch : tensor(0.1348)
WS24_boiling/val_MulticlassAccuracy : tensor(0.5833)
WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.1690)
WS24_boiling/val_MulticlassF1Score : tensor(0.5833)
WS24_boiling/val_MulticlassAUROC : tensor(0.6944)
val_Metric : tensor(0.5466, dtype=torch.float64)
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=63-val_Metric=0.547.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_6/checkpoints/best-epoch=63-val_Metric=0.547.ckpt
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m            Test metric             [0m[1m [0m[1m [0m[1m            DataLoader 0             [0m[1m [0m

[36m [0m[36m      SSD/test_MulticlassAUROC      [0m[36m [0m[35m [0m[35m         0.7190631031990051          [0m[35m [0m
[36m [0m[36m    SSD/test_MulticlassAccuracy     [0m[36m [0m[35m [0m[35m         0.7164351940155029          [0m[35m [0m
[36m [0m[36m     SSD/test_MulticlassF1Score     [0m[36m [0m[35m [0m[35m         0.7164351940155029          [0m[35m [0m
[36m [0m[36mSSD/test_MulticlassMatthewsCorrCoef [0m[36m [0m[35m [0m[35m         0.37098440527915955         [0m[35m [0m
[36m [0m[36m        SSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         1.4661880731582642          [0m[35m [0m
[36m [0m[36m     SSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         1.6994599103927612          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanAbsoluteError     [0m[36m [0m[35m [0m[35m         51.872230529785156          [0m[35m [0m
[36m [0m[36mTSD/test_MeanAbsolutePercentageError[0m[36m [0m[35m [0m[35m         0.15210628509521484         [0m[35m [0m
[36m [0m[36m     TSD/test_MeanSquaredError      [0m[36m [0m[35m [0m[35m           4617.6005859375           [0m[35m [0m
[36m [0m[36m          TSD/test_R2Score          [0m[36m [0m[35m [0m[35m         0.35239145159721375         [0m[35m [0m
[36m [0m[36m        TSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.5815497636795044          [0m[35m [0m
[36m [0m[36m     TSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         2.5557641983032227          [0m[35m [0m
[36m [0m[36m   WS24_acid/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.9043209552764893          [0m[35m [0m
[36m [0m[36m WS24_acid/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36mWS24_acid/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m          0.589255690574646          [0m[35m [0m
[36m [0m[36m     WS24_acid/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.9438974857330322          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.18408076465129852         [0m[35m [0m
[36m [0m[36m   WS24_base/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.4333333373069763          [0m[35m [0m
[36m [0m[36m WS24_base/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.8863636255264282          [0m[35m [0m
[36m [0m[36m  WS24_base/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.8863636255264282          [0m[35m [0m
[36m [0m[36mWS24_base/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.7869428396224976          [0m[35m [0m
[36m [0m[36m     WS24_base/test_loss_epoch      [0m[36m [0m[35m [0m[35m          0.675333559513092          [0m[35m [0m
[36m [0m[36m  WS24_base/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.13148626685142517         [0m[35m [0m
[36m [0m[36m WS24_boiling/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.6005917191505432          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassAccuracy[0m[36m [0m[35m [0m[35m         0.4615384638309479          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.4615384638309479          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassMatthew[0m[36m [0m[35m [0m[35m        -0.09759000688791275         [0m[35m [0m
[36m [0m[36m    WS24_boiling/test_loss_epoch    [0m[36m [0m[35m [0m[35m          4.059422969818115          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         0.13477341830730438         [0m[35m [0m
[36m [0m[36m  WS24_water/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8289165496826172          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.7305936217308044          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7305936217308044          [0m[35m [0m
[36m [0m[36mWS24_water/test_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.4298476278781891          [0m[35m [0m
[36m [0m[36m     WS24_water/test_loss_epoch     [0m[36m [0m[35m [0m[35m         1.4132707118988037          [0m[35m [0m
[36m [0m[36m WS24_water/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m  WS24_water4/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.7837027311325073          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m          0.646789014339447          [0m[35m [0m
[36m [0m[36m WS24_water4/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m          0.646789014339447          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassMatthews[0m[36m [0m[35m [0m[35m         0.42172718048095703         [0m[35m [0m
[36m [0m[36m    WS24_water4/test_loss_epoch     [0m[36m [0m[35m [0m[35m         1.0346571207046509          [0m[35m [0m
[36m [0m[36m WS24_water4/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m            test_Metric             [0m[36m [0m[35m [0m[35m         0.5350127552296547          [0m[35m [0m
[36m [0m[36m          test_loss_epoch           [0m[36m [0m[35m [0m[35m         2.5569210052490234          [0m[35m [0m

TSD/test_loss : tensor(0.5815)
TSD/test_loss_epoch : tensor(0.5815)
TSD/test_loss_weight : tensor(2.5558)
TSD/test_loss_weight_epoch : tensor(2.5558)
TSD/test_R2Score : tensor(0.3524)
TSD/test_MeanAbsoluteError : tensor(51.8722)
TSD/test_MeanAbsolutePercentageError : tensor(0.1521)
TSD/test_MeanSquaredError : tensor(4617.6006)
test_loss : tensor(2.5569)
test_loss_epoch : tensor(2.5569)
SSD/test_loss : tensor(1.4662)
SSD/test_loss_epoch : tensor(1.4662)
SSD/test_loss_weight : tensor(1.6995)
SSD/test_loss_weight_epoch : tensor(1.6995)
SSD/test_MulticlassAccuracy : tensor(0.7164)
SSD/test_MulticlassMatthewsCorrCoef : tensor(0.3710)
SSD/test_MulticlassF1Score : tensor(0.7164)
SSD/test_MulticlassAUROC : tensor(0.7191)
WS24_water/test_loss : tensor(1.4133)
WS24_water/test_loss_epoch : tensor(1.4133)
WS24_water/test_loss_weight : tensor(1.1472)
WS24_water/test_loss_weight_epoch : tensor(1.1472)
WS24_water/test_MulticlassAccuracy : tensor(0.7306)
WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4298)
WS24_water/test_MulticlassF1Score : tensor(0.7306)
WS24_water/test_MulticlassAUROC : tensor(0.8289)
WS24_water4/test_loss : tensor(1.0347)
WS24_water4/test_loss_epoch : tensor(1.0347)
WS24_water4/test_loss_weight : tensor(1.1472)
WS24_water4/test_loss_weight_epoch : tensor(1.1472)
WS24_water4/test_MulticlassAccuracy : tensor(0.6468)
WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.4217)
WS24_water4/test_MulticlassF1Score : tensor(0.6468)
WS24_water4/test_MulticlassAUROC : tensor(0.7837)
WS24_acid/test_loss : tensor(0.9439)
WS24_acid/test_loss_epoch : tensor(0.9439)
WS24_acid/test_loss_weight : tensor(0.1841)
WS24_acid/test_loss_weight_epoch : tensor(0.1841)
WS24_acid/test_MulticlassAccuracy : tensor(0.7778)
WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.5893)
WS24_acid/test_MulticlassF1Score : tensor(0.7778)
WS24_acid/test_MulticlassAUROC : tensor(0.9043)
WS24_base/test_loss : tensor(0.6753)
WS24_base/test_loss_epoch : tensor(0.6753)
WS24_base/test_loss_weight : tensor(0.1315)
WS24_base/test_loss_weight_epoch : tensor(0.1315)
WS24_base/test_MulticlassAccuracy : tensor(0.8864)
WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.7869)
WS24_base/test_MulticlassF1Score : tensor(0.8864)
WS24_base/test_MulticlassAUROC : tensor(0.4333)
WS24_boiling/test_loss : tensor(4.0594)
WS24_boiling/test_loss_epoch : tensor(4.0594)
WS24_boiling/test_loss_weight : tensor(0.1348)
WS24_boiling/test_loss_weight_epoch : tensor(0.1348)
WS24_boiling/test_MulticlassAccuracy : tensor(0.4615)
WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(-0.0976)
WS24_boiling/test_MulticlassF1Score : tensor(0.4615)
WS24_boiling/test_MulticlassAUROC : tensor(0.6006)
test_Metric : tensor(0.5350, dtype=torch.float64)
[I 2025-12-03 15:13:11,021] Trial 8 finished with value: 0.5247209443643848 and parameters: {'atom_fea_len': 48, 'h_fea_len': 96, 'n_conv': 4, 'n_h': 6, 'lr_mult': 13, 'extra_fea_len': 52, 'dropout': 0.75}. Best is trial 8 with value: 0.5247209443643848.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 3
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 176
extra_fea_len : 36
h_fea_len : 192
n_conv : 2
n_h : 1
att_S : 64
dropout_prob : 0.55
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=48, bias=True)
  (embedding_atom_norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-3): 4 x ConvLayer(
      (fc_full): Linear(in_features=137, out_features=96, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=52, bias=True)
  (embedding_extra_norm): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=100, out_features=96, bias=True)
  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.75, inplace=False)
  (fcs): ModuleList(
    (0-4): 5 x Linear(in_features=96, out_features=96, bias=True)
  )
  (norms): ModuleList(
    (0-4): 5 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-4): 5 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=96, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=96, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=96, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=96, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=96, out_features=96, bias=True)
      (key): Linear(in_features=96, out_features=96, bias=True)
      (value): Linear(in_features=96, out_features=96, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9279e580>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9279e310>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9279ea00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9279ef40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9279ed00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9279e790>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9279e1c0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
   | Name                            | Type                | Params | In sizes                                  | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0  | model                           | CrystalGraphConvNet | 1.1 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192]]]
1  | model.embedding_atom            | Linear              | 16.4 K | [4608, 92]                                | [4608, 176]
2  | model.embedding_atom_norm       | LayerNorm           | 352    | [4608, 176]                               | [4608, 176]
3  | model.convs                     | ModuleList          | 279 K  | ?                                         | ?
4  | model.convs.0                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
5  | model.convs.0.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
6  | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
7  | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
8  | model.convs.0.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
9  | model.convs.0.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
10 | model.convs.0.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
11 | model.convs.1                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
12 | model.convs.1.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
13 | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
14 | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
15 | model.convs.1.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
16 | model.convs.1.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
17 | model.convs.1.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
18 | model.embedding_extra           | Linear              | 252    | [256, 6]                                  | [256, 36]
19 | model.embedding_extra_norm      | BatchNorm1d         | 72     | [256, 36]                                 | [256, 36]
20 | model.embedding_extra_softplus  | Softplus            | 0      | [256, 36]                                 | [256, 36]
21 | model.conv_to_fc                | Linear              | 40.9 K | [256, 212]                                | [256, 192]
22 | model.conv_to_fc_norm           | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
23 | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 192]                                | [256, 192]
24 | model.dropout                   | Dropout             | 0      | [256, 192]                                | [256, 192]
25 | model.fc_outs                   | ModuleList          | 2.9 K  | ?                                         | ?
26 | model.fc_outs.0                 | OutputLayer         | 193    | [256, 192]                                | [256, 1]
27 | model.fc_outs.0.fc              | Linear              | 193    | [256, 192]                                | [256, 1]
28 | model.fc_outs.1                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
29 | model.fc_outs.1.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
30 | model.fc_outs.1.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
31 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
32 | model.fc_outs.2                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
33 | model.fc_outs.2.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
34 | model.fc_outs.2.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
35 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
36 | model.fc_outs.3                 | OutputLayer         | 772    | [256, 192]                                | [256, 4]
37 | model.fc_outs.3.fc              | Sequential          | 772    | [256, 192]                                | [256, 4]
38 | model.fc_outs.3.fc.0            | Linear              | 772    | [256, 192]                                | [256, 4]
39 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
40 | model.fc_outs.4                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
41 | model.fc_outs.4.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
42 | model.fc_outs.4.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
43 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
44 | model.fc_outs.5                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
45 | model.fc_outs.5.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
46 | model.fc_outs.5.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
47 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
48 | model.fc_outs.6                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
49 | model.fc_outs.6.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
50 | model.fc_outs.6.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
51 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
52 | model.task_norms                | ModuleList          | 2.7 K  | ?                                         | ?
53 | model.task_norms.0              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
54 | model.task_norms.1              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
55 | model.task_norms.2              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
56 | model.task_norms.3              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
57 | model.task_norms.4              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
58 | model.task_norms.5              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
59 | model.task_norms.6              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
60 | model.task_attentions           | ModuleList          | 778 K  | ?                                         | ?
61 | model.task_attentions.0         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
62 | model.task_attentions.0.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
63 | model.task_attentions.0.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
64 | model.task_attentions.0.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
65 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
66 | model.task_attentions.1         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
67 | model.task_attentions.1.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
68 | model.task_attentions.1.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
69 | model.task_attentions.1.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
70 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
71 | model.task_attentions.2         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
72 | model.task_attentions.2.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
73 | model.task_attentions.2.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
74 | model.task_attentions.2.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
75 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
76 | model.task_attentions.3         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
77 | model.task_attentions.3.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
78 | model.task_attentions.3.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
79 | model.task_attentions.3.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
80 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
81 | model.task_attentions.4         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
82 | model.task_attentions.4.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
83 | model.task_attentions.4.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
84 | model.task_attentions.4.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
85 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
86 | model.task_attentions.5         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
87 | model.task_attentions.5.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
88 | model.task_attentions.5.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
89 | model.task_attentions.5.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
90 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
91 | model.task_attentions.6         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
92 | model.task_attentions.6.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
93 | model.task_attentions.6.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
94 | model.task_attentions.6.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
95 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.486     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 3 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 1.1 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.486     Total estimated model params size (MB)
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(0): metric=0.3210 > best_metric=0.0000, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Epoch 0, global step 17: 'val_Metric' reached 0.32097 (best 0.32097), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=00-val_Metric=0.321.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(1): metric=0.3246 > best_metric=0.3210, log val results..
Epoch 1, global step 34: 'val_Metric' reached 0.32456 (best 0.32456), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=01-val_Metric=0.325.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(2): metric=0.3611 > best_metric=0.3246, log val results..
Epoch 2, global step 51: 'val_Metric' reached 0.36109 (best 0.36109), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=02-val_Metric=0.361.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(3): metric=0.3856 > best_metric=0.3611, log val results..
Epoch 3, global step 68: 'val_Metric' reached 0.38559 (best 0.38559), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=03-val_Metric=0.386.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(4): metric=0.4108 > best_metric=0.3856, log val results..
Epoch 4, global step 85: 'val_Metric' reached 0.41077 (best 0.41077), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=04-val_Metric=0.411.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 5, global step 102: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(6): metric=0.4395 > best_metric=0.4108, log val results..
Epoch 6, global step 119: 'val_Metric' reached 0.43946 (best 0.43946), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=06-val_Metric=0.439.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(7): metric=0.4466 > best_metric=0.4395, log val results..
Epoch 7, global step 136: 'val_Metric' reached 0.44660 (best 0.44660), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=07-val_Metric=0.447.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 8, global step 153: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(9): metric=0.4623 > best_metric=0.4466, log val results..
Epoch 9, global step 170: 'val_Metric' reached 0.46226 (best 0.46226), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=09-val_Metric=0.462.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(10): metric=0.4851 > best_metric=0.4623, log val results..
Epoch 10, global step 187: 'val_Metric' reached 0.48510 (best 0.48510), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=10-val_Metric=0.485.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 11, global step 204: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 12, global step 221: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 13, global step 238: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 14, global step 255: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(15): metric=0.5030 > best_metric=0.4851, log val results..
Epoch 15, global step 272: 'val_Metric' reached 0.50303 (best 0.50303), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=15-val_Metric=0.503.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 16, global step 289: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 17, global step 306: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 18, global step 323: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 19, global step 340: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 20, global step 357: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 21, global step 374: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(22): metric=0.5075 > best_metric=0.5030, log val results..
Epoch 22, global step 391: 'val_Metric' reached 0.50750 (best 0.50750), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=22-val_Metric=0.507.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(23): metric=0.5317 > best_metric=0.5075, log val results..
Epoch 23, global step 408: 'val_Metric' reached 0.53173 (best 0.53173), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=23-val_Metric=0.532.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 24, global step 425: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 25, global step 442: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 26, global step 459: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 27, global step 476: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 28, global step 493: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 29, global step 510: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 30, global step 527: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 31, global step 544: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 32, global step 561: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 33, global step 578: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 34, global step 595: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 35, global step 612: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 36, global step 629: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 37, global step 646: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 38, global step 663: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 39, global step 680: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 40, global step 697: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(41): metric=0.5424 > best_metric=0.5317, log val results..
Epoch 41, global step 714: 'val_Metric' reached 0.54238 (best 0.54238), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=41-val_Metric=0.542.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 42, global step 731: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 43, global step 748: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 44, global step 765: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 45, global step 782: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 46, global step 799: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 47, global step 816: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 48, global step 833: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 49, global step 850: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(50): metric=0.5509 > best_metric=0.5424, log val results..
Epoch 50, global step 867: 'val_Metric' reached 0.55091 (best 0.55091), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=50-val_Metric=0.551.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 51, global step 884: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 52, global step 901: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 53, global step 918: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 54, global step 935: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 55, global step 952: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 56, global step 969: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 57, global step 986: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 58, global step 1003: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 59, global step 1020: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 60, global step 1037: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 61, global step 1054: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 62, global step 1071: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 63, global step 1088: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 64, global step 1105: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 65, global step 1122: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 66, global step 1139: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 67, global step 1156: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 68, global step 1173: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 69, global step 1190: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 70, global step 1207: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 71, global step 1224: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 72, global step 1241: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(73): metric=0.5549 > best_metric=0.5509, log val results..
Epoch 73, global step 1258: 'val_Metric' reached 0.55490 (best 0.55490), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=73-val_Metric=0.555.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 74, global step 1275: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 75, global step 1292: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 76, global step 1309: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 77, global step 1326: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 78, global step 1343: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 79, global step 1360: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 80, global step 1377: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 81, global step 1394: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 82, global step 1411: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 83, global step 1428: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 84, global step 1445: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 85, global step 1462: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 86, global step 1479: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 87, global step 1496: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 88, global step 1513: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 89, global step 1530: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 90, global step 1547: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 91, global step 1564: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 92, global step 1581: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 93, global step 1598: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 94, global step 1615: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 95, global step 1632: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 96, global step 1649: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 97, global step 1666: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 98, global step 1683: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 99, global step 1700: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 100, global step 1717: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 101, global step 1734: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 102, global step 1751: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 103, global step 1768: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 104, global step 1785: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 105, global step 1802: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 106, global step 1819: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 107, global step 1836: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 108, global step 1853: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 109, global step 1870: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 110, global step 1887: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 111, global step 1904: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 112, global step 1921: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 113, global step 1938: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 114, global step 1955: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 115, global step 1972: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 116, global step 1989: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 117, global step 2006: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 118, global step 2023: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 119, global step 2040: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 120, global step 2057: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 121, global step 2074: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 122, global step 2091: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 123, global step 2108: 'val_Metric' was not in top 1
Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=73-val_Metric=0.555.ckpt
##################################################best
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=73-val_Metric=0.555.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=73-val_Metric=0.555.ckpt
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m           Validate metric           [0m[1m [0m[1m [0m[1m            DataLoader 0            [0m[1m [0m

[36m [0m[36m       SSD/val_MulticlassAUROC       [0m[36m [0m[35m [0m[35m         0.729272723197937          [0m[35m [0m
[36m [0m[36m     SSD/val_MulticlassAccuracy      [0m[36m [0m[35m [0m[35m         0.7001408338546753         [0m[35m [0m
[36m [0m[36m      SSD/val_MulticlassF1Score      [0m[36m [0m[35m [0m[35m         0.7001408338546753         [0m[35m [0m
[36m [0m[36m SSD/val_MulticlassMatthewsCorrCoef  [0m[36m [0m[35m [0m[35m         0.3774181008338928         [0m[35m [0m
[36m [0m[36m         SSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         1.1654329299926758         [0m[35m [0m
[36m [0m[36m      SSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         1.6994599103927612         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanAbsoluteError      [0m[36m [0m[35m [0m[35m          49.0841064453125          [0m[35m [0m
[36m [0m[36m TSD/val_MeanAbsolutePercentageError [0m[36m [0m[35m [0m[35m        0.14327728748321533         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanSquaredError       [0m[36m [0m[35m [0m[35m          4196.0732421875           [0m[35m [0m
[36m [0m[36m           TSD/val_R2Score           [0m[36m [0m[35m [0m[35m        0.45494818687438965         [0m[35m [0m
[36m [0m[36m         TSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.5284618139266968         [0m[35m [0m
[36m [0m[36m      TSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         2.5557641983032227         [0m[35m [0m
[36m [0m[36m    WS24_acid/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7091836929321289         [0m[35m [0m
[36m [0m[36m  WS24_acid/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.7142857313156128         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7142857313156128         [0m[35m [0m
[36m [0m[36mWS24_acid/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m        0.47434163093566895         [0m[35m [0m
[36m [0m[36m      WS24_acid/val_loss_epoch       [0m[36m [0m[35m [0m[35m         1.727609395980835          [0m[35m [0m
[36m [0m[36m   WS24_acid/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.18408076465129852         [0m[35m [0m
[36m [0m[36m    WS24_base/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m        0.21250000596046448         [0m[35m [0m
[36m [0m[36m  WS24_base/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m               0.5625               [0m[35m [0m
[36m [0m[36m   WS24_base/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m               0.5625               [0m[35m [0m
[36m [0m[36mWS24_base/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m        0.03781235218048096         [0m[35m [0m
[36m [0m[36m      WS24_base/val_loss_epoch       [0m[36m [0m[35m [0m[35m         3.8182501792907715         [0m[35m [0m
[36m [0m[36m   WS24_base/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.13148626685142517         [0m[35m [0m
[36m [0m[36m  WS24_boiling/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m               0.5625               [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassAccuracy [0m[36m [0m[35m [0m[35m               0.625                [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m               0.625                [0m[35m [0m
[36m [0m[36mWS24_boiling/val_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m        0.25819888710975647         [0m[35m [0m
[36m [0m[36m     WS24_boiling/val_loss_epoch     [0m[36m [0m[35m [0m[35m         2.5693554878234863         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m        0.13477341830730438         [0m[35m [0m
[36m [0m[36m   WS24_water/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7823402881622314         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7320512533187866         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7320512533187866         [0m[35m [0m
[36m [0m[36mWS24_water/val_MulticlassMatthewsCor[0m[36m [0m[35m [0m[35m         0.432758092880249          [0m[35m [0m
[36m [0m[36m      WS24_water/val_loss_epoch      [0m[36m [0m[35m [0m[35m         1.2086329460144043         [0m[35m [0m
[36m [0m[36m  WS24_water/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m   WS24_water4/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.756244421005249          [0m[35m [0m
[36m [0m[36m WS24_water4/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.5542857050895691         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5542857050895691         [0m[35m [0m
[36m [0m[36mWS24_water4/val_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.2838667631149292         [0m[35m [0m
[36m [0m[36m     WS24_water4/val_loss_epoch      [0m[36m [0m[35m [0m[35m         2.474339485168457          [0m[35m [0m
[36m [0m[36m  WS24_water4/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m       val_MergedMetric_epoch        [0m[36m [0m[35m [0m[35m         0.5919870138168335         [0m[35m [0m
[36m [0m[36m             val_Metric              [0m[36m [0m[35m [0m[35m         0.5549032765503463         [0m[35m [0m
[36m [0m[36m           val_loss_epoch            [0m[36m [0m[35m [0m[35m         2.7885184288024902         [0m[35m [0m

TSD/val_loss : tensor(0.5285)
TSD/val_loss_epoch : tensor(0.5285)
TSD/val_loss_weight : tensor(2.5558)
TSD/val_loss_weight_epoch : tensor(2.5558)
TSD/val_R2Score : tensor(0.4549)
TSD/val_MeanAbsoluteError : tensor(49.0841)
TSD/val_MeanAbsolutePercentageError : tensor(0.1433)
TSD/val_MeanSquaredError : tensor(4196.0732)
val_loss : tensor(2.7885)
val_loss_epoch : tensor(2.7885)
val_MergedMetric : tensor(0.5920)
val_MergedMetric_epoch : tensor(0.5920)
SSD/val_loss : tensor(1.1654)
SSD/val_loss_epoch : tensor(1.1654)
SSD/val_loss_weight : tensor(1.6995)
SSD/val_loss_weight_epoch : tensor(1.6995)
SSD/val_MulticlassAccuracy : tensor(0.7001)
SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3774)
SSD/val_MulticlassF1Score : tensor(0.7001)
SSD/val_MulticlassAUROC : tensor(0.7293)
WS24_water/val_loss : tensor(1.2086)
WS24_water/val_loss_epoch : tensor(1.2086)
WS24_water/val_loss_weight : tensor(1.1472)
WS24_water/val_loss_weight_epoch : tensor(1.1472)
WS24_water/val_MulticlassAccuracy : tensor(0.7321)
WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.4328)
WS24_water/val_MulticlassF1Score : tensor(0.7321)
WS24_water/val_MulticlassAUROC : tensor(0.7823)
WS24_water4/val_loss : tensor(2.4743)
WS24_water4/val_loss_epoch : tensor(2.4743)
WS24_water4/val_loss_weight : tensor(1.1472)
WS24_water4/val_loss_weight_epoch : tensor(1.1472)
WS24_water4/val_MulticlassAccuracy : tensor(0.5543)
WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.2839)
WS24_water4/val_MulticlassF1Score : tensor(0.5543)
WS24_water4/val_MulticlassAUROC : tensor(0.7562)
WS24_acid/val_loss : tensor(1.7276)
WS24_acid/val_loss_epoch : tensor(1.7276)
WS24_acid/val_loss_weight : tensor(0.1841)
WS24_acid/val_loss_weight_epoch : tensor(0.1841)
WS24_acid/val_MulticlassAccuracy : tensor(0.7143)
WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.4743)
WS24_acid/val_MulticlassF1Score : tensor(0.7143)
WS24_acid/val_MulticlassAUROC : tensor(0.7092)
WS24_base/val_loss : tensor(3.8183)
WS24_base/val_loss_epoch : tensor(3.8183)
WS24_base/val_loss_weight : tensor(0.1315)
WS24_base/val_loss_weight_epoch : tensor(0.1315)
WS24_base/val_MulticlassAccuracy : tensor(0.5625)
WS24_base/val_MulticlassMatthewsCorrCoef : tensor(0.0378)
WS24_base/val_MulticlassF1Score : tensor(0.5625)
WS24_base/val_MulticlassAUROC : tensor(0.2125)
WS24_boiling/val_loss : tensor(2.5694)
WS24_boiling/val_loss_epoch : tensor(2.5694)
WS24_boiling/val_loss_weight : tensor(0.1348)
WS24_boiling/val_loss_weight_epoch : tensor(0.1348)
WS24_boiling/val_MulticlassAccuracy : tensor(0.6250)
WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.2582)
WS24_boiling/val_MulticlassF1Score : tensor(0.6250)
WS24_boiling/val_MulticlassAUROC : tensor(0.5625)
val_Metric : tensor(0.5549, dtype=torch.float64)
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=73-val_Metric=0.555.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_7/checkpoints/best-epoch=73-val_Metric=0.555.ckpt
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m            Test metric             [0m[1m [0m[1m [0m[1m            DataLoader 0             [0m[1m [0m

[36m [0m[36m      SSD/test_MulticlassAUROC      [0m[36m [0m[35m [0m[35m          0.664035439491272          [0m[35m [0m
[36m [0m[36m    SSD/test_MulticlassAccuracy     [0m[36m [0m[35m [0m[35m         0.6754918694496155          [0m[35m [0m
[36m [0m[36m     SSD/test_MulticlassF1Score     [0m[36m [0m[35m [0m[35m         0.6754918694496155          [0m[35m [0m
[36m [0m[36mSSD/test_MulticlassMatthewsCorrCoef [0m[36m [0m[35m [0m[35m         0.2217317372560501          [0m[35m [0m
[36m [0m[36m        SSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m          1.279852271080017          [0m[35m [0m
[36m [0m[36m     SSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         1.6994599103927612          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanAbsoluteError     [0m[36m [0m[35m [0m[35m         51.631507873535156          [0m[35m [0m
[36m [0m[36mTSD/test_MeanAbsolutePercentageError[0m[36m [0m[35m [0m[35m         0.1588636189699173          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanSquaredError      [0m[36m [0m[35m [0m[35m           4780.298828125            [0m[35m [0m
[36m [0m[36m          TSD/test_R2Score          [0m[36m [0m[35m [0m[35m         0.33023595809936523         [0m[35m [0m
[36m [0m[36m        TSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.6020403504371643          [0m[35m [0m
[36m [0m[36m     TSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         2.5557641983032227          [0m[35m [0m
[36m [0m[36m   WS24_acid/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8580247163772583          [0m[35m [0m
[36m [0m[36m WS24_acid/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7222222089767456          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7222222089767456          [0m[35m [0m
[36m [0m[36mWS24_acid/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.4444444477558136          [0m[35m [0m
[36m [0m[36m     WS24_acid/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.7925954461097717          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.18408076465129852         [0m[35m [0m
[36m [0m[36m   WS24_base/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.42500001192092896         [0m[35m [0m
[36m [0m[36m WS24_base/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.8863636255264282          [0m[35m [0m
[36m [0m[36m  WS24_base/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.8863636255264282          [0m[35m [0m
[36m [0m[36mWS24_base/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.7869428396224976          [0m[35m [0m
[36m [0m[36m     WS24_base/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.8507492542266846          [0m[35m [0m
[36m [0m[36m  WS24_base/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.13148626685142517         [0m[35m [0m
[36m [0m[36m WS24_boiling/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.6272189617156982          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassAccuracy[0m[36m [0m[35m [0m[35m                 0.5                 [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m                 0.5                 [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassMatthew[0m[36m [0m[35m [0m[35m                 0.0                 [0m[35m [0m
[36m [0m[36m    WS24_boiling/test_loss_epoch    [0m[36m [0m[35m [0m[35m         1.6159377098083496          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         0.13477341830730438         [0m[35m [0m
[36m [0m[36m  WS24_water/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7615371346473694          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.7442922592163086          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7442922592163086          [0m[35m [0m
[36m [0m[36mWS24_water/test_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.46631285548210144         [0m[35m [0m
[36m [0m[36m     WS24_water/test_loss_epoch     [0m[36m [0m[35m [0m[35m         1.2902897596359253          [0m[35m [0m
[36m [0m[36m WS24_water/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m  WS24_water4/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.7896094918251038          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.6100917458534241          [0m[35m [0m
[36m [0m[36m WS24_water4/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.6100917458534241          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassMatthews[0m[36m [0m[35m [0m[35m         0.35155820846557617         [0m[35m [0m
[36m [0m[36m    WS24_water4/test_loss_epoch     [0m[36m [0m[35m [0m[35m         1.1436469554901123          [0m[35m [0m
[36m [0m[36m WS24_water4/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m            test_Metric             [0m[36m [0m[35m [0m[35m         0.5172876568144792          [0m[35m [0m
[36m [0m[36m          test_loss_epoch           [0m[36m [0m[35m [0m[35m         2.3823659420013428          [0m[35m [0m

TSD/test_loss : tensor(0.6020)
TSD/test_loss_epoch : tensor(0.6020)
TSD/test_loss_weight : tensor(2.5558)
TSD/test_loss_weight_epoch : tensor(2.5558)
TSD/test_R2Score : tensor(0.3302)
TSD/test_MeanAbsoluteError : tensor(51.6315)
TSD/test_MeanAbsolutePercentageError : tensor(0.1589)
TSD/test_MeanSquaredError : tensor(4780.2988)
test_loss : tensor(2.3824)
test_loss_epoch : tensor(2.3824)
SSD/test_loss : tensor(1.2799)
SSD/test_loss_epoch : tensor(1.2799)
SSD/test_loss_weight : tensor(1.6995)
SSD/test_loss_weight_epoch : tensor(1.6995)
SSD/test_MulticlassAccuracy : tensor(0.6755)
SSD/test_MulticlassMatthewsCorrCoef : tensor(0.2217)
SSD/test_MulticlassF1Score : tensor(0.6755)
SSD/test_MulticlassAUROC : tensor(0.6640)
WS24_water/test_loss : tensor(1.2903)
WS24_water/test_loss_epoch : tensor(1.2903)
WS24_water/test_loss_weight : tensor(1.1472)
WS24_water/test_loss_weight_epoch : tensor(1.1472)
WS24_water/test_MulticlassAccuracy : tensor(0.7443)
WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4663)
WS24_water/test_MulticlassF1Score : tensor(0.7443)
WS24_water/test_MulticlassAUROC : tensor(0.7615)
WS24_water4/test_loss : tensor(1.1436)
WS24_water4/test_loss_epoch : tensor(1.1436)
WS24_water4/test_loss_weight : tensor(1.1472)
WS24_water4/test_loss_weight_epoch : tensor(1.1472)
WS24_water4/test_MulticlassAccuracy : tensor(0.6101)
WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3516)
WS24_water4/test_MulticlassF1Score : tensor(0.6101)
WS24_water4/test_MulticlassAUROC : tensor(0.7896)
WS24_acid/test_loss : tensor(0.7926)
WS24_acid/test_loss_epoch : tensor(0.7926)
WS24_acid/test_loss_weight : tensor(0.1841)
WS24_acid/test_loss_weight_epoch : tensor(0.1841)
WS24_acid/test_MulticlassAccuracy : tensor(0.7222)
WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.4444)
WS24_acid/test_MulticlassF1Score : tensor(0.7222)
WS24_acid/test_MulticlassAUROC : tensor(0.8580)
WS24_base/test_loss : tensor(0.8507)
WS24_base/test_loss_epoch : tensor(0.8507)
WS24_base/test_loss_weight : tensor(0.1315)
WS24_base/test_loss_weight_epoch : tensor(0.1315)
WS24_base/test_MulticlassAccuracy : tensor(0.8864)
WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.7869)
WS24_base/test_MulticlassF1Score : tensor(0.8864)
WS24_base/test_MulticlassAUROC : tensor(0.4250)
WS24_boiling/test_loss : tensor(1.6159)
WS24_boiling/test_loss_epoch : tensor(1.6159)
WS24_boiling/test_loss_weight : tensor(0.1348)
WS24_boiling/test_loss_weight_epoch : tensor(0.1348)
WS24_boiling/test_MulticlassAccuracy : tensor(0.5000)
WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.)
WS24_boiling/test_MulticlassF1Score : tensor(0.5000)
WS24_boiling/test_MulticlassAUROC : tensor(0.6272)
test_Metric : tensor(0.5173, dtype=torch.float64)
[I 2025-12-03 15:54:54,206] Trial 9 finished with value: 0.5209502373317322 and parameters: {'atom_fea_len': 176, 'h_fea_len': 192, 'n_conv': 2, 'n_h': 1, 'lr_mult': 3, 'extra_fea_len': 36, 'dropout': 0.55}. Best is trial 8 with value: 0.5247209443643848.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 2
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 208
extra_fea_len : 64
h_fea_len : 240
n_conv : 2
n_h : 1
att_S : 64
dropout_prob : 0.7000000000000001
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=176, bias=True)
  (embedding_atom_norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-1): 2 x ConvLayer(
      (fc_full): Linear(in_features=393, out_features=352, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=36, bias=True)
  (embedding_extra_norm): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=212, out_features=192, bias=True)
  (conv_to_fc_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.55, inplace=False)
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=192, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=192, out_features=192, bias=True)
      (key): Linear(in_features=192, out_features=192, bias=True)
      (value): Linear(in_features=192, out_features=192, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92138ca0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f901b1760>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f901b1eb0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f901b1220>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f901b1250>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f901b1850>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f901b16a0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
   | Name                            | Type                | Params | In sizes                                  | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0  | model                           | CrystalGraphConvNet | 1.7 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240]]]
1  | model.embedding_atom            | Linear              | 19.3 K | [4608, 92]                                | [4608, 208]
2  | model.embedding_atom_norm       | LayerNorm           | 416    | [4608, 208]                               | [4608, 208]
3  | model.convs                     | ModuleList          | 383 K  | ?                                         | ?
4  | model.convs.0                   | ConvLayer           | 191 K  | [[4608, 208], [4608, 10, 41], [4608, 10]] | [4608, 208]
5  | model.convs.0.fc_full           | Linear              | 190 K  | [4608, 10, 457]                           | [4608, 10, 416]
6  | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 208]                           | [4608, 10, 208]
7  | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 208]                           | [4608, 10, 208]
8  | model.convs.0.bn1               | BatchNorm1d         | 832    | [46080, 416]                              | [46080, 416]
9  | model.convs.0.bn2               | BatchNorm1d         | 416    | [4608, 208]                               | [4608, 208]
10 | model.convs.0.softplus2         | Softplus            | 0      | [4608, 208]                               | [4608, 208]
11 | model.convs.1                   | ConvLayer           | 191 K  | [[4608, 208], [4608, 10, 41], [4608, 10]] | [4608, 208]
12 | model.convs.1.fc_full           | Linear              | 190 K  | [4608, 10, 457]                           | [4608, 10, 416]
13 | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 208]                           | [4608, 10, 208]
14 | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 208]                           | [4608, 10, 208]
15 | model.convs.1.bn1               | BatchNorm1d         | 832    | [46080, 416]                              | [46080, 416]
16 | model.convs.1.bn2               | BatchNorm1d         | 416    | [4608, 208]                               | [4608, 208]
17 | model.convs.1.softplus2         | Softplus            | 0      | [4608, 208]                               | [4608, 208]
18 | model.embedding_extra           | Linear              | 448    | [256, 6]                                  | [256, 64]
19 | model.embedding_extra_norm      | BatchNorm1d         | 128    | [256, 64]                                 | [256, 64]
20 | model.embedding_extra_softplus  | Softplus            | 0      | [256, 64]                                 | [256, 64]
21 | model.conv_to_fc                | Linear              | 65.5 K | [256, 272]                                | [256, 240]
22 | model.conv_to_fc_norm           | BatchNorm1d         | 480    | [256, 240]                                | [256, 240]
23 | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 240]                                | [256, 240]
24 | model.dropout                   | Dropout             | 0      | [256, 240]                                | [256, 240]
25 | model.fc_outs                   | ModuleList          | 3.6 K  | ?                                         | ?
26 | model.fc_outs.0                 | OutputLayer         | 241    | [256, 240]                                | [256, 1]
27 | model.fc_outs.0.fc              | Linear              | 241    | [256, 240]                                | [256, 1]
28 | model.fc_outs.1                 | OutputLayer         | 482    | [256, 240]                                | [256, 2]
29 | model.fc_outs.1.fc              | Sequential          | 482    | [256, 240]                                | [256, 2]
30 | model.fc_outs.1.fc.0            | Linear              | 482    | [256, 240]                                | [256, 2]
31 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
32 | model.fc_outs.2                 | OutputLayer         | 482    | [256, 240]                                | [256, 2]
33 | model.fc_outs.2.fc              | Sequential          | 482    | [256, 240]                                | [256, 2]
34 | model.fc_outs.2.fc.0            | Linear              | 482    | [256, 240]                                | [256, 2]
35 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
36 | model.fc_outs.3                 | OutputLayer         | 964    | [256, 240]                                | [256, 4]
37 | model.fc_outs.3.fc              | Sequential          | 964    | [256, 240]                                | [256, 4]
38 | model.fc_outs.3.fc.0            | Linear              | 964    | [256, 240]                                | [256, 4]
39 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
40 | model.fc_outs.4                 | OutputLayer         | 482    | [256, 240]                                | [256, 2]
41 | model.fc_outs.4.fc              | Sequential          | 482    | [256, 240]                                | [256, 2]
42 | model.fc_outs.4.fc.0            | Linear              | 482    | [256, 240]                                | [256, 2]
43 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
44 | model.fc_outs.5                 | OutputLayer         | 482    | [256, 240]                                | [256, 2]
45 | model.fc_outs.5.fc              | Sequential          | 482    | [256, 240]                                | [256, 2]
46 | model.fc_outs.5.fc.0            | Linear              | 482    | [256, 240]                                | [256, 2]
47 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
48 | model.fc_outs.6                 | OutputLayer         | 482    | [256, 240]                                | [256, 2]
49 | model.fc_outs.6.fc              | Sequential          | 482    | [256, 240]                                | [256, 2]
50 | model.fc_outs.6.fc.0            | Linear              | 482    | [256, 240]                                | [256, 2]
51 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
52 | model.task_norms                | ModuleList          | 3.4 K  | ?                                         | ?
53 | model.task_norms.0              | LayerNorm           | 480    | [256, 240]                                | [256, 240]
54 | model.task_norms.1              | LayerNorm           | 480    | [256, 240]                                | [256, 240]
55 | model.task_norms.2              | LayerNorm           | 480    | [256, 240]                                | [256, 240]
56 | model.task_norms.3              | LayerNorm           | 480    | [256, 240]                                | [256, 240]
57 | model.task_norms.4              | LayerNorm           | 480    | [256, 240]                                | [256, 240]
58 | model.task_norms.5              | LayerNorm           | 480    | [256, 240]                                | [256, 240]
59 | model.task_norms.6              | LayerNorm           | 480    | [256, 240]                                | [256, 240]
60 | model.task_attentions           | ModuleList          | 1.2 M  | ?                                         | ?
61 | model.task_attentions.0         | SelfAttention       | 173 K  | [256, 240]                                | [256, 240]
62 | model.task_attentions.0.query   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
63 | model.task_attentions.0.key     | Linear              | 57.8 K | [256, 240]                                | [256, 240]
64 | model.task_attentions.0.value   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
65 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
66 | model.task_attentions.1         | SelfAttention       | 173 K  | [256, 240]                                | [256, 240]
67 | model.task_attentions.1.query   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
68 | model.task_attentions.1.key     | Linear              | 57.8 K | [256, 240]                                | [256, 240]
69 | model.task_attentions.1.value   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
70 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
71 | model.task_attentions.2         | SelfAttention       | 173 K  | [256, 240]                                | [256, 240]
72 | model.task_attentions.2.query   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
73 | model.task_attentions.2.key     | Linear              | 57.8 K | [256, 240]                                | [256, 240]
74 | model.task_attentions.2.value   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
75 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
76 | model.task_attentions.3         | SelfAttention       | 173 K  | [256, 240]                                | [256, 240]
77 | model.task_attentions.3.query   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
78 | model.task_attentions.3.key     | Linear              | 57.8 K | [256, 240]                                | [256, 240]
79 | model.task_attentions.3.value   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
80 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
81 | model.task_attentions.4         | SelfAttention       | 173 K  | [256, 240]                                | [256, 240]
82 | model.task_attentions.4.query   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
83 | model.task_attentions.4.key     | Linear              | 57.8 K | [256, 240]                                | [256, 240]
84 | model.task_attentions.4.value   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
85 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
86 | model.task_attentions.5         | SelfAttention       | 173 K  | [256, 240]                                | [256, 240]
87 | model.task_attentions.5.query   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
88 | model.task_attentions.5.key     | Linear              | 57.8 K | [256, 240]                                | [256, 240]
89 | model.task_attentions.5.value   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
90 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
91 | model.task_attentions.6         | SelfAttention       | 173 K  | [256, 240]                                | [256, 240]
92 | model.task_attentions.6.query   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
93 | model.task_attentions.6.key     | Linear              | 57.8 K | [256, 240]                                | [256, 240]
94 | model.task_attentions.6.value   | Linear              | 57.8 K | [256, 240]                                | [256, 240]
95 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.7 M     Trainable params
0         Non-trainable params
1.7 M     Total params
6.766     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 2 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 1.7 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.7 M     Trainable params
0         Non-trainable params
1.7 M     Total params
6.766     Total estimated model params size (MB)
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(0): metric=0.3001 > best_metric=0.0000, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Epoch 0, global step 17: 'val_Metric' reached 0.30012 (best 0.30012), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=00-val_Metric=0.300.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(1): metric=0.3865 > best_metric=0.3001, log val results..
Epoch 1, global step 34: 'val_Metric' reached 0.38647 (best 0.38647), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=01-val_Metric=0.386.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 2, global step 51: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(3): metric=0.4000 > best_metric=0.3865, log val results..
Epoch 3, global step 68: 'val_Metric' reached 0.40001 (best 0.40001), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=03-val_Metric=0.400.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 4, global step 85: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(5): metric=0.4177 > best_metric=0.4000, log val results..
Epoch 5, global step 102: 'val_Metric' reached 0.41773 (best 0.41773), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=05-val_Metric=0.418.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(6): metric=0.4253 > best_metric=0.4177, log val results..
Epoch 6, global step 119: 'val_Metric' reached 0.42529 (best 0.42529), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=06-val_Metric=0.425.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(7): metric=0.4358 > best_metric=0.4253, log val results..
Epoch 7, global step 136: 'val_Metric' reached 0.43580 (best 0.43580), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=07-val_Metric=0.436.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(8): metric=0.4392 > best_metric=0.4358, log val results..
Epoch 8, global step 153: 'val_Metric' reached 0.43917 (best 0.43917), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=08-val_Metric=0.439.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 9, global step 170: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 10, global step 187: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(11): metric=0.4566 > best_metric=0.4392, log val results..
Epoch 11, global step 204: 'val_Metric' reached 0.45663 (best 0.45663), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=11-val_Metric=0.457.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 12, global step 221: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(13): metric=0.4663 > best_metric=0.4566, log val results..
Epoch 13, global step 238: 'val_Metric' reached 0.46634 (best 0.46634), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=13-val_Metric=0.466.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 14, global step 255: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 15, global step 272: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 16, global step 289: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 17, global step 306: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(18): metric=0.4998 > best_metric=0.4663, log val results..
Epoch 18, global step 323: 'val_Metric' reached 0.49985 (best 0.49985), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=18-val_Metric=0.500.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 19, global step 340: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 20, global step 357: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 21, global step 374: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 22, global step 391: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 23, global step 408: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 24, global step 425: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 25, global step 442: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 26, global step 459: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 27, global step 476: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(28): metric=0.5134 > best_metric=0.4998, log val results..
Epoch 28, global step 493: 'val_Metric' reached 0.51340 (best 0.51340), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=28-val_Metric=0.513.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 29, global step 510: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 30, global step 527: 'val_Metric' reached 0.51378 (best 0.51378), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=30-val_Metric=0.514.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 31, global step 544: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 32, global step 561: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 33, global step 578: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 34, global step 595: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 35, global step 612: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 36, global step 629: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 37, global step 646: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 38, global step 663: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 39, global step 680: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 40, global step 697: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 41, global step 714: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(42): metric=0.5178 > best_metric=0.5134, log val results..
Epoch 42, global step 731: 'val_Metric' reached 0.51776 (best 0.51776), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=42-val_Metric=0.518.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 43, global step 748: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 44, global step 765: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 45, global step 782: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 46, global step 799: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 47, global step 816: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 48, global step 833: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 49, global step 850: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(50): metric=0.5224 > best_metric=0.5178, log val results..
Epoch 50, global step 867: 'val_Metric' reached 0.52237 (best 0.52237), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=50-val_Metric=0.522.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 51, global step 884: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 52, global step 901: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(53): metric=0.5448 > best_metric=0.5224, log val results..
Epoch 53, global step 918: 'val_Metric' reached 0.54477 (best 0.54477), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=53-val_Metric=0.545.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 54, global step 935: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 55, global step 952: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 56, global step 969: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 57, global step 986: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 58, global step 1003: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 59, global step 1020: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 60, global step 1037: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 61, global step 1054: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 62, global step 1071: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 63, global step 1088: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 64, global step 1105: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 65, global step 1122: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 66, global step 1139: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 67, global step 1156: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 68, global step 1173: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 69, global step 1190: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 70, global step 1207: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 71, global step 1224: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 72, global step 1241: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 73, global step 1258: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 74, global step 1275: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 75, global step 1292: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(76): metric=0.5473 > best_metric=0.5448, log val results..
Epoch 76, global step 1309: 'val_Metric' reached 0.54729 (best 0.54729), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=76-val_Metric=0.547.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 77, global step 1326: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 78, global step 1343: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 79, global step 1360: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 80, global step 1377: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 81, global step 1394: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 82, global step 1411: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 83, global step 1428: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 84, global step 1445: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 85, global step 1462: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 86, global step 1479: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 87, global step 1496: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 88, global step 1513: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 89, global step 1530: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 90, global step 1547: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 91, global step 1564: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 92, global step 1581: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 93, global step 1598: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 94, global step 1615: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 95, global step 1632: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 96, global step 1649: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 97, global step 1666: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 98, global step 1683: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 99, global step 1700: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 100, global step 1717: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 101, global step 1734: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 102, global step 1751: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 103, global step 1768: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 104, global step 1785: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 105, global step 1802: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 106, global step 1819: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 107, global step 1836: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 108, global step 1853: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 109, global step 1870: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 110, global step 1887: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 111, global step 1904: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 112, global step 1921: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 113, global step 1938: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 114, global step 1955: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 115, global step 1972: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 116, global step 1989: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 117, global step 2006: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 118, global step 2023: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 119, global step 2040: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 120, global step 2057: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 121, global step 2074: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 122, global step 2091: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 123, global step 2108: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 124, global step 2125: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 125, global step 2142: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 126, global step 2159: 'val_Metric' was not in top 1
Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=76-val_Metric=0.547.ckpt
##################################################best
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=76-val_Metric=0.547.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=76-val_Metric=0.547.ckpt
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m           Validate metric           [0m[1m [0m[1m [0m[1m            DataLoader 0            [0m[1m [0m

[36m [0m[36m       SSD/val_MulticlassAUROC       [0m[36m [0m[35m [0m[35m         0.7304686307907104         [0m[35m [0m
[36m [0m[36m     SSD/val_MulticlassAccuracy      [0m[36m [0m[35m [0m[35m         0.6719790101051331         [0m[35m [0m
[36m [0m[36m      SSD/val_MulticlassF1Score      [0m[36m [0m[35m [0m[35m         0.6719790101051331         [0m[35m [0m
[36m [0m[36m SSD/val_MulticlassMatthewsCorrCoef  [0m[36m [0m[35m [0m[35m         0.3421032726764679         [0m[35m [0m
[36m [0m[36m         SSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.804487943649292          [0m[35m [0m
[36m [0m[36m      SSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         1.6994599103927612         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanAbsoluteError      [0m[36m [0m[35m [0m[35m         50.26923370361328          [0m[35m [0m
[36m [0m[36m TSD/val_MeanAbsolutePercentageError [0m[36m [0m[35m [0m[35m        0.14602160453796387         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanSquaredError       [0m[36m [0m[35m [0m[35m           4293.58984375            [0m[35m [0m
[36m [0m[36m           TSD/val_R2Score           [0m[36m [0m[35m [0m[35m         0.4422593414783478         [0m[35m [0m
[36m [0m[36m         TSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.5407431721687317         [0m[35m [0m
[36m [0m[36m      TSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         2.5557641983032227         [0m[35m [0m
[36m [0m[36m    WS24_acid/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.6938775777816772         [0m[35m [0m
[36m [0m[36m  WS24_acid/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.6071428656578064         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.6071428656578064         [0m[35m [0m
[36m [0m[36mWS24_acid/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m        0.22941572964191437         [0m[35m [0m
[36m [0m[36m      WS24_acid/val_loss_epoch       [0m[36m [0m[35m [0m[35m         1.577925443649292          [0m[35m [0m
[36m [0m[36m   WS24_acid/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.18408076465129852         [0m[35m [0m
[36m [0m[36m    WS24_base/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m        0.20000000298023224         [0m[35m [0m
[36m [0m[36m  WS24_base/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.4583333432674408         [0m[35m [0m
[36m [0m[36m   WS24_base/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.4583333432674408         [0m[35m [0m
[36m [0m[36mWS24_base/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m        -0.3041241466999054         [0m[35m [0m
[36m [0m[36m      WS24_base/val_loss_epoch       [0m[36m [0m[35m [0m[35m         4.0716166496276855         [0m[35m [0m
[36m [0m[36m   WS24_base/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.13148626685142517         [0m[35m [0m
[36m [0m[36m  WS24_boiling/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m               0.5625               [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassAccuracy [0m[36m [0m[35m [0m[35m               0.625                [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m               0.625                [0m[35m [0m
[36m [0m[36mWS24_boiling/val_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.2508726119995117         [0m[35m [0m
[36m [0m[36m     WS24_boiling/val_loss_epoch     [0m[36m [0m[35m [0m[35m         2.4516730308532715         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m        0.13477341830730438         [0m[35m [0m
[36m [0m[36m   WS24_water/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.752029538154602          [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.6829060316085815         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.6829060316085815         [0m[35m [0m
[36m [0m[36mWS24_water/val_MulticlassMatthewsCor[0m[36m [0m[35m [0m[35m         0.3431490659713745         [0m[35m [0m
[36m [0m[36m      WS24_water/val_loss_epoch      [0m[36m [0m[35m [0m[35m         1.2626879215240479         [0m[35m [0m
[36m [0m[36m  WS24_water/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m   WS24_water4/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7110637426376343         [0m[35m [0m
[36m [0m[36m WS24_water4/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.5428571701049805         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5428571701049805         [0m[35m [0m
[36m [0m[36mWS24_water4/val_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m        0.32822200655937195         [0m[35m [0m
[36m [0m[36m     WS24_water4/val_loss_epoch      [0m[36m [0m[35m [0m[35m         2.476536273956299          [0m[35m [0m
[36m [0m[36m  WS24_water4/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m       val_MergedMetric_epoch        [0m[36m [0m[35m [0m[35m         0.5647681951522827         [0m[35m [0m
[36m [0m[36m             val_Metric              [0m[36m [0m[35m [0m[35m         0.5472902667476861         [0m[35m [0m
[36m [0m[36m           val_loss_epoch            [0m[36m [0m[35m [0m[35m         2.585660934448242          [0m[35m [0m

TSD/val_loss : tensor(0.5407)
TSD/val_loss_epoch : tensor(0.5407)
TSD/val_loss_weight : tensor(2.5558)
TSD/val_loss_weight_epoch : tensor(2.5558)
TSD/val_R2Score : tensor(0.4423)
TSD/val_MeanAbsoluteError : tensor(50.2692)
TSD/val_MeanAbsolutePercentageError : tensor(0.1460)
TSD/val_MeanSquaredError : tensor(4293.5898)
val_loss : tensor(2.5857)
val_loss_epoch : tensor(2.5857)
val_MergedMetric : tensor(0.5648)
val_MergedMetric_epoch : tensor(0.5648)
SSD/val_loss : tensor(0.8045)
SSD/val_loss_epoch : tensor(0.8045)
SSD/val_loss_weight : tensor(1.6995)
SSD/val_loss_weight_epoch : tensor(1.6995)
SSD/val_MulticlassAccuracy : tensor(0.6720)
SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3421)
SSD/val_MulticlassF1Score : tensor(0.6720)
SSD/val_MulticlassAUROC : tensor(0.7305)
WS24_water/val_loss : tensor(1.2627)
WS24_water/val_loss_epoch : tensor(1.2627)
WS24_water/val_loss_weight : tensor(1.1472)
WS24_water/val_loss_weight_epoch : tensor(1.1472)
WS24_water/val_MulticlassAccuracy : tensor(0.6829)
WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.3431)
WS24_water/val_MulticlassF1Score : tensor(0.6829)
WS24_water/val_MulticlassAUROC : tensor(0.7520)
WS24_water4/val_loss : tensor(2.4765)
WS24_water4/val_loss_epoch : tensor(2.4765)
WS24_water4/val_loss_weight : tensor(1.1472)
WS24_water4/val_loss_weight_epoch : tensor(1.1472)
WS24_water4/val_MulticlassAccuracy : tensor(0.5429)
WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.3282)
WS24_water4/val_MulticlassF1Score : tensor(0.5429)
WS24_water4/val_MulticlassAUROC : tensor(0.7111)
WS24_acid/val_loss : tensor(1.5779)
WS24_acid/val_loss_epoch : tensor(1.5779)
WS24_acid/val_loss_weight : tensor(0.1841)
WS24_acid/val_loss_weight_epoch : tensor(0.1841)
WS24_acid/val_MulticlassAccuracy : tensor(0.6071)
WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.2294)
WS24_acid/val_MulticlassF1Score : tensor(0.6071)
WS24_acid/val_MulticlassAUROC : tensor(0.6939)
WS24_base/val_loss : tensor(4.0716)
WS24_base/val_loss_epoch : tensor(4.0716)
WS24_base/val_loss_weight : tensor(0.1315)
WS24_base/val_loss_weight_epoch : tensor(0.1315)
WS24_base/val_MulticlassAccuracy : tensor(0.4583)
WS24_base/val_MulticlassMatthewsCorrCoef : tensor(-0.3041)
WS24_base/val_MulticlassF1Score : tensor(0.4583)
WS24_base/val_MulticlassAUROC : tensor(0.2000)
WS24_boiling/val_loss : tensor(2.4517)
WS24_boiling/val_loss_epoch : tensor(2.4517)
WS24_boiling/val_loss_weight : tensor(0.1348)
WS24_boiling/val_loss_weight_epoch : tensor(0.1348)
WS24_boiling/val_MulticlassAccuracy : tensor(0.6250)
WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.2509)
WS24_boiling/val_MulticlassF1Score : tensor(0.6250)
WS24_boiling/val_MulticlassAUROC : tensor(0.5625)
val_Metric : tensor(0.5473, dtype=torch.float64)
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=76-val_Metric=0.547.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_8/checkpoints/best-epoch=76-val_Metric=0.547.ckpt
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m            Test metric             [0m[1m [0m[1m [0m[1m            DataLoader 0             [0m[1m [0m

[36m [0m[36m      SSD/test_MulticlassAUROC      [0m[36m [0m[35m [0m[35m         0.6997525691986084          [0m[35m [0m
[36m [0m[36m    SSD/test_MulticlassAccuracy     [0m[36m [0m[35m [0m[35m         0.6440972685813904          [0m[35m [0m
[36m [0m[36m     SSD/test_MulticlassF1Score     [0m[36m [0m[35m [0m[35m         0.6440972685813904          [0m[35m [0m
[36m [0m[36mSSD/test_MulticlassMatthewsCorrCoef [0m[36m [0m[35m [0m[35m         0.2712257206439972          [0m[35m [0m
[36m [0m[36m        SSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.8175773024559021          [0m[35m [0m
[36m [0m[36m     SSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         1.6994599103927612          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanAbsoluteError     [0m[36m [0m[35m [0m[35m         49.379249572753906          [0m[35m [0m
[36m [0m[36mTSD/test_MeanAbsolutePercentageError[0m[36m [0m[35m [0m[35m          0.149032860994339          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanSquaredError      [0m[36m [0m[35m [0m[35m           4376.5986328125           [0m[35m [0m
[36m [0m[36m          TSD/test_R2Score          [0m[36m [0m[35m [0m[35m         0.38618898391723633         [0m[35m [0m
[36m [0m[36m        TSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.5511975288391113          [0m[35m [0m
[36m [0m[36m     TSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         2.5557641983032227          [0m[35m [0m
[36m [0m[36m   WS24_acid/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8487654328346252          [0m[35m [0m
[36m [0m[36m WS24_acid/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7222222089767456          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7222222089767456          [0m[35m [0m
[36m [0m[36mWS24_acid/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.4444444477558136          [0m[35m [0m
[36m [0m[36m     WS24_acid/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.8090811371803284          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.18408076465129852         [0m[35m [0m
[36m [0m[36m   WS24_base/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.4166666865348816          [0m[35m [0m
[36m [0m[36m WS24_base/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.8181818127632141          [0m[35m [0m
[36m [0m[36m  WS24_base/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.8181818127632141          [0m[35m [0m
[36m [0m[36mWS24_base/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.6552647352218628          [0m[35m [0m
[36m [0m[36m     WS24_base/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.9558181762695312          [0m[35m [0m
[36m [0m[36m  WS24_base/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.13148626685142517         [0m[35m [0m
[36m [0m[36m WS24_boiling/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.6982248425483704          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassAccuracy[0m[36m [0m[35m [0m[35m         0.6153846383094788          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.6153846383094788          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassMatthew[0m[36m [0m[35m [0m[35m         0.2601329982280731          [0m[35m [0m
[36m [0m[36m    WS24_boiling/test_loss_epoch    [0m[36m [0m[35m [0m[35m         1.5424652099609375          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         0.13477341830730438         [0m[35m [0m
[36m [0m[36m  WS24_water/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8004857301712036          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.7351598143577576          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7351598143577576          [0m[35m [0m
[36m [0m[36mWS24_water/test_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.4368033707141876          [0m[35m [0m
[36m [0m[36m     WS24_water/test_loss_epoch     [0m[36m [0m[35m [0m[35m         0.9606915712356567          [0m[35m [0m
[36m [0m[36m WS24_water/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m  WS24_water4/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.7994464039802551          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.5596330165863037          [0m[35m [0m
[36m [0m[36m WS24_water4/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.5596330165863037          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassMatthews[0m[36m [0m[35m [0m[35m          0.369854211807251          [0m[35m [0m
[36m [0m[36m    WS24_water4/test_loss_epoch     [0m[36m [0m[35m [0m[35m         1.8906464576721191          [0m[35m [0m
[36m [0m[36m WS24_water4/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m            test_Metric             [0m[36m [0m[35m [0m[35m         0.5626529281328234          [0m[35m [0m
[36m [0m[36m          test_loss_epoch           [0m[36m [0m[35m [0m[35m         2.1723403930664062          [0m[35m [0m

TSD/test_loss : tensor(0.5512)
TSD/test_loss_epoch : tensor(0.5512)
TSD/test_loss_weight : tensor(2.5558)
TSD/test_loss_weight_epoch : tensor(2.5558)
TSD/test_R2Score : tensor(0.3862)
TSD/test_MeanAbsoluteError : tensor(49.3792)
TSD/test_MeanAbsolutePercentageError : tensor(0.1490)
TSD/test_MeanSquaredError : tensor(4376.5986)
test_loss : tensor(2.1723)
test_loss_epoch : tensor(2.1723)
SSD/test_loss : tensor(0.8176)
SSD/test_loss_epoch : tensor(0.8176)
SSD/test_loss_weight : tensor(1.6995)
SSD/test_loss_weight_epoch : tensor(1.6995)
SSD/test_MulticlassAccuracy : tensor(0.6441)
SSD/test_MulticlassMatthewsCorrCoef : tensor(0.2712)
SSD/test_MulticlassF1Score : tensor(0.6441)
SSD/test_MulticlassAUROC : tensor(0.6998)
WS24_water/test_loss : tensor(0.9607)
WS24_water/test_loss_epoch : tensor(0.9607)
WS24_water/test_loss_weight : tensor(1.1472)
WS24_water/test_loss_weight_epoch : tensor(1.1472)
WS24_water/test_MulticlassAccuracy : tensor(0.7352)
WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4368)
WS24_water/test_MulticlassF1Score : tensor(0.7352)
WS24_water/test_MulticlassAUROC : tensor(0.8005)
WS24_water4/test_loss : tensor(1.8906)
WS24_water4/test_loss_epoch : tensor(1.8906)
WS24_water4/test_loss_weight : tensor(1.1472)
WS24_water4/test_loss_weight_epoch : tensor(1.1472)
WS24_water4/test_MulticlassAccuracy : tensor(0.5596)
WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3699)
WS24_water4/test_MulticlassF1Score : tensor(0.5596)
WS24_water4/test_MulticlassAUROC : tensor(0.7994)
WS24_acid/test_loss : tensor(0.8091)
WS24_acid/test_loss_epoch : tensor(0.8091)
WS24_acid/test_loss_weight : tensor(0.1841)
WS24_acid/test_loss_weight_epoch : tensor(0.1841)
WS24_acid/test_MulticlassAccuracy : tensor(0.7222)
WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.4444)
WS24_acid/test_MulticlassF1Score : tensor(0.7222)
WS24_acid/test_MulticlassAUROC : tensor(0.8488)
WS24_base/test_loss : tensor(0.9558)
WS24_base/test_loss_epoch : tensor(0.9558)
WS24_base/test_loss_weight : tensor(0.1315)
WS24_base/test_loss_weight_epoch : tensor(0.1315)
WS24_base/test_MulticlassAccuracy : tensor(0.8182)
WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.6553)
WS24_base/test_MulticlassF1Score : tensor(0.8182)
WS24_base/test_MulticlassAUROC : tensor(0.4167)
WS24_boiling/test_loss : tensor(1.5425)
WS24_boiling/test_loss_epoch : tensor(1.5425)
WS24_boiling/test_loss_weight : tensor(0.1348)
WS24_boiling/test_loss_weight_epoch : tensor(0.1348)
WS24_boiling/test_MulticlassAccuracy : tensor(0.6154)
WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.2601)
WS24_boiling/test_MulticlassF1Score : tensor(0.6154)
WS24_boiling/test_MulticlassAUROC : tensor(0.6982)
test_Metric : tensor(0.5627, dtype=torch.float64)
[I 2025-12-03 16:42:05,909] Trial 10 finished with value: 0.5156966360665889 and parameters: {'atom_fea_len': 208, 'h_fea_len': 240, 'n_conv': 2, 'n_h': 1, 'lr_mult': 2, 'extra_fea_len': 64, 'dropout': 0.7000000000000001}. Best is trial 8 with value: 0.5247209443643848.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 8
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 64
extra_fea_len : 20
h_fea_len : 240
n_conv : 4
n_h : 1
att_S : 64
dropout_prob : 0.4
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=208, bias=True)
  (embedding_atom_norm): LayerNorm((208,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-1): 2 x ConvLayer(
      (fc_full): Linear(in_features=457, out_features=416, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=64, bias=True)
  (embedding_extra_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=272, out_features=240, bias=True)
  (conv_to_fc_norm): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.7000000000000001, inplace=False)
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=240, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=240, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=240, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=240, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((240,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=240, out_features=240, bias=True)
      (key): Linear(in_features=240, out_features=240, bias=True)
      (value): Linear(in_features=240, out_features=240, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90195790>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90195e80>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90195d00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f901951c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90195520>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90195310>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90195be0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                 | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 1.3 M  | ?                                        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240]]]
1   | model.embedding_atom            | Linear              | 6.0 K  | [4608, 92]                               | [4608, 64]
2   | model.embedding_atom_norm       | LayerNorm           | 128    | [4608, 64]                               | [4608, 64]
3   | model.convs                     | ModuleList          | 88.6 K | ?                                        | ?
4   | model.convs.0                   | ConvLayer           | 22.1 K | [[4608, 64], [4608, 10, 41], [4608, 10]] | [4608, 64]
5   | model.convs.0.fc_full           | Linear              | 21.8 K | [4608, 10, 169]                          | [4608, 10, 128]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 64]                           | [4608, 10, 64]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 64]                           | [4608, 10, 64]
8   | model.convs.0.bn1               | BatchNorm1d         | 256    | [46080, 128]                             | [46080, 128]
9   | model.convs.0.bn2               | BatchNorm1d         | 128    | [4608, 64]                               | [4608, 64]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 64]                               | [4608, 64]
11  | model.convs.1                   | ConvLayer           | 22.1 K | [[4608, 64], [4608, 10, 41], [4608, 10]] | [4608, 64]
12  | model.convs.1.fc_full           | Linear              | 21.8 K | [4608, 10, 169]                          | [4608, 10, 128]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 64]                           | [4608, 10, 64]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 64]                           | [4608, 10, 64]
15  | model.convs.1.bn1               | BatchNorm1d         | 256    | [46080, 128]                             | [46080, 128]
16  | model.convs.1.bn2               | BatchNorm1d         | 128    | [4608, 64]                               | [4608, 64]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 64]                               | [4608, 64]
18  | model.convs.2                   | ConvLayer           | 22.1 K | [[4608, 64], [4608, 10, 41], [4608, 10]] | [4608, 64]
19  | model.convs.2.fc_full           | Linear              | 21.8 K | [4608, 10, 169]                          | [4608, 10, 128]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 64]                           | [4608, 10, 64]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 64]                           | [4608, 10, 64]
22  | model.convs.2.bn1               | BatchNorm1d         | 256    | [46080, 128]                             | [46080, 128]
23  | model.convs.2.bn2               | BatchNorm1d         | 128    | [4608, 64]                               | [4608, 64]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 64]                               | [4608, 64]
25  | model.convs.3                   | ConvLayer           | 22.1 K | [[4608, 64], [4608, 10, 41], [4608, 10]] | [4608, 64]
26  | model.convs.3.fc_full           | Linear              | 21.8 K | [4608, 10, 169]                          | [4608, 10, 128]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 64]                           | [4608, 10, 64]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 64]                           | [4608, 10, 64]
29  | model.convs.3.bn1               | BatchNorm1d         | 256    | [46080, 128]                             | [46080, 128]
30  | model.convs.3.bn2               | BatchNorm1d         | 128    | [4608, 64]                               | [4608, 64]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 64]                               | [4608, 64]
32  | model.embedding_extra           | Linear              | 140    | [256, 6]                                 | [256, 20]
33  | model.embedding_extra_norm      | BatchNorm1d         | 40     | [256, 20]                                | [256, 20]
34  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 20]                                | [256, 20]
35  | model.conv_to_fc                | Linear              | 20.4 K | [256, 84]                                | [256, 240]
36  | model.conv_to_fc_norm           | BatchNorm1d         | 480    | [256, 240]                               | [256, 240]
37  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 240]                               | [256, 240]
38  | model.dropout                   | Dropout             | 0      | [256, 240]                               | [256, 240]
39  | model.fc_outs                   | ModuleList          | 3.6 K  | ?                                        | ?
40  | model.fc_outs.0                 | OutputLayer         | 241    | [256, 240]                               | [256, 1]
41  | model.fc_outs.0.fc              | Linear              | 241    | [256, 240]                               | [256, 1]
42  | model.fc_outs.1                 | OutputLayer         | 482    | [256, 240]                               | [256, 2]
43  | model.fc_outs.1.fc              | Sequential          | 482    | [256, 240]                               | [256, 2]
44  | model.fc_outs.1.fc.0            | Linear              | 482    | [256, 240]                               | [256, 2]
45  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
46  | model.fc_outs.2                 | OutputLayer         | 482    | [256, 240]                               | [256, 2]
47  | model.fc_outs.2.fc              | Sequential          | 482    | [256, 240]                               | [256, 2]
48  | model.fc_outs.2.fc.0            | Linear              | 482    | [256, 240]                               | [256, 2]
49  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
50  | model.fc_outs.3                 | OutputLayer         | 964    | [256, 240]                               | [256, 4]
51  | model.fc_outs.3.fc              | Sequential          | 964    | [256, 240]                               | [256, 4]
52  | model.fc_outs.3.fc.0            | Linear              | 964    | [256, 240]                               | [256, 4]
53  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                 | [256, 4]
54  | model.fc_outs.4                 | OutputLayer         | 482    | [256, 240]                               | [256, 2]
55  | model.fc_outs.4.fc              | Sequential          | 482    | [256, 240]                               | [256, 2]
56  | model.fc_outs.4.fc.0            | Linear              | 482    | [256, 240]                               | [256, 2]
57  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
58  | model.fc_outs.5                 | OutputLayer         | 482    | [256, 240]                               | [256, 2]
59  | model.fc_outs.5.fc              | Sequential          | 482    | [256, 240]                               | [256, 2]
60  | model.fc_outs.5.fc.0            | Linear              | 482    | [256, 240]                               | [256, 2]
61  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
62  | model.fc_outs.6                 | OutputLayer         | 482    | [256, 240]                               | [256, 2]
63  | model.fc_outs.6.fc              | Sequential          | 482    | [256, 240]                               | [256, 2]
64  | model.fc_outs.6.fc.0            | Linear              | 482    | [256, 240]                               | [256, 2]
65  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
66  | model.task_norms                | ModuleList          | 3.4 K  | ?                                        | ?
67  | model.task_norms.0              | LayerNorm           | 480    | [256, 240]                               | [256, 240]
68  | model.task_norms.1              | LayerNorm           | 480    | [256, 240]                               | [256, 240]
69  | model.task_norms.2              | LayerNorm           | 480    | [256, 240]                               | [256, 240]
70  | model.task_norms.3              | LayerNorm           | 480    | [256, 240]                               | [256, 240]
71  | model.task_norms.4              | LayerNorm           | 480    | [256, 240]                               | [256, 240]
72  | model.task_norms.5              | LayerNorm           | 480    | [256, 240]                               | [256, 240]
73  | model.task_norms.6              | LayerNorm           | 480    | [256, 240]                               | [256, 240]
74  | model.task_attentions           | ModuleList          | 1.2 M  | ?                                        | ?
75  | model.task_attentions.0         | SelfAttention       | 173 K  | [256, 240]                               | [256, 240]
76  | model.task_attentions.0.query   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
77  | model.task_attentions.0.key     | Linear              | 57.8 K | [256, 240]                               | [256, 240]
78  | model.task_attentions.0.value   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
79  | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
80  | model.task_attentions.1         | SelfAttention       | 173 K  | [256, 240]                               | [256, 240]
81  | model.task_attentions.1.query   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
82  | model.task_attentions.1.key     | Linear              | 57.8 K | [256, 240]                               | [256, 240]
83  | model.task_attentions.1.value   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
84  | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
85  | model.task_attentions.2         | SelfAttention       | 173 K  | [256, 240]                               | [256, 240]
86  | model.task_attentions.2.query   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
87  | model.task_attentions.2.key     | Linear              | 57.8 K | [256, 240]                               | [256, 240]
88  | model.task_attentions.2.value   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
89  | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
90  | model.task_attentions.3         | SelfAttention       | 173 K  | [256, 240]                               | [256, 240]
91  | model.task_attentions.3.query   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
92  | model.task_attentions.3.key     | Linear              | 57.8 K | [256, 240]                               | [256, 240]
93  | model.task_attentions.3.value   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
94  | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
95  | model.task_attentions.4         | SelfAttention       | 173 K  | [256, 240]                               | [256, 240]
96  | model.task_attentions.4.query   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
97  | model.task_attentions.4.key     | Linear              | 57.8 K | [256, 240]                               | [256, 240]
98  | model.task_attentions.4.value   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
99  | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
100 | model.task_attentions.5         | SelfAttention       | 173 K  | [256, 240]                               | [256, 240]
101 | model.task_attentions.5.query   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
102 | model.task_attentions.5.key     | Linear              | 57.8 K | [256, 240]                               | [256, 240]
103 | model.task_attentions.5.value   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
104 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
105 | model.task_attentions.6         | SelfAttention       | 173 K  | [256, 240]                               | [256, 240]
106 | model.task_attentions.6.query   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
107 | model.task_attentions.6.key     | Linear              | 57.8 K | [256, 240]                               | [256, 240]
108 | model.task_attentions.6.value   | Linear              | 57.8 K | [256, 240]                               | [256, 240]
109 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.3 M     Trainable params
0         Non-trainable params
1.3 M     Total params
5.349     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 8 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 1.3 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240], [256, 240]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.3 M     Trainable params
0         Non-trainable params
1.3 M     Total params
5.349     Total estimated model params size (MB)
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(0): metric=0.3257 > best_metric=0.0000, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Epoch 0, global step 17: 'val_Metric' reached 0.32567 (best 0.32567), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=00-val_Metric=0.326.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 1, global step 34: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(2): metric=0.3775 > best_metric=0.3257, log val results..
Epoch 2, global step 51: 'val_Metric' reached 0.37749 (best 0.37749), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=02-val_Metric=0.377.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 3, global step 68: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 4, global step 85: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(5): metric=0.4332 > best_metric=0.3775, log val results..
Epoch 5, global step 102: 'val_Metric' reached 0.43320 (best 0.43320), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=05-val_Metric=0.433.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 6, global step 119: 'val_Metric' reached 0.43357 (best 0.43357), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=06-val_Metric=0.434.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 7, global step 136: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 8, global step 153: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(9): metric=0.4571 > best_metric=0.4332, log val results..
Epoch 9, global step 170: 'val_Metric' reached 0.45715 (best 0.45715), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=09-val_Metric=0.457.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 10, global step 187: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 11, global step 204: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 12, global step 221: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 13, global step 238: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 14, global step 255: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(15): metric=0.4758 > best_metric=0.4571, log val results..
Epoch 15, global step 272: 'val_Metric' reached 0.47580 (best 0.47580), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=15-val_Metric=0.476.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(16): metric=0.4839 > best_metric=0.4758, log val results..
Epoch 16, global step 289: 'val_Metric' reached 0.48387 (best 0.48387), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=16-val_Metric=0.484.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 17, global step 306: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(18): metric=0.4924 > best_metric=0.4839, log val results..
Epoch 18, global step 323: 'val_Metric' reached 0.49238 (best 0.49238), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=18-val_Metric=0.492.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(19): metric=0.4965 > best_metric=0.4924, log val results..
Epoch 19, global step 340: 'val_Metric' reached 0.49647 (best 0.49647), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=19-val_Metric=0.496.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 20, global step 357: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 21, global step 374: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 22, global step 391: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 23, global step 408: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(24): metric=0.5077 > best_metric=0.4965, log val results..
Epoch 24, global step 425: 'val_Metric' reached 0.50773 (best 0.50773), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=24-val_Metric=0.508.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 25, global step 442: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 26, global step 459: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 27, global step 476: 'val_Metric' reached 0.50809 (best 0.50809), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=27-val_Metric=0.508.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 28, global step 493: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 29, global step 510: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(30): metric=0.5096 > best_metric=0.5077, log val results..
Epoch 30, global step 527: 'val_Metric' reached 0.50959 (best 0.50959), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=30-val_Metric=0.510.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(31): metric=0.5281 > best_metric=0.5096, log val results..
Epoch 31, global step 544: 'val_Metric' reached 0.52805 (best 0.52805), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=31-val_Metric=0.528.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(32): metric=0.5307 > best_metric=0.5281, log val results..
Epoch 32, global step 561: 'val_Metric' reached 0.53074 (best 0.53074), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=32-val_Metric=0.531.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 33, global step 578: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 34, global step 595: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 35, global step 612: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 36, global step 629: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 37, global step 646: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 38, global step 663: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 39, global step 680: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 40, global step 697: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 41, global step 714: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 42, global step 731: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 43, global step 748: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 44, global step 765: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(45): metric=0.5396 > best_metric=0.5307, log val results..
Epoch 45, global step 782: 'val_Metric' reached 0.53961 (best 0.53961), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=45-val_Metric=0.540.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(46): metric=0.5448 > best_metric=0.5396, log val results..
Epoch 46, global step 799: 'val_Metric' reached 0.54476 (best 0.54476), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=46-val_Metric=0.545.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 47, global step 816: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 48, global step 833: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 49, global step 850: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 50, global step 867: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 51, global step 884: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 52, global step 901: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 53, global step 918: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 54, global step 935: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 55, global step 952: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 56, global step 969: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 57, global step 986: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 58, global step 1003: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 59, global step 1020: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 60, global step 1037: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 61, global step 1054: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 62, global step 1071: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 63, global step 1088: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 64, global step 1105: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 65, global step 1122: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 66, global step 1139: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 67, global step 1156: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 68, global step 1173: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 69, global step 1190: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(70): metric=0.5537 > best_metric=0.5448, log val results..
Epoch 70, global step 1207: 'val_Metric' reached 0.55366 (best 0.55366), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=70-val_Metric=0.554.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(71): metric=0.5553 > best_metric=0.5537, log val results..
Epoch 71, global step 1224: 'val_Metric' reached 0.55528 (best 0.55528), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=71-val_Metric=0.555.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 72, global step 1241: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 73, global step 1258: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 74, global step 1275: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 75, global step 1292: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 76, global step 1309: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 77, global step 1326: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 78, global step 1343: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 79, global step 1360: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 80, global step 1377: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 81, global step 1394: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 82, global step 1411: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 83, global step 1428: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 84, global step 1445: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 85, global step 1462: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 86, global step 1479: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 87, global step 1496: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 88, global step 1513: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 89, global step 1530: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 90, global step 1547: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 91, global step 1564: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 92, global step 1581: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 93, global step 1598: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 94, global step 1615: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 95, global step 1632: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 96, global step 1649: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 97, global step 1666: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 98, global step 1683: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 99, global step 1700: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 100, global step 1717: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 101, global step 1734: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 102, global step 1751: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 103, global step 1768: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 104, global step 1785: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 105, global step 1802: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 106, global step 1819: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 107, global step 1836: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 108, global step 1853: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 109, global step 1870: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 110, global step 1887: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 111, global step 1904: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 112, global step 1921: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 113, global step 1938: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 114, global step 1955: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 115, global step 1972: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 116, global step 1989: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 117, global step 2006: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 118, global step 2023: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 119, global step 2040: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 120, global step 2057: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 121, global step 2074: 'val_Metric' was not in top 1
Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=71-val_Metric=0.555.ckpt
##################################################best
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=71-val_Metric=0.555.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=71-val_Metric=0.555.ckpt
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m           Validate metric           [0m[1m [0m[1m [0m[1m            DataLoader 0            [0m[1m [0m

[36m [0m[36m       SSD/val_MulticlassAUROC       [0m[36m [0m[35m [0m[35m         0.7321104407310486         [0m[35m [0m
[36m [0m[36m     SSD/val_MulticlassAccuracy      [0m[36m [0m[35m [0m[35m         0.6797875165939331         [0m[35m [0m
[36m [0m[36m      SSD/val_MulticlassF1Score      [0m[36m [0m[35m [0m[35m         0.6797875165939331         [0m[35m [0m
[36m [0m[36m SSD/val_MulticlassMatthewsCorrCoef  [0m[36m [0m[35m [0m[35m        0.34618866443634033         [0m[35m [0m
[36m [0m[36m         SSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         1.212393045425415          [0m[35m [0m
[36m [0m[36m      SSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         1.6994599103927612         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanAbsoluteError      [0m[36m [0m[35m [0m[35m          50.047607421875           [0m[35m [0m
[36m [0m[36m TSD/val_MeanAbsolutePercentageError [0m[36m [0m[35m [0m[35m         0.1474381387233734         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanSquaredError       [0m[36m [0m[35m [0m[35m          4317.69970703125          [0m[35m [0m
[36m [0m[36m           TSD/val_R2Score           [0m[36m [0m[35m [0m[35m        0.43891721963882446         [0m[35m [0m
[36m [0m[36m         TSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.5437796711921692         [0m[35m [0m
[36m [0m[36m      TSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         2.5557641983032227         [0m[35m [0m
[36m [0m[36m    WS24_acid/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7551020383834839         [0m[35m [0m
[36m [0m[36m  WS24_acid/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m                0.75                [0m[35m [0m
[36m [0m[36m   WS24_acid/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m                0.75                [0m[35m [0m
[36m [0m[36mWS24_acid/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m         0.511890709400177          [0m[35m [0m
[36m [0m[36m      WS24_acid/val_loss_epoch       [0m[36m [0m[35m [0m[35m         1.5395429134368896         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.18408076465129852         [0m[35m [0m
[36m [0m[36m    WS24_base/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m               0.1875               [0m[35m [0m
[36m [0m[36m  WS24_base/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.4791666567325592         [0m[35m [0m
[36m [0m[36m   WS24_base/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.4791666567325592         [0m[35m [0m
[36m [0m[36mWS24_base/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m        -0.2203865349292755         [0m[35m [0m
[36m [0m[36m      WS24_base/val_loss_epoch       [0m[36m [0m[35m [0m[35m          7.24116325378418          [0m[35m [0m
[36m [0m[36m   WS24_base/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.13148626685142517         [0m[35m [0m
[36m [0m[36m  WS24_boiling/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.5902777910232544         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.5833333134651184         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5833333134651184         [0m[35m [0m
[36m [0m[36mWS24_boiling/val_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.1666666716337204         [0m[35m [0m
[36m [0m[36m     WS24_boiling/val_loss_epoch     [0m[36m [0m[35m [0m[35m         3.366994857788086          [0m[35m [0m
[36m [0m[36m WS24_boiling/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m        0.13477341830730438         [0m[35m [0m
[36m [0m[36m   WS24_water/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7757206559181213         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7277777791023254         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7277777791023254         [0m[35m [0m
[36m [0m[36mWS24_water/val_MulticlassMatthewsCor[0m[36m [0m[35m [0m[35m         0.4709424674510956         [0m[35m [0m
[36m [0m[36m      WS24_water/val_loss_epoch      [0m[36m [0m[35m [0m[35m         1.8055081367492676         [0m[35m [0m
[36m [0m[36m  WS24_water/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m   WS24_water4/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7610795497894287         [0m[35m [0m
[36m [0m[36m WS24_water4/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.6057142615318298         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.6057142615318298         [0m[35m [0m
[36m [0m[36mWS24_water4/val_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.3846059739589691         [0m[35m [0m
[36m [0m[36m     WS24_water4/val_loss_epoch      [0m[36m [0m[35m [0m[35m         3.0392589569091797         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m       val_MergedMetric_epoch        [0m[36m [0m[35m [0m[35m         0.5674644708633423         [0m[35m [0m
[36m [0m[36m             val_Metric              [0m[36m [0m[35m [0m[35m         0.5552837604230226         [0m[35m [0m
[36m [0m[36m           val_loss_epoch            [0m[36m [0m[35m [0m[35m         3.434218645095825          [0m[35m [0m

TSD/val_loss : tensor(0.5438)
TSD/val_loss_epoch : tensor(0.5438)
TSD/val_loss_weight : tensor(2.5558)
TSD/val_loss_weight_epoch : tensor(2.5558)
TSD/val_R2Score : tensor(0.4389)
TSD/val_MeanAbsoluteError : tensor(50.0476)
TSD/val_MeanAbsolutePercentageError : tensor(0.1474)
TSD/val_MeanSquaredError : tensor(4317.6997)
val_loss : tensor(3.4342)
val_loss_epoch : tensor(3.4342)
val_MergedMetric : tensor(0.5675)
val_MergedMetric_epoch : tensor(0.5675)
SSD/val_loss : tensor(1.2124)
SSD/val_loss_epoch : tensor(1.2124)
SSD/val_loss_weight : tensor(1.6995)
SSD/val_loss_weight_epoch : tensor(1.6995)
SSD/val_MulticlassAccuracy : tensor(0.6798)
SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3462)
SSD/val_MulticlassF1Score : tensor(0.6798)
SSD/val_MulticlassAUROC : tensor(0.7321)
WS24_water/val_loss : tensor(1.8055)
WS24_water/val_loss_epoch : tensor(1.8055)
WS24_water/val_loss_weight : tensor(1.1472)
WS24_water/val_loss_weight_epoch : tensor(1.1472)
WS24_water/val_MulticlassAccuracy : tensor(0.7278)
WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.4709)
WS24_water/val_MulticlassF1Score : tensor(0.7278)
WS24_water/val_MulticlassAUROC : tensor(0.7757)
WS24_water4/val_loss : tensor(3.0393)
WS24_water4/val_loss_epoch : tensor(3.0393)
WS24_water4/val_loss_weight : tensor(1.1472)
WS24_water4/val_loss_weight_epoch : tensor(1.1472)
WS24_water4/val_MulticlassAccuracy : tensor(0.6057)
WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.3846)
WS24_water4/val_MulticlassF1Score : tensor(0.6057)
WS24_water4/val_MulticlassAUROC : tensor(0.7611)
WS24_acid/val_loss : tensor(1.5395)
WS24_acid/val_loss_epoch : tensor(1.5395)
WS24_acid/val_loss_weight : tensor(0.1841)
WS24_acid/val_loss_weight_epoch : tensor(0.1841)
WS24_acid/val_MulticlassAccuracy : tensor(0.7500)
WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.5119)
WS24_acid/val_MulticlassF1Score : tensor(0.7500)
WS24_acid/val_MulticlassAUROC : tensor(0.7551)
WS24_base/val_loss : tensor(7.2412)
WS24_base/val_loss_epoch : tensor(7.2412)
WS24_base/val_loss_weight : tensor(0.1315)
WS24_base/val_loss_weight_epoch : tensor(0.1315)
WS24_base/val_MulticlassAccuracy : tensor(0.4792)
WS24_base/val_MulticlassMatthewsCorrCoef : tensor(-0.2204)
WS24_base/val_MulticlassF1Score : tensor(0.4792)
WS24_base/val_MulticlassAUROC : tensor(0.1875)
WS24_boiling/val_loss : tensor(3.3670)
WS24_boiling/val_loss_epoch : tensor(3.3670)
WS24_boiling/val_loss_weight : tensor(0.1348)
WS24_boiling/val_loss_weight_epoch : tensor(0.1348)
WS24_boiling/val_MulticlassAccuracy : tensor(0.5833)
WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.1667)
WS24_boiling/val_MulticlassF1Score : tensor(0.5833)
WS24_boiling/val_MulticlassAUROC : tensor(0.5903)
val_Metric : tensor(0.5553, dtype=torch.float64)
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=71-val_Metric=0.555.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_9/checkpoints/best-epoch=71-val_Metric=0.555.ckpt
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m            Test metric             [0m[1m [0m[1m [0m[1m            DataLoader 0             [0m[1m [0m

[36m [0m[36m      SSD/test_MulticlassAUROC      [0m[36m [0m[35m [0m[35m         0.7324450016021729          [0m[35m [0m
[36m [0m[36m    SSD/test_MulticlassAccuracy     [0m[36m [0m[35m [0m[35m         0.7296006679534912          [0m[35m [0m
[36m [0m[36m     SSD/test_MulticlassF1Score     [0m[36m [0m[35m [0m[35m         0.7296006679534912          [0m[35m [0m
[36m [0m[36mSSD/test_MulticlassMatthewsCorrCoef [0m[36m [0m[35m [0m[35m         0.42254915833473206         [0m[35m [0m
[36m [0m[36m        SSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         1.1035488843917847          [0m[35m [0m
[36m [0m[36m     SSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         1.6994599103927612          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanAbsoluteError     [0m[36m [0m[35m [0m[35m          51.83533477783203          [0m[35m [0m
[36m [0m[36mTSD/test_MeanAbsolutePercentageError[0m[36m [0m[35m [0m[35m         0.15911772847175598         [0m[35m [0m
[36m [0m[36m     TSD/test_MeanSquaredError      [0m[36m [0m[35m [0m[35m           4648.9091796875           [0m[35m [0m
[36m [0m[36m          TSD/test_R2Score          [0m[36m [0m[35m [0m[35m         0.3486602008342743          [0m[35m [0m
[36m [0m[36m        TSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.5854928493499756          [0m[35m [0m
[36m [0m[36m     TSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         2.5557641983032227          [0m[35m [0m
[36m [0m[36m   WS24_acid/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8703703880310059          [0m[35m [0m
[36m [0m[36m WS24_acid/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36mWS24_acid/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.5698028802871704          [0m[35m [0m
[36m [0m[36m     WS24_acid/test_loss_epoch      [0m[36m [0m[35m [0m[35m          0.908257246017456          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.18408076465129852         [0m[35m [0m
[36m [0m[36m   WS24_base/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.40833333134651184         [0m[35m [0m
[36m [0m[36m WS24_base/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.8636363744735718          [0m[35m [0m
[36m [0m[36m  WS24_base/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.8636363744735718          [0m[35m [0m
[36m [0m[36mWS24_base/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.7501487731933594          [0m[35m [0m
[36m [0m[36m     WS24_base/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.6397719979286194          [0m[35m [0m
[36m [0m[36m  WS24_base/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.13148626685142517         [0m[35m [0m
[36m [0m[36m WS24_boiling/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.6627218723297119          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassAccuracy[0m[36m [0m[35m [0m[35m         0.6538461446762085          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.6538461446762085          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassMatthew[0m[36m [0m[35m [0m[35m         0.3162277936935425          [0m[35m [0m
[36m [0m[36m    WS24_boiling/test_loss_epoch    [0m[36m [0m[35m [0m[35m         2.2707340717315674          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         0.13477341830730438         [0m[35m [0m
[36m [0m[36m  WS24_water/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8132807016372681          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m          0.767123281955719          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m          0.767123281955719          [0m[35m [0m
[36m [0m[36mWS24_water/test_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.5184743404388428          [0m[35m [0m
[36m [0m[36m     WS24_water/test_loss_epoch     [0m[36m [0m[35m [0m[35m          1.214360237121582          [0m[35m [0m
[36m [0m[36m WS24_water/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m  WS24_water4/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m          0.843621015548706          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.6834862232208252          [0m[35m [0m
[36m [0m[36m WS24_water4/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.6834862232208252          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassMatthews[0m[36m [0m[35m [0m[35m          0.481229305267334          [0m[35m [0m
[36m [0m[36m    WS24_water4/test_loss_epoch     [0m[36m [0m[35m [0m[35m         2.9513659477233887          [0m[35m [0m
[36m [0m[36m WS24_water4/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m            test_Metric             [0m[36m [0m[35m [0m[35m          0.57276533301289           [0m[35m [0m
[36m [0m[36m          test_loss_epoch           [0m[36m [0m[35m [0m[35m          2.904232978820801          [0m[35m [0m

TSD/test_loss : tensor(0.5855)
TSD/test_loss_epoch : tensor(0.5855)
TSD/test_loss_weight : tensor(2.5558)
TSD/test_loss_weight_epoch : tensor(2.5558)
TSD/test_R2Score : tensor(0.3487)
TSD/test_MeanAbsoluteError : tensor(51.8353)
TSD/test_MeanAbsolutePercentageError : tensor(0.1591)
TSD/test_MeanSquaredError : tensor(4648.9092)
test_loss : tensor(2.9042)
test_loss_epoch : tensor(2.9042)
SSD/test_loss : tensor(1.1035)
SSD/test_loss_epoch : tensor(1.1035)
SSD/test_loss_weight : tensor(1.6995)
SSD/test_loss_weight_epoch : tensor(1.6995)
SSD/test_MulticlassAccuracy : tensor(0.7296)
SSD/test_MulticlassMatthewsCorrCoef : tensor(0.4225)
SSD/test_MulticlassF1Score : tensor(0.7296)
SSD/test_MulticlassAUROC : tensor(0.7324)
WS24_water/test_loss : tensor(1.2144)
WS24_water/test_loss_epoch : tensor(1.2144)
WS24_water/test_loss_weight : tensor(1.1472)
WS24_water/test_loss_weight_epoch : tensor(1.1472)
WS24_water/test_MulticlassAccuracy : tensor(0.7671)
WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.5185)
WS24_water/test_MulticlassF1Score : tensor(0.7671)
WS24_water/test_MulticlassAUROC : tensor(0.8133)
WS24_water4/test_loss : tensor(2.9514)
WS24_water4/test_loss_epoch : tensor(2.9514)
WS24_water4/test_loss_weight : tensor(1.1472)
WS24_water4/test_loss_weight_epoch : tensor(1.1472)
WS24_water4/test_MulticlassAccuracy : tensor(0.6835)
WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.4812)
WS24_water4/test_MulticlassF1Score : tensor(0.6835)
WS24_water4/test_MulticlassAUROC : tensor(0.8436)
WS24_acid/test_loss : tensor(0.9083)
WS24_acid/test_loss_epoch : tensor(0.9083)
WS24_acid/test_loss_weight : tensor(0.1841)
WS24_acid/test_loss_weight_epoch : tensor(0.1841)
WS24_acid/test_MulticlassAccuracy : tensor(0.7778)
WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.5698)
WS24_acid/test_MulticlassF1Score : tensor(0.7778)
WS24_acid/test_MulticlassAUROC : tensor(0.8704)
WS24_base/test_loss : tensor(0.6398)
WS24_base/test_loss_epoch : tensor(0.6398)
WS24_base/test_loss_weight : tensor(0.1315)
WS24_base/test_loss_weight_epoch : tensor(0.1315)
WS24_base/test_MulticlassAccuracy : tensor(0.8636)
WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.7501)
WS24_base/test_MulticlassF1Score : tensor(0.8636)
WS24_base/test_MulticlassAUROC : tensor(0.4083)
WS24_boiling/test_loss : tensor(2.2707)
WS24_boiling/test_loss_epoch : tensor(2.2707)
WS24_boiling/test_loss_weight : tensor(0.1348)
WS24_boiling/test_loss_weight_epoch : tensor(0.1348)
WS24_boiling/test_MulticlassAccuracy : tensor(0.6538)
WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.3162)
WS24_boiling/test_MulticlassF1Score : tensor(0.6538)
WS24_boiling/test_MulticlassAUROC : tensor(0.6627)
test_Metric : tensor(0.5728, dtype=torch.float64)
[I 2025-12-03 17:13:26,559] Trial 11 finished with value: 0.4707919482871162 and parameters: {'atom_fea_len': 64, 'h_fea_len': 240, 'n_conv': 4, 'n_h': 1, 'lr_mult': 8, 'extra_fea_len': 20, 'dropout': 0.4}. Best is trial 8 with value: 0.5247209443643848.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 18
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 160
extra_fea_len : 32
h_fea_len : 144
n_conv : 5
n_h : 3
att_S : 64
dropout_prob : 0.35000000000000003
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=64, bias=True)
  (embedding_atom_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-3): 4 x ConvLayer(
      (fc_full): Linear(in_features=169, out_features=128, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=20, bias=True)
  (embedding_extra_norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=84, out_features=240, bias=True)
  (conv_to_fc_norm): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.4, inplace=False)
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=240, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=240, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=240, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=240, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((240,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=240, out_features=240, bias=True)
      (key): Linear(in_features=240, out_features=240, bias=True)
      (value): Linear(in_features=240, out_features=240, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9293c130>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9293c2e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9293ca30>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9293c5b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9293c6d0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9293c910>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f9293cfd0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 1.1 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144]]]
1   | model.embedding_atom            | Linear              | 14.9 K | [4608, 92]                                | [4608, 160]
2   | model.embedding_atom_norm       | LayerNorm           | 320    | [4608, 160]                               | [4608, 160]
3   | model.convs                     | ModuleList          | 584 K  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 116 K  | [[4608, 160], [4608, 10, 41], [4608, 10]] | [4608, 160]
5   | model.convs.0.fc_full           | Linear              | 115 K  | [4608, 10, 361]                           | [4608, 10, 320]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 160]                           | [4608, 10, 160]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 160]                           | [4608, 10, 160]
8   | model.convs.0.bn1               | BatchNorm1d         | 640    | [46080, 320]                              | [46080, 320]
9   | model.convs.0.bn2               | BatchNorm1d         | 320    | [4608, 160]                               | [4608, 160]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 160]                               | [4608, 160]
11  | model.convs.1                   | ConvLayer           | 116 K  | [[4608, 160], [4608, 10, 41], [4608, 10]] | [4608, 160]
12  | model.convs.1.fc_full           | Linear              | 115 K  | [4608, 10, 361]                           | [4608, 10, 320]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 160]                           | [4608, 10, 160]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 160]                           | [4608, 10, 160]
15  | model.convs.1.bn1               | BatchNorm1d         | 640    | [46080, 320]                              | [46080, 320]
16  | model.convs.1.bn2               | BatchNorm1d         | 320    | [4608, 160]                               | [4608, 160]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 160]                               | [4608, 160]
18  | model.convs.2                   | ConvLayer           | 116 K  | [[4608, 160], [4608, 10, 41], [4608, 10]] | [4608, 160]
19  | model.convs.2.fc_full           | Linear              | 115 K  | [4608, 10, 361]                           | [4608, 10, 320]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 160]                           | [4608, 10, 160]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 160]                           | [4608, 10, 160]
22  | model.convs.2.bn1               | BatchNorm1d         | 640    | [46080, 320]                              | [46080, 320]
23  | model.convs.2.bn2               | BatchNorm1d         | 320    | [4608, 160]                               | [4608, 160]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 160]                               | [4608, 160]
25  | model.convs.3                   | ConvLayer           | 116 K  | [[4608, 160], [4608, 10, 41], [4608, 10]] | [4608, 160]
26  | model.convs.3.fc_full           | Linear              | 115 K  | [4608, 10, 361]                           | [4608, 10, 320]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 160]                           | [4608, 10, 160]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 160]                           | [4608, 10, 160]
29  | model.convs.3.bn1               | BatchNorm1d         | 640    | [46080, 320]                              | [46080, 320]
30  | model.convs.3.bn2               | BatchNorm1d         | 320    | [4608, 160]                               | [4608, 160]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 160]                               | [4608, 160]
32  | model.convs.4                   | ConvLayer           | 116 K  | [[4608, 160], [4608, 10, 41], [4608, 10]] | [4608, 160]
33  | model.convs.4.fc_full           | Linear              | 115 K  | [4608, 10, 361]                           | [4608, 10, 320]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 160]                           | [4608, 10, 160]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 160]                           | [4608, 10, 160]
36  | model.convs.4.bn1               | BatchNorm1d         | 640    | [46080, 320]                              | [46080, 320]
37  | model.convs.4.bn2               | BatchNorm1d         | 320    | [4608, 160]                               | [4608, 160]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 160]                               | [4608, 160]
39  | model.embedding_extra           | Linear              | 224    | [256, 6]                                  | [256, 32]
40  | model.embedding_extra_norm      | BatchNorm1d         | 64     | [256, 32]                                 | [256, 32]
41  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 32]                                 | [256, 32]
42  | model.conv_to_fc                | Linear              | 27.8 K | [256, 192]                                | [256, 144]
43  | model.conv_to_fc_norm           | BatchNorm1d         | 288    | [256, 144]                                | [256, 144]
44  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 144]                                | [256, 144]
45  | model.dropout                   | Dropout             | 0      | [256, 144]                                | [256, 144]
46  | model.fcs                       | ModuleList          | 41.8 K | ?                                         | ?
47  | model.fcs.0                     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
48  | model.fcs.1                     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
49  | model.norms                     | ModuleList          | 576    | ?                                         | ?
50  | model.norms.0                   | BatchNorm1d         | 288    | [256, 144]                                | [256, 144]
51  | model.norms.1                   | BatchNorm1d         | 288    | [256, 144]                                | [256, 144]
52  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
53  | model.softpluses.0              | Softplus            | 0      | [256, 144]                                | [256, 144]
54  | model.softpluses.1              | Softplus            | 0      | [256, 144]                                | [256, 144]
55  | model.fc_outs                   | ModuleList          | 2.2 K  | ?                                         | ?
56  | model.fc_outs.0                 | OutputLayer         | 145    | [256, 144]                                | [256, 1]
57  | model.fc_outs.0.fc              | Linear              | 145    | [256, 144]                                | [256, 1]
58  | model.fc_outs.1                 | OutputLayer         | 290    | [256, 144]                                | [256, 2]
59  | model.fc_outs.1.fc              | Sequential          | 290    | [256, 144]                                | [256, 2]
60  | model.fc_outs.1.fc.0            | Linear              | 290    | [256, 144]                                | [256, 2]
61  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
62  | model.fc_outs.2                 | OutputLayer         | 290    | [256, 144]                                | [256, 2]
63  | model.fc_outs.2.fc              | Sequential          | 290    | [256, 144]                                | [256, 2]
64  | model.fc_outs.2.fc.0            | Linear              | 290    | [256, 144]                                | [256, 2]
65  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
66  | model.fc_outs.3                 | OutputLayer         | 580    | [256, 144]                                | [256, 4]
67  | model.fc_outs.3.fc              | Sequential          | 580    | [256, 144]                                | [256, 4]
68  | model.fc_outs.3.fc.0            | Linear              | 580    | [256, 144]                                | [256, 4]
69  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
70  | model.fc_outs.4                 | OutputLayer         | 290    | [256, 144]                                | [256, 2]
71  | model.fc_outs.4.fc              | Sequential          | 290    | [256, 144]                                | [256, 2]
72  | model.fc_outs.4.fc.0            | Linear              | 290    | [256, 144]                                | [256, 2]
73  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
74  | model.fc_outs.5                 | OutputLayer         | 290    | [256, 144]                                | [256, 2]
75  | model.fc_outs.5.fc              | Sequential          | 290    | [256, 144]                                | [256, 2]
76  | model.fc_outs.5.fc.0            | Linear              | 290    | [256, 144]                                | [256, 2]
77  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
78  | model.fc_outs.6                 | OutputLayer         | 290    | [256, 144]                                | [256, 2]
79  | model.fc_outs.6.fc              | Sequential          | 290    | [256, 144]                                | [256, 2]
80  | model.fc_outs.6.fc.0            | Linear              | 290    | [256, 144]                                | [256, 2]
81  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
82  | model.task_norms                | ModuleList          | 2.0 K  | ?                                         | ?
83  | model.task_norms.0              | LayerNorm           | 288    | [256, 144]                                | [256, 144]
84  | model.task_norms.1              | LayerNorm           | 288    | [256, 144]                                | [256, 144]
85  | model.task_norms.2              | LayerNorm           | 288    | [256, 144]                                | [256, 144]
86  | model.task_norms.3              | LayerNorm           | 288    | [256, 144]                                | [256, 144]
87  | model.task_norms.4              | LayerNorm           | 288    | [256, 144]                                | [256, 144]
88  | model.task_norms.5              | LayerNorm           | 288    | [256, 144]                                | [256, 144]
89  | model.task_norms.6              | LayerNorm           | 288    | [256, 144]                                | [256, 144]
90  | model.task_attentions           | ModuleList          | 438 K  | ?                                         | ?
91  | model.task_attentions.0         | SelfAttention       | 62.6 K | [256, 144]                                | [256, 144]
92  | model.task_attentions.0.query   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
93  | model.task_attentions.0.key     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
94  | model.task_attentions.0.value   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
95  | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
96  | model.task_attentions.1         | SelfAttention       | 62.6 K | [256, 144]                                | [256, 144]
97  | model.task_attentions.1.query   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
98  | model.task_attentions.1.key     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
99  | model.task_attentions.1.value   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
100 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
101 | model.task_attentions.2         | SelfAttention       | 62.6 K | [256, 144]                                | [256, 144]
102 | model.task_attentions.2.query   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
103 | model.task_attentions.2.key     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
104 | model.task_attentions.2.value   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
105 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
106 | model.task_attentions.3         | SelfAttention       | 62.6 K | [256, 144]                                | [256, 144]
107 | model.task_attentions.3.query   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
108 | model.task_attentions.3.key     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
109 | model.task_attentions.3.value   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
110 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
111 | model.task_attentions.4         | SelfAttention       | 62.6 K | [256, 144]                                | [256, 144]
112 | model.task_attentions.4.query   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
113 | model.task_attentions.4.key     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
114 | model.task_attentions.4.value   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
115 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
116 | model.task_attentions.5         | SelfAttention       | 62.6 K | [256, 144]                                | [256, 144]
117 | model.task_attentions.5.query   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
118 | model.task_attentions.5.key     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
119 | model.task_attentions.5.value   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
120 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
121 | model.task_attentions.6         | SelfAttention       | 62.6 K | [256, 144]                                | [256, 144]
122 | model.task_attentions.6.query   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
123 | model.task_attentions.6.key     | Linear              | 20.9 K | [256, 144]                                | [256, 144]
124 | model.task_attentions.6.value   | Linear              | 20.9 K | [256, 144]                                | [256, 144]
125 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.450     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_10
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 18 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 1.1 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.450     Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 17:13:38,016] Trial 12 failed with parameters: {'atom_fea_len': 160, 'h_fea_len': 144, 'n_conv': 5, 'n_h': 3, 'lr_mult': 18, 'extra_fea_len': 32, 'dropout': 0.35000000000000003} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 492.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 368.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.46 GiB memory in use. Of the allocated memory 20.94 GiB is allocated by PyTorch, and 299.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 96, in forward
    nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 492.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 368.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.46 GiB memory in use. Of the allocated memory 20.94 GiB is allocated by PyTorch, and 299.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 17:13:38,020] Trial 12 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 2
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 96
extra_fea_len : 60
h_fea_len : 144
n_conv : 10
n_h : 7
att_S : 64
dropout_prob : 0.35000000000000003
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=160, bias=True)
  (embedding_atom_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-4): 5 x ConvLayer(
      (fc_full): Linear(in_features=361, out_features=320, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=32, bias=True)
  (embedding_extra_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=192, out_features=144, bias=True)
  (conv_to_fc_norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.35000000000000003, inplace=False)
  (fcs): ModuleList(
    (0-1): 2 x Linear(in_features=144, out_features=144, bias=True)
  )
  (norms): ModuleList(
    (0-1): 2 x BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-1): 2 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=144, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=144, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=144, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=144, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((144,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=144, out_features=144, bias=True)
      (key): Linear(in_features=144, out_features=144, bias=True)
      (value): Linear(in_features=144, out_features=144, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92bbe850>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92bbe880>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92bbe160>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92bbee20>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92bbe8b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92bbe130>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92bbe8e0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                 | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 1.1 M  | ?                                        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144]]]
1   | model.embedding_atom            | Linear              | 8.9 K  | [4608, 92]                               | [4608, 96]
2   | model.embedding_atom_norm       | LayerNorm           | 192    | [4608, 96]                               | [4608, 96]
3   | model.convs                     | ModuleList          | 455 K  | ?                                        | ?
4   | model.convs.0                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
5   | model.convs.0.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
8   | model.convs.0.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
9   | model.convs.0.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
11  | model.convs.1                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
12  | model.convs.1.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
15  | model.convs.1.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
16  | model.convs.1.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
18  | model.convs.2                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
19  | model.convs.2.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
22  | model.convs.2.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
23  | model.convs.2.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
25  | model.convs.3                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
26  | model.convs.3.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
29  | model.convs.3.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
30  | model.convs.3.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
32  | model.convs.4                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
33  | model.convs.4.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
36  | model.convs.4.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
37  | model.convs.4.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
39  | model.convs.5                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
40  | model.convs.5.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
43  | model.convs.5.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
44  | model.convs.5.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
46  | model.convs.6                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
47  | model.convs.6.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
50  | model.convs.6.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
51  | model.convs.6.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
53  | model.convs.7                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
54  | model.convs.7.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
57  | model.convs.7.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
58  | model.convs.7.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
60  | model.convs.8                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
61  | model.convs.8.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
62  | model.convs.8.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
63  | model.convs.8.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
64  | model.convs.8.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
65  | model.convs.8.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
66  | model.convs.8.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
67  | model.convs.9                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
68  | model.convs.9.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
69  | model.convs.9.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
70  | model.convs.9.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
71  | model.convs.9.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
72  | model.convs.9.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
73  | model.convs.9.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
74  | model.embedding_extra           | Linear              | 420    | [256, 6]                                 | [256, 60]
75  | model.embedding_extra_norm      | BatchNorm1d         | 120    | [256, 60]                                | [256, 60]
76  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 60]                                | [256, 60]
77  | model.conv_to_fc                | Linear              | 22.6 K | [256, 156]                               | [256, 144]
78  | model.conv_to_fc_norm           | BatchNorm1d         | 288    | [256, 144]                               | [256, 144]
79  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 144]                               | [256, 144]
80  | model.dropout                   | Dropout             | 0      | [256, 144]                               | [256, 144]
81  | model.fcs                       | ModuleList          | 125 K  | ?                                        | ?
82  | model.fcs.0                     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
83  | model.fcs.1                     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
84  | model.fcs.2                     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
85  | model.fcs.3                     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
86  | model.fcs.4                     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
87  | model.fcs.5                     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
88  | model.norms                     | ModuleList          | 1.7 K  | ?                                        | ?
89  | model.norms.0                   | BatchNorm1d         | 288    | [256, 144]                               | [256, 144]
90  | model.norms.1                   | BatchNorm1d         | 288    | [256, 144]                               | [256, 144]
91  | model.norms.2                   | BatchNorm1d         | 288    | [256, 144]                               | [256, 144]
92  | model.norms.3                   | BatchNorm1d         | 288    | [256, 144]                               | [256, 144]
93  | model.norms.4                   | BatchNorm1d         | 288    | [256, 144]                               | [256, 144]
94  | model.norms.5                   | BatchNorm1d         | 288    | [256, 144]                               | [256, 144]
95  | model.softpluses                | ModuleList          | 0      | ?                                        | ?
96  | model.softpluses.0              | Softplus            | 0      | [256, 144]                               | [256, 144]
97  | model.softpluses.1              | Softplus            | 0      | [256, 144]                               | [256, 144]
98  | model.softpluses.2              | Softplus            | 0      | [256, 144]                               | [256, 144]
99  | model.softpluses.3              | Softplus            | 0      | [256, 144]                               | [256, 144]
100 | model.softpluses.4              | Softplus            | 0      | [256, 144]                               | [256, 144]
101 | model.softpluses.5              | Softplus            | 0      | [256, 144]                               | [256, 144]
102 | model.fc_outs                   | ModuleList          | 2.2 K  | ?                                        | ?
103 | model.fc_outs.0                 | OutputLayer         | 145    | [256, 144]                               | [256, 1]
104 | model.fc_outs.0.fc              | Linear              | 145    | [256, 144]                               | [256, 1]
105 | model.fc_outs.1                 | OutputLayer         | 290    | [256, 144]                               | [256, 2]
106 | model.fc_outs.1.fc              | Sequential          | 290    | [256, 144]                               | [256, 2]
107 | model.fc_outs.1.fc.0            | Linear              | 290    | [256, 144]                               | [256, 2]
108 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
109 | model.fc_outs.2                 | OutputLayer         | 290    | [256, 144]                               | [256, 2]
110 | model.fc_outs.2.fc              | Sequential          | 290    | [256, 144]                               | [256, 2]
111 | model.fc_outs.2.fc.0            | Linear              | 290    | [256, 144]                               | [256, 2]
112 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
113 | model.fc_outs.3                 | OutputLayer         | 580    | [256, 144]                               | [256, 4]
114 | model.fc_outs.3.fc              | Sequential          | 580    | [256, 144]                               | [256, 4]
115 | model.fc_outs.3.fc.0            | Linear              | 580    | [256, 144]                               | [256, 4]
116 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                 | [256, 4]
117 | model.fc_outs.4                 | OutputLayer         | 290    | [256, 144]                               | [256, 2]
118 | model.fc_outs.4.fc              | Sequential          | 290    | [256, 144]                               | [256, 2]
119 | model.fc_outs.4.fc.0            | Linear              | 290    | [256, 144]                               | [256, 2]
120 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
121 | model.fc_outs.5                 | OutputLayer         | 290    | [256, 144]                               | [256, 2]
122 | model.fc_outs.5.fc              | Sequential          | 290    | [256, 144]                               | [256, 2]
123 | model.fc_outs.5.fc.0            | Linear              | 290    | [256, 144]                               | [256, 2]
124 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
125 | model.fc_outs.6                 | OutputLayer         | 290    | [256, 144]                               | [256, 2]
126 | model.fc_outs.6.fc              | Sequential          | 290    | [256, 144]                               | [256, 2]
127 | model.fc_outs.6.fc.0            | Linear              | 290    | [256, 144]                               | [256, 2]
128 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
129 | model.task_norms                | ModuleList          | 2.0 K  | ?                                        | ?
130 | model.task_norms.0              | LayerNorm           | 288    | [256, 144]                               | [256, 144]
131 | model.task_norms.1              | LayerNorm           | 288    | [256, 144]                               | [256, 144]
132 | model.task_norms.2              | LayerNorm           | 288    | [256, 144]                               | [256, 144]
133 | model.task_norms.3              | LayerNorm           | 288    | [256, 144]                               | [256, 144]
134 | model.task_norms.4              | LayerNorm           | 288    | [256, 144]                               | [256, 144]
135 | model.task_norms.5              | LayerNorm           | 288    | [256, 144]                               | [256, 144]
136 | model.task_norms.6              | LayerNorm           | 288    | [256, 144]                               | [256, 144]
137 | model.task_attentions           | ModuleList          | 438 K  | ?                                        | ?
138 | model.task_attentions.0         | SelfAttention       | 62.6 K | [256, 144]                               | [256, 144]
139 | model.task_attentions.0.query   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
140 | model.task_attentions.0.key     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
141 | model.task_attentions.0.value   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
142 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
143 | model.task_attentions.1         | SelfAttention       | 62.6 K | [256, 144]                               | [256, 144]
144 | model.task_attentions.1.query   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
145 | model.task_attentions.1.key     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
146 | model.task_attentions.1.value   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
147 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
148 | model.task_attentions.2         | SelfAttention       | 62.6 K | [256, 144]                               | [256, 144]
149 | model.task_attentions.2.query   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
150 | model.task_attentions.2.key     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
151 | model.task_attentions.2.value   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
152 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
153 | model.task_attentions.3         | SelfAttention       | 62.6 K | [256, 144]                               | [256, 144]
154 | model.task_attentions.3.query   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
155 | model.task_attentions.3.key     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
156 | model.task_attentions.3.value   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
157 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
158 | model.task_attentions.4         | SelfAttention       | 62.6 K | [256, 144]                               | [256, 144]
159 | model.task_attentions.4.query   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
160 | model.task_attentions.4.key     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
161 | model.task_attentions.4.value   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
162 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
163 | model.task_attentions.5         | SelfAttention       | 62.6 K | [256, 144]                               | [256, 144]
164 | model.task_attentions.5.query   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
165 | model.task_attentions.5.key     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
166 | model.task_attentions.5.value   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
167 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
168 | model.task_attentions.6         | SelfAttention       | 62.6 K | [256, 144]                               | [256, 144]
169 | model.task_attentions.6.query   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
170 | model.task_attentions.6.key     | Linear              | 20.9 K | [256, 144]                               | [256, 144]
171 | model.task_attentions.6.value   | Linear              | 20.9 K | [256, 144]                               | [256, 144]
172 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.229     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_11
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'convs.8.fc_full.weight', 'convs.9.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'convs.8.fc_full.bias', 'convs.8.bn1.weight', 'convs.8.bn1.bias', 'convs.8.bn2.weight', 'convs.8.bn2.bias', 'convs.9.fc_full.bias', 'convs.9.bn1.weight', 'convs.9.bn1.bias', 'convs.9.bn2.weight', 'convs.9.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 2 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 1.1 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144], [256, 144]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.1 M     Trainable params
0         Non-trainable params
1.1 M     Total params
4.229     Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 17:13:49,234] Trial 13 failed with parameters: {'atom_fea_len': 96, 'h_fea_len': 144, 'n_conv': 10, 'n_h': 7, 'lr_mult': 2, 'extra_fea_len': 60, 'dropout': 0.35000000000000003} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 144.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.68 GiB memory in use. Of the allocated memory 20.96 GiB is allocated by PyTorch, and 499.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 94, in forward
    nbr_filter = self.sigmoid(nbr_filter)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 329, in forward
    return torch.sigmoid(input)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 144.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.68 GiB memory in use. Of the allocated memory 20.96 GiB is allocated by PyTorch, and 499.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 17:13:49,240] Trial 13 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 2
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 272
extra_fea_len : 20
h_fea_len : 128
n_conv : 8
n_h : 5
att_S : 64
dropout_prob : 0.5
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=96, bias=True)
  (embedding_atom_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-9): 10 x ConvLayer(
      (fc_full): Linear(in_features=233, out_features=192, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=60, bias=True)
  (embedding_extra_norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=156, out_features=144, bias=True)
  (conv_to_fc_norm): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.35000000000000003, inplace=False)
  (fcs): ModuleList(
    (0-5): 6 x Linear(in_features=144, out_features=144, bias=True)
  )
  (norms): ModuleList(
    (0-5): 6 x BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-5): 6 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=144, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=144, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=144, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=144, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((144,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=144, out_features=144, bias=True)
      (key): Linear(in_features=144, out_features=144, bias=True)
      (value): Linear(in_features=144, out_features=144, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0bb0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0100>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0f70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d05e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0f10>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0310>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0a00>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 3.0 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 128], [256, 128], [256, 128], [256, 128], [256, 128], [256, 128], [256, 128]]]
1   | model.embedding_atom            | Linear              | 25.3 K | [4608, 92]                                | [4608, 272]
2   | model.embedding_atom_norm       | LayerNorm           | 544    | [4608, 272]                               | [4608, 272]
3   | model.convs                     | ModuleList          | 2.6 M  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
5   | model.convs.0.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
8   | model.convs.0.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
9   | model.convs.0.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
11  | model.convs.1                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
12  | model.convs.1.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
15  | model.convs.1.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
16  | model.convs.1.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
18  | model.convs.2                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
19  | model.convs.2.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
22  | model.convs.2.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
23  | model.convs.2.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
25  | model.convs.3                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
26  | model.convs.3.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
29  | model.convs.3.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
30  | model.convs.3.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
32  | model.convs.4                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
33  | model.convs.4.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
36  | model.convs.4.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
37  | model.convs.4.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
39  | model.convs.5                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
40  | model.convs.5.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
43  | model.convs.5.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
44  | model.convs.5.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
46  | model.convs.6                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
47  | model.convs.6.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
50  | model.convs.6.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
51  | model.convs.6.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
53  | model.convs.7                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
54  | model.convs.7.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
57  | model.convs.7.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
58  | model.convs.7.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
60  | model.embedding_extra           | Linear              | 140    | [256, 6]                                  | [256, 20]
61  | model.embedding_extra_norm      | BatchNorm1d         | 40     | [256, 20]                                 | [256, 20]
62  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 20]                                 | [256, 20]
63  | model.conv_to_fc                | Linear              | 37.5 K | [256, 292]                                | [256, 128]
64  | model.conv_to_fc_norm           | BatchNorm1d         | 256    | [256, 128]                                | [256, 128]
65  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 128]                                | [256, 128]
66  | model.dropout                   | Dropout             | 0      | [256, 128]                                | [256, 128]
67  | model.fcs                       | ModuleList          | 66.0 K | ?                                         | ?
68  | model.fcs.0                     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
69  | model.fcs.1                     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
70  | model.fcs.2                     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
71  | model.fcs.3                     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
72  | model.norms                     | ModuleList          | 1.0 K  | ?                                         | ?
73  | model.norms.0                   | BatchNorm1d         | 256    | [256, 128]                                | [256, 128]
74  | model.norms.1                   | BatchNorm1d         | 256    | [256, 128]                                | [256, 128]
75  | model.norms.2                   | BatchNorm1d         | 256    | [256, 128]                                | [256, 128]
76  | model.norms.3                   | BatchNorm1d         | 256    | [256, 128]                                | [256, 128]
77  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
78  | model.softpluses.0              | Softplus            | 0      | [256, 128]                                | [256, 128]
79  | model.softpluses.1              | Softplus            | 0      | [256, 128]                                | [256, 128]
80  | model.softpluses.2              | Softplus            | 0      | [256, 128]                                | [256, 128]
81  | model.softpluses.3              | Softplus            | 0      | [256, 128]                                | [256, 128]
82  | model.fc_outs                   | ModuleList          | 1.9 K  | ?                                         | ?
83  | model.fc_outs.0                 | OutputLayer         | 129    | [256, 128]                                | [256, 1]
84  | model.fc_outs.0.fc              | Linear              | 129    | [256, 128]                                | [256, 1]
85  | model.fc_outs.1                 | OutputLayer         | 258    | [256, 128]                                | [256, 2]
86  | model.fc_outs.1.fc              | Sequential          | 258    | [256, 128]                                | [256, 2]
87  | model.fc_outs.1.fc.0            | Linear              | 258    | [256, 128]                                | [256, 2]
88  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
89  | model.fc_outs.2                 | OutputLayer         | 258    | [256, 128]                                | [256, 2]
90  | model.fc_outs.2.fc              | Sequential          | 258    | [256, 128]                                | [256, 2]
91  | model.fc_outs.2.fc.0            | Linear              | 258    | [256, 128]                                | [256, 2]
92  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
93  | model.fc_outs.3                 | OutputLayer         | 516    | [256, 128]                                | [256, 4]
94  | model.fc_outs.3.fc              | Sequential          | 516    | [256, 128]                                | [256, 4]
95  | model.fc_outs.3.fc.0            | Linear              | 516    | [256, 128]                                | [256, 4]
96  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
97  | model.fc_outs.4                 | OutputLayer         | 258    | [256, 128]                                | [256, 2]
98  | model.fc_outs.4.fc              | Sequential          | 258    | [256, 128]                                | [256, 2]
99  | model.fc_outs.4.fc.0            | Linear              | 258    | [256, 128]                                | [256, 2]
100 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
101 | model.fc_outs.5                 | OutputLayer         | 258    | [256, 128]                                | [256, 2]
102 | model.fc_outs.5.fc              | Sequential          | 258    | [256, 128]                                | [256, 2]
103 | model.fc_outs.5.fc.0            | Linear              | 258    | [256, 128]                                | [256, 2]
104 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
105 | model.fc_outs.6                 | OutputLayer         | 258    | [256, 128]                                | [256, 2]
106 | model.fc_outs.6.fc              | Sequential          | 258    | [256, 128]                                | [256, 2]
107 | model.fc_outs.6.fc.0            | Linear              | 258    | [256, 128]                                | [256, 2]
108 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
109 | model.task_norms                | ModuleList          | 1.8 K  | ?                                         | ?
110 | model.task_norms.0              | LayerNorm           | 256    | [256, 128]                                | [256, 128]
111 | model.task_norms.1              | LayerNorm           | 256    | [256, 128]                                | [256, 128]
112 | model.task_norms.2              | LayerNorm           | 256    | [256, 128]                                | [256, 128]
113 | model.task_norms.3              | LayerNorm           | 256    | [256, 128]                                | [256, 128]
114 | model.task_norms.4              | LayerNorm           | 256    | [256, 128]                                | [256, 128]
115 | model.task_norms.5              | LayerNorm           | 256    | [256, 128]                                | [256, 128]
116 | model.task_norms.6              | LayerNorm           | 256    | [256, 128]                                | [256, 128]
117 | model.task_attentions           | ModuleList          | 346 K  | ?                                         | ?
118 | model.task_attentions.0         | SelfAttention       | 49.5 K | [256, 128]                                | [256, 128]
119 | model.task_attentions.0.query   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
120 | model.task_attentions.0.key     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
121 | model.task_attentions.0.value   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
122 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
123 | model.task_attentions.1         | SelfAttention       | 49.5 K | [256, 128]                                | [256, 128]
124 | model.task_attentions.1.query   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
125 | model.task_attentions.1.key     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
126 | model.task_attentions.1.value   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
127 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
128 | model.task_attentions.2         | SelfAttention       | 49.5 K | [256, 128]                                | [256, 128]
129 | model.task_attentions.2.query   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
130 | model.task_attentions.2.key     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
131 | model.task_attentions.2.value   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
132 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
133 | model.task_attentions.3         | SelfAttention       | 49.5 K | [256, 128]                                | [256, 128]
134 | model.task_attentions.3.query   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
135 | model.task_attentions.3.key     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
136 | model.task_attentions.3.value   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
137 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
138 | model.task_attentions.4         | SelfAttention       | 49.5 K | [256, 128]                                | [256, 128]
139 | model.task_attentions.4.query   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
140 | model.task_attentions.4.key     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
141 | model.task_attentions.4.value   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
142 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
143 | model.task_attentions.5         | SelfAttention       | 49.5 K | [256, 128]                                | [256, 128]
144 | model.task_attentions.5.query   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
145 | model.task_attentions.5.key     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
146 | model.task_attentions.5.value   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
147 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
148 | model.task_attentions.6         | SelfAttention       | 49.5 K | [256, 128]                                | [256, 128]
149 | model.task_attentions.6.query   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
150 | model.task_attentions.6.key     | Linear              | 16.5 K | [256, 128]                                | [256, 128]
151 | model.task_attentions.6.value   | Linear              | 16.5 K | [256, 128]                                | [256, 128]
152 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3.0 M     Trainable params
0         Non-trainable params
3.0 M     Total params
12.179    Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_12
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 2 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 3.0 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 128], [256, 128], [256, 128], [256, 128], [256, 128], [256, 128], [256, 128]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3.0 M     Trainable params
0         Non-trainable params
3.0 M     Total params
12.179    Total estimated model params size (MB)
Using no sampler for validation data.
current_epoch(0): metric=0.0083 > best_metric=0.0000, log val results..
[W 2025-12-03 17:14:03,586] Trial 14 failed with parameters: {'atom_fea_len': 272, 'h_fea_len': 128, 'n_conv': 8, 'n_h': 5, 'lr_mult': 2, 'extra_fea_len': 20, 'dropout': 0.5} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 796.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 442.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.39 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 94, in forward
    nbr_filter = self.sigmoid(nbr_filter)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 329, in forward
    return torch.sigmoid(input)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 796.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 442.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.39 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 17:14:03,587] Trial 14 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 5
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 176
extra_fea_len : 52
h_fea_len : 176
n_conv : 7
n_h : 10
att_S : 64
dropout_prob : 0.4
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=272, bias=True)
  (embedding_atom_norm): LayerNorm((272,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-7): 8 x ConvLayer(
      (fc_full): Linear(in_features=585, out_features=544, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=20, bias=True)
  (embedding_extra_norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=292, out_features=128, bias=True)
  (conv_to_fc_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.5, inplace=False)
  (fcs): ModuleList(
    (0-3): 4 x Linear(in_features=128, out_features=128, bias=True)
  )
  (norms): ModuleList(
    (0-3): 4 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-3): 4 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=128, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=128, out_features=128, bias=True)
      (key): Linear(in_features=128, out_features=128, bias=True)
      (value): Linear(in_features=128, out_features=128, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f88635610>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f88635d90>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f88635d60>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f88635fa0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f88635490>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f88635340>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f88635640>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 2.0 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176]]]
1   | model.embedding_atom            | Linear              | 16.4 K | [4608, 92]                                | [4608, 176]
2   | model.embedding_atom_norm       | LayerNorm           | 352    | [4608, 176]                               | [4608, 176]
3   | model.convs                     | ModuleList          | 978 K  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
5   | model.convs.0.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
8   | model.convs.0.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
9   | model.convs.0.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
11  | model.convs.1                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
12  | model.convs.1.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
15  | model.convs.1.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
16  | model.convs.1.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
18  | model.convs.2                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
19  | model.convs.2.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
22  | model.convs.2.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
23  | model.convs.2.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
25  | model.convs.3                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
26  | model.convs.3.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
29  | model.convs.3.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
30  | model.convs.3.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
32  | model.convs.4                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
33  | model.convs.4.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
36  | model.convs.4.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
37  | model.convs.4.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
39  | model.convs.5                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
40  | model.convs.5.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
43  | model.convs.5.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
44  | model.convs.5.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
46  | model.convs.6                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
47  | model.convs.6.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
50  | model.convs.6.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
51  | model.convs.6.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
53  | model.embedding_extra           | Linear              | 364    | [256, 6]                                  | [256, 52]
54  | model.embedding_extra_norm      | BatchNorm1d         | 104    | [256, 52]                                 | [256, 52]
55  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 52]                                 | [256, 52]
56  | model.conv_to_fc                | Linear              | 40.3 K | [256, 228]                                | [256, 176]
57  | model.conv_to_fc_norm           | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
58  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 176]                                | [256, 176]
59  | model.dropout                   | Dropout             | 0      | [256, 176]                                | [256, 176]
60  | model.fcs                       | ModuleList          | 280 K  | ?                                         | ?
61  | model.fcs.0                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
62  | model.fcs.1                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
63  | model.fcs.2                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
64  | model.fcs.3                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
65  | model.fcs.4                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
66  | model.fcs.5                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
67  | model.fcs.6                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
68  | model.fcs.7                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
69  | model.fcs.8                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
70  | model.norms                     | ModuleList          | 3.2 K  | ?                                         | ?
71  | model.norms.0                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
72  | model.norms.1                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
73  | model.norms.2                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
74  | model.norms.3                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
75  | model.norms.4                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
76  | model.norms.5                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
77  | model.norms.6                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
78  | model.norms.7                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
79  | model.norms.8                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
80  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
81  | model.softpluses.0              | Softplus            | 0      | [256, 176]                                | [256, 176]
82  | model.softpluses.1              | Softplus            | 0      | [256, 176]                                | [256, 176]
83  | model.softpluses.2              | Softplus            | 0      | [256, 176]                                | [256, 176]
84  | model.softpluses.3              | Softplus            | 0      | [256, 176]                                | [256, 176]
85  | model.softpluses.4              | Softplus            | 0      | [256, 176]                                | [256, 176]
86  | model.softpluses.5              | Softplus            | 0      | [256, 176]                                | [256, 176]
87  | model.softpluses.6              | Softplus            | 0      | [256, 176]                                | [256, 176]
88  | model.softpluses.7              | Softplus            | 0      | [256, 176]                                | [256, 176]
89  | model.softpluses.8              | Softplus            | 0      | [256, 176]                                | [256, 176]
90  | model.fc_outs                   | ModuleList          | 2.7 K  | ?                                         | ?
91  | model.fc_outs.0                 | OutputLayer         | 177    | [256, 176]                                | [256, 1]
92  | model.fc_outs.0.fc              | Linear              | 177    | [256, 176]                                | [256, 1]
93  | model.fc_outs.1                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
94  | model.fc_outs.1.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
95  | model.fc_outs.1.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
96  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
97  | model.fc_outs.2                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
98  | model.fc_outs.2.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
99  | model.fc_outs.2.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
100 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
101 | model.fc_outs.3                 | OutputLayer         | 708    | [256, 176]                                | [256, 4]
102 | model.fc_outs.3.fc              | Sequential          | 708    | [256, 176]                                | [256, 4]
103 | model.fc_outs.3.fc.0            | Linear              | 708    | [256, 176]                                | [256, 4]
104 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
105 | model.fc_outs.4                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
106 | model.fc_outs.4.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
107 | model.fc_outs.4.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
108 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
109 | model.fc_outs.5                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
110 | model.fc_outs.5.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
111 | model.fc_outs.5.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
112 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
113 | model.fc_outs.6                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
114 | model.fc_outs.6.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
115 | model.fc_outs.6.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
116 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
117 | model.task_norms                | ModuleList          | 2.5 K  | ?                                         | ?
118 | model.task_norms.0              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
119 | model.task_norms.1              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
120 | model.task_norms.2              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
121 | model.task_norms.3              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
122 | model.task_norms.4              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
123 | model.task_norms.5              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
124 | model.task_norms.6              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
125 | model.task_attentions           | ModuleList          | 654 K  | ?                                         | ?
126 | model.task_attentions.0         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
127 | model.task_attentions.0.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
128 | model.task_attentions.0.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
129 | model.task_attentions.0.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
130 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
131 | model.task_attentions.1         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
132 | model.task_attentions.1.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
133 | model.task_attentions.1.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
134 | model.task_attentions.1.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
135 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
136 | model.task_attentions.2         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
137 | model.task_attentions.2.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
138 | model.task_attentions.2.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
139 | model.task_attentions.2.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
140 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
141 | model.task_attentions.3         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
142 | model.task_attentions.3.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
143 | model.task_attentions.3.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
144 | model.task_attentions.3.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
145 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
146 | model.task_attentions.4         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
147 | model.task_attentions.4.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
148 | model.task_attentions.4.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
149 | model.task_attentions.4.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
150 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
151 | model.task_attentions.5         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
152 | model.task_attentions.5.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
153 | model.task_attentions.5.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
154 | model.task_attentions.5.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
155 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
156 | model.task_attentions.6         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
157 | model.task_attentions.6.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
158 | model.task_attentions.6.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
159 | model.task_attentions.6.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
160 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
7.916     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_13
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight', 'fcs.7.weight', 'fcs.8.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'fcs.7.bias', 'fcs.8.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'norms.7.weight', 'norms.7.bias', 'norms.8.weight', 'norms.8.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 5 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 2.0 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
7.916     Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 17:14:14,911] Trial 15 failed with parameters: {'atom_fea_len': 176, 'h_fea_len': 176, 'n_conv': 7, 'n_h': 10, 'lr_mult': 5, 'extra_fea_len': 52, 'dropout': 0.4} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1.21 GiB. GPU 0 has a total capacity of 22.03 GiB of which 932.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.91 GiB memory in use. Of the allocated memory 19.18 GiB is allocated by PyTorch, and 1.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 87, in forward
    total_nbr_fea = torch.cat(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.21 GiB. GPU 0 has a total capacity of 22.03 GiB of which 932.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.91 GiB memory in use. Of the allocated memory 19.18 GiB is allocated by PyTorch, and 1.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 17:14:14,912] Trial 15 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 3
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 96
extra_fea_len : 32
h_fea_len : 48
n_conv : 9
n_h : 4
att_S : 64
dropout_prob : 0.8
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=176, bias=True)
  (embedding_atom_norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-6): 7 x ConvLayer(
      (fc_full): Linear(in_features=393, out_features=352, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=52, bias=True)
  (embedding_extra_norm): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=228, out_features=176, bias=True)
  (conv_to_fc_norm): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.4, inplace=False)
  (fcs): ModuleList(
    (0-8): 9 x Linear(in_features=176, out_features=176, bias=True)
  )
  (norms): ModuleList(
    (0-8): 9 x BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-8): 9 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=176, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=176, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=176, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=176, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((176,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=176, out_features=176, bias=True)
      (key): Linear(in_features=176, out_features=176, bias=True)
      (value): Linear(in_features=176, out_features=176, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f922b8a90>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926e7970>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926e7580>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926e75e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926e7070>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926e78b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926e73d0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                 | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 483 K  | ?                                        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 48], [256, 48], [256, 48], [256, 48], [256, 48], [256, 48], [256, 48]]]
1   | model.embedding_atom            | Linear              | 8.9 K  | [4608, 92]                               | [4608, 96]
2   | model.embedding_atom_norm       | LayerNorm           | 192    | [4608, 96]                               | [4608, 96]
3   | model.convs                     | ModuleList          | 409 K  | ?                                        | ?
4   | model.convs.0                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
5   | model.convs.0.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
8   | model.convs.0.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
9   | model.convs.0.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
11  | model.convs.1                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
12  | model.convs.1.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
15  | model.convs.1.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
16  | model.convs.1.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
18  | model.convs.2                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
19  | model.convs.2.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
22  | model.convs.2.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
23  | model.convs.2.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
25  | model.convs.3                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
26  | model.convs.3.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
29  | model.convs.3.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
30  | model.convs.3.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
32  | model.convs.4                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
33  | model.convs.4.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
36  | model.convs.4.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
37  | model.convs.4.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
39  | model.convs.5                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
40  | model.convs.5.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
43  | model.convs.5.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
44  | model.convs.5.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
46  | model.convs.6                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
47  | model.convs.6.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
50  | model.convs.6.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
51  | model.convs.6.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
53  | model.convs.7                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
54  | model.convs.7.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
57  | model.convs.7.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
58  | model.convs.7.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
60  | model.convs.8                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
61  | model.convs.8.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
62  | model.convs.8.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
63  | model.convs.8.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
64  | model.convs.8.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
65  | model.convs.8.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
66  | model.convs.8.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
67  | model.embedding_extra           | Linear              | 224    | [256, 6]                                 | [256, 32]
68  | model.embedding_extra_norm      | BatchNorm1d         | 64     | [256, 32]                                | [256, 32]
69  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 32]                                | [256, 32]
70  | model.conv_to_fc                | Linear              | 6.2 K  | [256, 128]                               | [256, 48]
71  | model.conv_to_fc_norm           | BatchNorm1d         | 96     | [256, 48]                                | [256, 48]
72  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 48]                                | [256, 48]
73  | model.dropout                   | Dropout             | 0      | [256, 48]                                | [256, 48]
74  | model.fcs                       | ModuleList          | 7.1 K  | ?                                        | ?
75  | model.fcs.0                     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
76  | model.fcs.1                     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
77  | model.fcs.2                     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
78  | model.norms                     | ModuleList          | 288    | ?                                        | ?
79  | model.norms.0                   | BatchNorm1d         | 96     | [256, 48]                                | [256, 48]
80  | model.norms.1                   | BatchNorm1d         | 96     | [256, 48]                                | [256, 48]
81  | model.norms.2                   | BatchNorm1d         | 96     | [256, 48]                                | [256, 48]
82  | model.softpluses                | ModuleList          | 0      | ?                                        | ?
83  | model.softpluses.0              | Softplus            | 0      | [256, 48]                                | [256, 48]
84  | model.softpluses.1              | Softplus            | 0      | [256, 48]                                | [256, 48]
85  | model.softpluses.2              | Softplus            | 0      | [256, 48]                                | [256, 48]
86  | model.fc_outs                   | ModuleList          | 735    | ?                                        | ?
87  | model.fc_outs.0                 | OutputLayer         | 49     | [256, 48]                                | [256, 1]
88  | model.fc_outs.0.fc              | Linear              | 49     | [256, 48]                                | [256, 1]
89  | model.fc_outs.1                 | OutputLayer         | 98     | [256, 48]                                | [256, 2]
90  | model.fc_outs.1.fc              | Sequential          | 98     | [256, 48]                                | [256, 2]
91  | model.fc_outs.1.fc.0            | Linear              | 98     | [256, 48]                                | [256, 2]
92  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
93  | model.fc_outs.2                 | OutputLayer         | 98     | [256, 48]                                | [256, 2]
94  | model.fc_outs.2.fc              | Sequential          | 98     | [256, 48]                                | [256, 2]
95  | model.fc_outs.2.fc.0            | Linear              | 98     | [256, 48]                                | [256, 2]
96  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
97  | model.fc_outs.3                 | OutputLayer         | 196    | [256, 48]                                | [256, 4]
98  | model.fc_outs.3.fc              | Sequential          | 196    | [256, 48]                                | [256, 4]
99  | model.fc_outs.3.fc.0            | Linear              | 196    | [256, 48]                                | [256, 4]
100 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                 | [256, 4]
101 | model.fc_outs.4                 | OutputLayer         | 98     | [256, 48]                                | [256, 2]
102 | model.fc_outs.4.fc              | Sequential          | 98     | [256, 48]                                | [256, 2]
103 | model.fc_outs.4.fc.0            | Linear              | 98     | [256, 48]                                | [256, 2]
104 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
105 | model.fc_outs.5                 | OutputLayer         | 98     | [256, 48]                                | [256, 2]
106 | model.fc_outs.5.fc              | Sequential          | 98     | [256, 48]                                | [256, 2]
107 | model.fc_outs.5.fc.0            | Linear              | 98     | [256, 48]                                | [256, 2]
108 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
109 | model.fc_outs.6                 | OutputLayer         | 98     | [256, 48]                                | [256, 2]
110 | model.fc_outs.6.fc              | Sequential          | 98     | [256, 48]                                | [256, 2]
111 | model.fc_outs.6.fc.0            | Linear              | 98     | [256, 48]                                | [256, 2]
112 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
113 | model.task_norms                | ModuleList          | 672    | ?                                        | ?
114 | model.task_norms.0              | LayerNorm           | 96     | [256, 48]                                | [256, 48]
115 | model.task_norms.1              | LayerNorm           | 96     | [256, 48]                                | [256, 48]
116 | model.task_norms.2              | LayerNorm           | 96     | [256, 48]                                | [256, 48]
117 | model.task_norms.3              | LayerNorm           | 96     | [256, 48]                                | [256, 48]
118 | model.task_norms.4              | LayerNorm           | 96     | [256, 48]                                | [256, 48]
119 | model.task_norms.5              | LayerNorm           | 96     | [256, 48]                                | [256, 48]
120 | model.task_norms.6              | LayerNorm           | 96     | [256, 48]                                | [256, 48]
121 | model.task_attentions           | ModuleList          | 49.4 K | ?                                        | ?
122 | model.task_attentions.0         | SelfAttention       | 7.1 K  | [256, 48]                                | [256, 48]
123 | model.task_attentions.0.query   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
124 | model.task_attentions.0.key     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
125 | model.task_attentions.0.value   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
126 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
127 | model.task_attentions.1         | SelfAttention       | 7.1 K  | [256, 48]                                | [256, 48]
128 | model.task_attentions.1.query   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
129 | model.task_attentions.1.key     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
130 | model.task_attentions.1.value   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
131 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
132 | model.task_attentions.2         | SelfAttention       | 7.1 K  | [256, 48]                                | [256, 48]
133 | model.task_attentions.2.query   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
134 | model.task_attentions.2.key     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
135 | model.task_attentions.2.value   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
136 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
137 | model.task_attentions.3         | SelfAttention       | 7.1 K  | [256, 48]                                | [256, 48]
138 | model.task_attentions.3.query   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
139 | model.task_attentions.3.key     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
140 | model.task_attentions.3.value   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
141 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
142 | model.task_attentions.4         | SelfAttention       | 7.1 K  | [256, 48]                                | [256, 48]
143 | model.task_attentions.4.query   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
144 | model.task_attentions.4.key     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
145 | model.task_attentions.4.value   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
146 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
147 | model.task_attentions.5         | SelfAttention       | 7.1 K  | [256, 48]                                | [256, 48]
148 | model.task_attentions.5.query   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
149 | model.task_attentions.5.key     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
150 | model.task_attentions.5.value   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
151 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
152 | model.task_attentions.6         | SelfAttention       | 7.1 K  | [256, 48]                                | [256, 48]
153 | model.task_attentions.6.query   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
154 | model.task_attentions.6.key     | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
155 | model.task_attentions.6.value   | Linear              | 2.4 K  | [256, 48]                                | [256, 48]
156 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
483 K     Trainable params
0         Non-trainable params
483 K     Total params
1.933     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_14
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'convs.8.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'convs.8.fc_full.bias', 'convs.8.bn1.weight', 'convs.8.bn1.bias', 'convs.8.bn2.weight', 'convs.8.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 3 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 483 K  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 48], [256, 48], [256, 48], [256, 48], [256, 48], [256, 48], [256, 48]]]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
483 K     Trainable params
0         Non-trainable params
483 K     Total params
1.933     Total estimated model params size (MB)
Using no sampler for validation data.
current_epoch(0): metric=0.0753 > best_metric=0.0000, log val results..
[W 2025-12-03 17:14:27,032] Trial 16 failed with parameters: {'atom_fea_len': 96, 'h_fea_len': 48, 'n_conv': 9, 'n_h': 4, 'lr_mult': 3, 'extra_fea_len': 32, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 32.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.79 GiB memory in use. Of the allocated memory 21.07 GiB is allocated by PyTorch, and 499.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 94, in forward
    nbr_filter = self.sigmoid(nbr_filter)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 329, in forward
    return torch.sigmoid(input)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 32.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.79 GiB memory in use. Of the allocated memory 21.07 GiB is allocated by PyTorch, and 499.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 17:14:27,034] Trial 16 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 11
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 112
extra_fea_len : 16
h_fea_len : 192
n_conv : 2
n_h : 2
att_S : 64
dropout_prob : 0.55
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=96, bias=True)
  (embedding_atom_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-8): 9 x ConvLayer(
      (fc_full): Linear(in_features=233, out_features=192, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=32, bias=True)
  (embedding_extra_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=128, out_features=48, bias=True)
  (conv_to_fc_norm): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.8, inplace=False)
  (fcs): ModuleList(
    (0-2): 3 x Linear(in_features=48, out_features=48, bias=True)
  )
  (norms): ModuleList(
    (0-2): 3 x BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-2): 3 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=48, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=48, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=48, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=48, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((48,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=48, out_features=48, bias=True)
      (key): Linear(in_features=48, out_features=48, bias=True)
      (value): Linear(in_features=48, out_features=48, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92d2e3a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92d2e5b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92d2e9a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92d2e970>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92d2e340>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92d2e8e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92d2e220>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 977 K  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192]]]
1   | model.embedding_atom            | Linear              | 10.4 K | [4608, 92]                                | [4608, 112]
2   | model.embedding_atom_norm       | LayerNorm           | 224    | [4608, 112]                               | [4608, 112]
3   | model.convs                     | ModuleList          | 120 K  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 60.3 K | [[4608, 112], [4608, 10, 41], [4608, 10]] | [4608, 112]
5   | model.convs.0.fc_full           | Linear              | 59.6 K | [4608, 10, 265]                           | [4608, 10, 224]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 112]                           | [4608, 10, 112]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 112]                           | [4608, 10, 112]
8   | model.convs.0.bn1               | BatchNorm1d         | 448    | [46080, 224]                              | [46080, 224]
9   | model.convs.0.bn2               | BatchNorm1d         | 224    | [4608, 112]                               | [4608, 112]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 112]                               | [4608, 112]
11  | model.convs.1                   | ConvLayer           | 60.3 K | [[4608, 112], [4608, 10, 41], [4608, 10]] | [4608, 112]
12  | model.convs.1.fc_full           | Linear              | 59.6 K | [4608, 10, 265]                           | [4608, 10, 224]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 112]                           | [4608, 10, 112]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 112]                           | [4608, 10, 112]
15  | model.convs.1.bn1               | BatchNorm1d         | 448    | [46080, 224]                              | [46080, 224]
16  | model.convs.1.bn2               | BatchNorm1d         | 224    | [4608, 112]                               | [4608, 112]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 112]                               | [4608, 112]
18  | model.embedding_extra           | Linear              | 112    | [256, 6]                                  | [256, 16]
19  | model.embedding_extra_norm      | BatchNorm1d         | 32     | [256, 16]                                 | [256, 16]
20  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 16]                                 | [256, 16]
21  | model.conv_to_fc                | Linear              | 24.8 K | [256, 128]                                | [256, 192]
22  | model.conv_to_fc_norm           | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
23  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 192]                                | [256, 192]
24  | model.dropout                   | Dropout             | 0      | [256, 192]                                | [256, 192]
25  | model.fcs                       | ModuleList          | 37.1 K | ?                                         | ?
26  | model.fcs.0                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
27  | model.norms                     | ModuleList          | 384    | ?                                         | ?
28  | model.norms.0                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
29  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
30  | model.softpluses.0              | Softplus            | 0      | [256, 192]                                | [256, 192]
31  | model.fc_outs                   | ModuleList          | 2.9 K  | ?                                         | ?
32  | model.fc_outs.0                 | OutputLayer         | 193    | [256, 192]                                | [256, 1]
33  | model.fc_outs.0.fc              | Linear              | 193    | [256, 192]                                | [256, 1]
34  | model.fc_outs.1                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
35  | model.fc_outs.1.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
36  | model.fc_outs.1.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
37  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
38  | model.fc_outs.2                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
39  | model.fc_outs.2.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
40  | model.fc_outs.2.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
41  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
42  | model.fc_outs.3                 | OutputLayer         | 772    | [256, 192]                                | [256, 4]
43  | model.fc_outs.3.fc              | Sequential          | 772    | [256, 192]                                | [256, 4]
44  | model.fc_outs.3.fc.0            | Linear              | 772    | [256, 192]                                | [256, 4]
45  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
46  | model.fc_outs.4                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
47  | model.fc_outs.4.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
48  | model.fc_outs.4.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
49  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
50  | model.fc_outs.5                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
51  | model.fc_outs.5.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
52  | model.fc_outs.5.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
53  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
54  | model.fc_outs.6                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
55  | model.fc_outs.6.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
56  | model.fc_outs.6.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
57  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
58  | model.task_norms                | ModuleList          | 2.7 K  | ?                                         | ?
59  | model.task_norms.0              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
60  | model.task_norms.1              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
61  | model.task_norms.2              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
62  | model.task_norms.3              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
63  | model.task_norms.4              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
64  | model.task_norms.5              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
65  | model.task_norms.6              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
66  | model.task_attentions           | ModuleList          | 778 K  | ?                                         | ?
67  | model.task_attentions.0         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
68  | model.task_attentions.0.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
69  | model.task_attentions.0.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
70  | model.task_attentions.0.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
71  | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
72  | model.task_attentions.1         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
73  | model.task_attentions.1.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
74  | model.task_attentions.1.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
75  | model.task_attentions.1.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
76  | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
77  | model.task_attentions.2         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
78  | model.task_attentions.2.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
79  | model.task_attentions.2.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
80  | model.task_attentions.2.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
81  | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
82  | model.task_attentions.3         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
83  | model.task_attentions.3.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
84  | model.task_attentions.3.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
85  | model.task_attentions.3.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
86  | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
87  | model.task_attentions.4         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
88  | model.task_attentions.4.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
89  | model.task_attentions.4.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
90  | model.task_attentions.4.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
91  | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
92  | model.task_attentions.5         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
93  | model.task_attentions.5.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
94  | model.task_attentions.5.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
95  | model.task_attentions.5.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
96  | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
97  | model.task_attentions.6         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
98  | model.task_attentions.6.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
99  | model.task_attentions.6.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
100 | model.task_attentions.6.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
101 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
977 K     Trainable params
0         Non-trainable params
977 K     Total params
3.911     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'norms.0.weight', 'norms.0.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 11 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 977 K  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
977 K     Trainable params
0         Non-trainable params
977 K     Total params
3.911     Total estimated model params size (MB)
Using no sampler for validation data.
current_epoch(0): metric=0.0475 > best_metric=0.0000, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(0): metric=0.2959 > best_metric=0.0475, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Epoch 0, global step 17: 'val_Metric' reached 0.29589 (best 0.29589), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=00-val_Metric=0.296.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(1): metric=0.3361 > best_metric=0.2959, log val results..
Epoch 1, global step 34: 'val_Metric' reached 0.33610 (best 0.33610), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=01-val_Metric=0.336.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(2): metric=0.3564 > best_metric=0.3361, log val results..
Epoch 2, global step 51: 'val_Metric' reached 0.35640 (best 0.35640), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=02-val_Metric=0.356.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(3): metric=0.3676 > best_metric=0.3564, log val results..
Epoch 3, global step 68: 'val_Metric' reached 0.36763 (best 0.36763), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=03-val_Metric=0.368.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(4): metric=0.3797 > best_metric=0.3676, log val results..
Epoch 4, global step 85: 'val_Metric' reached 0.37967 (best 0.37967), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=04-val_Metric=0.380.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(5): metric=0.3908 > best_metric=0.3797, log val results..
Epoch 5, global step 102: 'val_Metric' reached 0.39082 (best 0.39082), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=05-val_Metric=0.391.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(6): metric=0.4091 > best_metric=0.3908, log val results..
Epoch 6, global step 119: 'val_Metric' reached 0.40911 (best 0.40911), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=06-val_Metric=0.409.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 7, global step 136: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 8, global step 153: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(9): metric=0.4266 > best_metric=0.4091, log val results..
Epoch 9, global step 170: 'val_Metric' reached 0.42664 (best 0.42664), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=09-val_Metric=0.427.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(10): metric=0.4284 > best_metric=0.4266, log val results..
Epoch 10, global step 187: 'val_Metric' reached 0.42842 (best 0.42842), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=10-val_Metric=0.428.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 11, global step 204: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(12): metric=0.4486 > best_metric=0.4284, log val results..
Epoch 12, global step 221: 'val_Metric' reached 0.44858 (best 0.44858), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=12-val_Metric=0.449.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(13): metric=0.4632 > best_metric=0.4486, log val results..
Epoch 13, global step 238: 'val_Metric' reached 0.46324 (best 0.46324), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=13-val_Metric=0.463.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(14): metric=0.4835 > best_metric=0.4632, log val results..
Epoch 14, global step 255: 'val_Metric' reached 0.48347 (best 0.48347), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=14-val_Metric=0.483.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 15, global step 272: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 16, global step 289: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(17): metric=0.4880 > best_metric=0.4835, log val results..
Epoch 17, global step 306: 'val_Metric' reached 0.48800 (best 0.48800), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=17-val_Metric=0.488.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 18, global step 323: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 19, global step 340: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 20, global step 357: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(21): metric=0.5009 > best_metric=0.4880, log val results..
Epoch 21, global step 374: 'val_Metric' reached 0.50094 (best 0.50094), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=21-val_Metric=0.501.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 22, global step 391: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 23, global step 408: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(24): metric=0.5074 > best_metric=0.5009, log val results..
Epoch 24, global step 425: 'val_Metric' reached 0.50743 (best 0.50743), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=24-val_Metric=0.507.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 25, global step 442: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 26, global step 459: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 27, global step 476: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 28, global step 493: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(29): metric=0.5219 > best_metric=0.5074, log val results..
Epoch 29, global step 510: 'val_Metric' reached 0.52187 (best 0.52187), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=29-val_Metric=0.522.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 30, global step 527: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 31, global step 544: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 32, global step 561: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 33, global step 578: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 34, global step 595: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 35, global step 612: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 36, global step 629: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 37, global step 646: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 38, global step 663: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 39, global step 680: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 40, global step 697: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 41, global step 714: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 42, global step 731: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 43, global step 748: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 44, global step 765: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 45, global step 782: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 46, global step 799: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 47, global step 816: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 48, global step 833: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 49, global step 850: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 50, global step 867: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 51, global step 884: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 52, global step 901: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 53, global step 918: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 54, global step 935: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 55, global step 952: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 56, global step 969: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 57, global step 986: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 58, global step 1003: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 59, global step 1020: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 60, global step 1037: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 61, global step 1054: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 62, global step 1071: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 63, global step 1088: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 64, global step 1105: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(65): metric=0.5308 > best_metric=0.5219, log val results..
Epoch 65, global step 1122: 'val_Metric' reached 0.53078 (best 0.53078), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=65-val_Metric=0.531.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 66, global step 1139: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 67, global step 1156: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 68, global step 1173: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 69, global step 1190: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 70, global step 1207: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 71, global step 1224: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 72, global step 1241: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 73, global step 1258: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 74, global step 1275: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 75, global step 1292: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 76, global step 1309: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 77, global step 1326: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 78, global step 1343: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 79, global step 1360: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 80, global step 1377: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 81, global step 1394: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 82, global step 1411: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 83, global step 1428: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 84, global step 1445: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 85, global step 1462: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 86, global step 1479: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 87, global step 1496: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 88, global step 1513: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 89, global step 1530: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 90, global step 1547: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 91, global step 1564: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 92, global step 1581: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 93, global step 1598: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 94, global step 1615: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 95, global step 1632: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 96, global step 1649: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 97, global step 1666: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 98, global step 1683: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 99, global step 1700: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 100, global step 1717: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 101, global step 1734: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 102, global step 1751: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 103, global step 1768: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 104, global step 1785: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 105, global step 1802: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 106, global step 1819: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 107, global step 1836: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 108, global step 1853: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 109, global step 1870: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 110, global step 1887: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 111, global step 1904: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 112, global step 1921: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 113, global step 1938: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 114, global step 1955: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 115, global step 1972: 'val_Metric' was not in top 1
Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=65-val_Metric=0.531.ckpt
##################################################best
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=65-val_Metric=0.531.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=65-val_Metric=0.531.ckpt
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m           Validate metric           [0m[1m [0m[1m [0m[1m            DataLoader 0            [0m[1m [0m

[36m [0m[36m       SSD/val_MulticlassAUROC       [0m[36m [0m[35m [0m[35m         0.7277201414108276         [0m[35m [0m
[36m [0m[36m     SSD/val_MulticlassAccuracy      [0m[36m [0m[35m [0m[35m         0.6721069812774658         [0m[35m [0m
[36m [0m[36m      SSD/val_MulticlassF1Score      [0m[36m [0m[35m [0m[35m         0.6721069812774658         [0m[35m [0m
[36m [0m[36m SSD/val_MulticlassMatthewsCorrCoef  [0m[36m [0m[35m [0m[35m         0.3256562650203705         [0m[35m [0m
[36m [0m[36m         SSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         1.0987420082092285         [0m[35m [0m
[36m [0m[36m      SSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         1.6994599103927612         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanAbsoluteError      [0m[36m [0m[35m [0m[35m          51.798583984375           [0m[35m [0m
[36m [0m[36m TSD/val_MeanAbsolutePercentageError [0m[36m [0m[35m [0m[35m        0.15074998140335083         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanSquaredError       [0m[36m [0m[35m [0m[35m          4573.42822265625          [0m[35m [0m
[36m [0m[36m           TSD/val_R2Score           [0m[36m [0m[35m [0m[35m         0.4059409201145172         [0m[35m [0m
[36m [0m[36m         TSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.5759866833686829         [0m[35m [0m
[36m [0m[36m      TSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         2.5557641983032227         [0m[35m [0m
[36m [0m[36m    WS24_acid/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7908163070678711         [0m[35m [0m
[36m [0m[36m  WS24_acid/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.7142857313156128         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7142857313156128         [0m[35m [0m
[36m [0m[36mWS24_acid/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m         0.5222330093383789         [0m[35m [0m
[36m [0m[36m      WS24_acid/val_loss_epoch       [0m[36m [0m[35m [0m[35m         2.0242021083831787         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.18408076465129852         [0m[35m [0m
[36m [0m[36m    WS24_base/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m               0.1875               [0m[35m [0m
[36m [0m[36m  WS24_base/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.5208333730697632         [0m[35m [0m
[36m [0m[36m   WS24_base/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.5208333730697632         [0m[35m [0m
[36m [0m[36mWS24_base/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m         -0.191287100315094         [0m[35m [0m
[36m [0m[36m      WS24_base/val_loss_epoch       [0m[36m [0m[35m [0m[35m         5.381083965301514          [0m[35m [0m
[36m [0m[36m   WS24_base/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.13148626685142517         [0m[35m [0m
[36m [0m[36m  WS24_boiling/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m               0.5625               [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.5416666865348816         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5416666865348816         [0m[35m [0m
[36m [0m[36mWS24_boiling/val_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m        0.08362419903278351         [0m[35m [0m
[36m [0m[36m     WS24_boiling/val_loss_epoch     [0m[36m [0m[35m [0m[35m         3.0883004665374756         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m        0.13477341830730438         [0m[35m [0m
[36m [0m[36m   WS24_water/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7931249737739563         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7393162250518799         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7393162250518799         [0m[35m [0m
[36m [0m[36mWS24_water/val_MulticlassMatthewsCor[0m[36m [0m[35m [0m[35m         0.4523909091949463         [0m[35m [0m
[36m [0m[36m      WS24_water/val_loss_epoch      [0m[36m [0m[35m [0m[35m         1.3393237590789795         [0m[35m [0m
[36m [0m[36m  WS24_water/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m   WS24_water4/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7535528540611267         [0m[35m [0m
[36m [0m[36m WS24_water4/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.5714285969734192         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.5714285969734192         [0m[35m [0m
[36m [0m[36mWS24_water4/val_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.316439688205719          [0m[35m [0m
[36m [0m[36m     WS24_water4/val_loss_epoch      [0m[36m [0m[35m [0m[35m         2.334524393081665          [0m[35m [0m
[36m [0m[36m  WS24_water4/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m       val_MergedMetric_epoch        [0m[36m [0m[35m [0m[35m         0.556641161441803          [0m[35m [0m
[36m [0m[36m             val_Metric              [0m[36m [0m[35m [0m[35m         0.5307783214764883         [0m[35m [0m
[36m [0m[36m           val_loss_epoch            [0m[36m [0m[35m [0m[35m         2.9267642498016357         [0m[35m [0m

TSD/val_loss : tensor(0.5760)
TSD/val_loss_epoch : tensor(0.5760)
TSD/val_loss_weight : tensor(2.5558)
TSD/val_loss_weight_epoch : tensor(2.5558)
TSD/val_R2Score : tensor(0.4059)
TSD/val_MeanAbsoluteError : tensor(51.7986)
TSD/val_MeanAbsolutePercentageError : tensor(0.1507)
TSD/val_MeanSquaredError : tensor(4573.4282)
val_loss : tensor(2.9268)
val_loss_epoch : tensor(2.9268)
val_MergedMetric : tensor(0.5566)
val_MergedMetric_epoch : tensor(0.5566)
SSD/val_loss : tensor(1.0987)
SSD/val_loss_epoch : tensor(1.0987)
SSD/val_loss_weight : tensor(1.6995)
SSD/val_loss_weight_epoch : tensor(1.6995)
SSD/val_MulticlassAccuracy : tensor(0.6721)
SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3257)
SSD/val_MulticlassF1Score : tensor(0.6721)
SSD/val_MulticlassAUROC : tensor(0.7277)
WS24_water/val_loss : tensor(1.3393)
WS24_water/val_loss_epoch : tensor(1.3393)
WS24_water/val_loss_weight : tensor(1.1472)
WS24_water/val_loss_weight_epoch : tensor(1.1472)
WS24_water/val_MulticlassAccuracy : tensor(0.7393)
WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.4524)
WS24_water/val_MulticlassF1Score : tensor(0.7393)
WS24_water/val_MulticlassAUROC : tensor(0.7931)
WS24_water4/val_loss : tensor(2.3345)
WS24_water4/val_loss_epoch : tensor(2.3345)
WS24_water4/val_loss_weight : tensor(1.1472)
WS24_water4/val_loss_weight_epoch : tensor(1.1472)
WS24_water4/val_MulticlassAccuracy : tensor(0.5714)
WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.3164)
WS24_water4/val_MulticlassF1Score : tensor(0.5714)
WS24_water4/val_MulticlassAUROC : tensor(0.7536)
WS24_acid/val_loss : tensor(2.0242)
WS24_acid/val_loss_epoch : tensor(2.0242)
WS24_acid/val_loss_weight : tensor(0.1841)
WS24_acid/val_loss_weight_epoch : tensor(0.1841)
WS24_acid/val_MulticlassAccuracy : tensor(0.7143)
WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.5222)
WS24_acid/val_MulticlassF1Score : tensor(0.7143)
WS24_acid/val_MulticlassAUROC : tensor(0.7908)
WS24_base/val_loss : tensor(5.3811)
WS24_base/val_loss_epoch : tensor(5.3811)
WS24_base/val_loss_weight : tensor(0.1315)
WS24_base/val_loss_weight_epoch : tensor(0.1315)
WS24_base/val_MulticlassAccuracy : tensor(0.5208)
WS24_base/val_MulticlassMatthewsCorrCoef : tensor(-0.1913)
WS24_base/val_MulticlassF1Score : tensor(0.5208)
WS24_base/val_MulticlassAUROC : tensor(0.1875)
WS24_boiling/val_loss : tensor(3.0883)
WS24_boiling/val_loss_epoch : tensor(3.0883)
WS24_boiling/val_loss_weight : tensor(0.1348)
WS24_boiling/val_loss_weight_epoch : tensor(0.1348)
WS24_boiling/val_MulticlassAccuracy : tensor(0.5417)
WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(0.0836)
WS24_boiling/val_MulticlassF1Score : tensor(0.5417)
WS24_boiling/val_MulticlassAUROC : tensor(0.5625)
val_Metric : tensor(0.5308, dtype=torch.float64)
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=65-val_Metric=0.531.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_15/checkpoints/best-epoch=65-val_Metric=0.531.ckpt
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m            Test metric             [0m[1m [0m[1m [0m[1m            DataLoader 0             [0m[1m [0m

[36m [0m[36m      SSD/test_MulticlassAUROC      [0m[36m [0m[35m [0m[35m         0.7091805338859558          [0m[35m [0m
[36m [0m[36m    SSD/test_MulticlassAccuracy     [0m[36m [0m[35m [0m[35m         0.6458333134651184          [0m[35m [0m
[36m [0m[36m     SSD/test_MulticlassF1Score     [0m[36m [0m[35m [0m[35m         0.6458333134651184          [0m[35m [0m
[36m [0m[36mSSD/test_MulticlassMatthewsCorrCoef [0m[36m [0m[35m [0m[35m         0.24852536618709564         [0m[35m [0m
[36m [0m[36m        SSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m          1.053930401802063          [0m[35m [0m
[36m [0m[36m     SSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         1.6994599103927612          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanAbsoluteError     [0m[36m [0m[35m [0m[35m          52.32870101928711          [0m[35m [0m
[36m [0m[36mTSD/test_MeanAbsolutePercentageError[0m[36m [0m[35m [0m[35m         0.1587286740541458          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanSquaredError      [0m[36m [0m[35m [0m[35m            4780.9453125             [0m[35m [0m
[36m [0m[36m          TSD/test_R2Score          [0m[36m [0m[35m [0m[35m         0.33060669898986816         [0m[35m [0m
[36m [0m[36m        TSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.6021217107772827          [0m[35m [0m
[36m [0m[36m     TSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         2.5557641983032227          [0m[35m [0m
[36m [0m[36m   WS24_acid/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8888888955116272          [0m[35m [0m
[36m [0m[36m WS24_acid/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36mWS24_acid/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m          0.55901700258255           [0m[35m [0m
[36m [0m[36m     WS24_acid/test_loss_epoch      [0m[36m [0m[35m [0m[35m          0.767516553401947          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.18408076465129852         [0m[35m [0m
[36m [0m[36m   WS24_base/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.4270833432674408          [0m[35m [0m
[36m [0m[36m WS24_base/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.8863636255264282          [0m[35m [0m
[36m [0m[36m  WS24_base/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.8863636255264282          [0m[35m [0m
[36m [0m[36mWS24_base/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m          0.773861289024353          [0m[35m [0m
[36m [0m[36m     WS24_base/test_loss_epoch      [0m[36m [0m[35m [0m[35m         1.0060158967971802          [0m[35m [0m
[36m [0m[36m  WS24_base/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.13148626685142517         [0m[35m [0m
[36m [0m[36m WS24_boiling/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m          0.639053225517273          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassAccuracy[0m[36m [0m[35m [0m[35m         0.5384615659713745          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.5384615659713745          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassMatthew[0m[36m [0m[35m [0m[35m         0.08671099692583084         [0m[35m [0m
[36m [0m[36m    WS24_boiling/test_loss_epoch    [0m[36m [0m[35m [0m[35m          2.019094944000244          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         0.13477341830730438         [0m[35m [0m
[36m [0m[36m  WS24_water/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7627081871032715          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.7214611768722534          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7214611768722534          [0m[35m [0m
[36m [0m[36mWS24_water/test_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m          0.40589639544487           [0m[35m [0m
[36m [0m[36m     WS24_water/test_loss_epoch     [0m[36m [0m[35m [0m[35m         1.3905829191207886          [0m[35m [0m
[36m [0m[36m WS24_water/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m  WS24_water4/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.7803705334663391          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.6238532066345215          [0m[35m [0m
[36m [0m[36m WS24_water4/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.6238532066345215          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassMatthews[0m[36m [0m[35m [0m[35m         0.3843812346458435          [0m[35m [0m
[36m [0m[36m    WS24_water4/test_loss_epoch     [0m[36m [0m[35m [0m[35m         2.8303864002227783          [0m[35m [0m
[36m [0m[36m WS24_water4/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m            test_Metric             [0m[36m [0m[35m [0m[35m         0.5323599624987417          [0m[35m [0m
[36m [0m[36m          test_loss_epoch           [0m[36m [0m[35m [0m[35m         2.8697497844696045          [0m[35m [0m

TSD/test_loss : tensor(0.6021)
TSD/test_loss_epoch : tensor(0.6021)
TSD/test_loss_weight : tensor(2.5558)
TSD/test_loss_weight_epoch : tensor(2.5558)
TSD/test_R2Score : tensor(0.3306)
TSD/test_MeanAbsoluteError : tensor(52.3287)
TSD/test_MeanAbsolutePercentageError : tensor(0.1587)
TSD/test_MeanSquaredError : tensor(4780.9453)
test_loss : tensor(2.8697)
test_loss_epoch : tensor(2.8697)
SSD/test_loss : tensor(1.0539)
SSD/test_loss_epoch : tensor(1.0539)
SSD/test_loss_weight : tensor(1.6995)
SSD/test_loss_weight_epoch : tensor(1.6995)
SSD/test_MulticlassAccuracy : tensor(0.6458)
SSD/test_MulticlassMatthewsCorrCoef : tensor(0.2485)
SSD/test_MulticlassF1Score : tensor(0.6458)
SSD/test_MulticlassAUROC : tensor(0.7092)
WS24_water/test_loss : tensor(1.3906)
WS24_water/test_loss_epoch : tensor(1.3906)
WS24_water/test_loss_weight : tensor(1.1472)
WS24_water/test_loss_weight_epoch : tensor(1.1472)
WS24_water/test_MulticlassAccuracy : tensor(0.7215)
WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.4059)
WS24_water/test_MulticlassF1Score : tensor(0.7215)
WS24_water/test_MulticlassAUROC : tensor(0.7627)
WS24_water4/test_loss : tensor(2.8304)
WS24_water4/test_loss_epoch : tensor(2.8304)
WS24_water4/test_loss_weight : tensor(1.1472)
WS24_water4/test_loss_weight_epoch : tensor(1.1472)
WS24_water4/test_MulticlassAccuracy : tensor(0.6239)
WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.3844)
WS24_water4/test_MulticlassF1Score : tensor(0.6239)
WS24_water4/test_MulticlassAUROC : tensor(0.7804)
WS24_acid/test_loss : tensor(0.7675)
WS24_acid/test_loss_epoch : tensor(0.7675)
WS24_acid/test_loss_weight : tensor(0.1841)
WS24_acid/test_loss_weight_epoch : tensor(0.1841)
WS24_acid/test_MulticlassAccuracy : tensor(0.7778)
WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.5590)
WS24_acid/test_MulticlassF1Score : tensor(0.7778)
WS24_acid/test_MulticlassAUROC : tensor(0.8889)
WS24_base/test_loss : tensor(1.0060)
WS24_base/test_loss_epoch : tensor(1.0060)
WS24_base/test_loss_weight : tensor(0.1315)
WS24_base/test_loss_weight_epoch : tensor(0.1315)
WS24_base/test_MulticlassAccuracy : tensor(0.8864)
WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.7739)
WS24_base/test_MulticlassF1Score : tensor(0.8864)
WS24_base/test_MulticlassAUROC : tensor(0.4271)
WS24_boiling/test_loss : tensor(2.0191)
WS24_boiling/test_loss_epoch : tensor(2.0191)
WS24_boiling/test_loss_weight : tensor(0.1348)
WS24_boiling/test_loss_weight_epoch : tensor(0.1348)
WS24_boiling/test_MulticlassAccuracy : tensor(0.5385)
WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.0867)
WS24_boiling/test_MulticlassF1Score : tensor(0.5385)
WS24_boiling/test_MulticlassAUROC : tensor(0.6391)
test_Metric : tensor(0.5324, dtype=torch.float64)
[I 2025-12-03 17:46:27,085] Trial 17 finished with value: 0.46593454935198336 and parameters: {'atom_fea_len': 112, 'h_fea_len': 192, 'n_conv': 2, 'n_h': 2, 'lr_mult': 11, 'extra_fea_len': 16, 'dropout': 0.55}. Best is trial 8 with value: 0.5247209443643848.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 12
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 96
extra_fea_len : 64
h_fea_len : 256
n_conv : 9
n_h : 3
att_S : 64
dropout_prob : 0.25
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=112, bias=True)
  (embedding_atom_norm): LayerNorm((112,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-1): 2 x ConvLayer(
      (fc_full): Linear(in_features=265, out_features=224, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=16, bias=True)
  (embedding_extra_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=128, out_features=192, bias=True)
  (conv_to_fc_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.55, inplace=False)
  (fcs): ModuleList(
    (0): Linear(in_features=192, out_features=192, bias=True)
  )
  (norms): ModuleList(
    (0): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0): Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=192, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=192, out_features=192, bias=True)
      (key): Linear(in_features=192, out_features=192, bias=True)
      (value): Linear(in_features=192, out_features=192, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa067d970>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa067d9a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa067d430>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa067d160>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa067df10>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa067d670>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa067d8e0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                 | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 2.0 M  | ?                                        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 256], [256, 256], [256, 256], [256, 256], [256, 256], [256, 256], [256, 256]]]
1   | model.embedding_atom            | Linear              | 8.9 K  | [4608, 92]                               | [4608, 96]
2   | model.embedding_atom_norm       | LayerNorm           | 192    | [4608, 96]                               | [4608, 96]
3   | model.convs                     | ModuleList          | 409 K  | ?                                        | ?
4   | model.convs.0                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
5   | model.convs.0.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
8   | model.convs.0.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
9   | model.convs.0.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
11  | model.convs.1                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
12  | model.convs.1.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
15  | model.convs.1.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
16  | model.convs.1.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
18  | model.convs.2                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
19  | model.convs.2.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
22  | model.convs.2.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
23  | model.convs.2.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
25  | model.convs.3                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
26  | model.convs.3.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
29  | model.convs.3.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
30  | model.convs.3.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
32  | model.convs.4                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
33  | model.convs.4.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
36  | model.convs.4.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
37  | model.convs.4.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
39  | model.convs.5                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
40  | model.convs.5.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
43  | model.convs.5.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
44  | model.convs.5.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
46  | model.convs.6                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
47  | model.convs.6.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
50  | model.convs.6.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
51  | model.convs.6.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
53  | model.convs.7                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
54  | model.convs.7.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
57  | model.convs.7.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
58  | model.convs.7.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
60  | model.convs.8                   | ConvLayer           | 45.5 K | [[4608, 96], [4608, 10, 41], [4608, 10]] | [4608, 96]
61  | model.convs.8.fc_full           | Linear              | 44.9 K | [4608, 10, 233]                          | [4608, 10, 192]
62  | model.convs.8.sigmoid           | Sigmoid             | 0      | [4608, 10, 96]                           | [4608, 10, 96]
63  | model.convs.8.softplus1         | Softplus            | 0      | [4608, 10, 96]                           | [4608, 10, 96]
64  | model.convs.8.bn1               | BatchNorm1d         | 384    | [46080, 192]                             | [46080, 192]
65  | model.convs.8.bn2               | BatchNorm1d         | 192    | [4608, 96]                               | [4608, 96]
66  | model.convs.8.softplus2         | Softplus            | 0      | [4608, 96]                               | [4608, 96]
67  | model.embedding_extra           | Linear              | 448    | [256, 6]                                 | [256, 64]
68  | model.embedding_extra_norm      | BatchNorm1d         | 128    | [256, 64]                                | [256, 64]
69  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 64]                                | [256, 64]
70  | model.conv_to_fc                | Linear              | 41.2 K | [256, 160]                               | [256, 256]
71  | model.conv_to_fc_norm           | BatchNorm1d         | 512    | [256, 256]                               | [256, 256]
72  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 256]                               | [256, 256]
73  | model.dropout                   | Dropout             | 0      | [256, 256]                               | [256, 256]
74  | model.fcs                       | ModuleList          | 131 K  | ?                                        | ?
75  | model.fcs.0                     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
76  | model.fcs.1                     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
77  | model.norms                     | ModuleList          | 1.0 K  | ?                                        | ?
78  | model.norms.0                   | BatchNorm1d         | 512    | [256, 256]                               | [256, 256]
79  | model.norms.1                   | BatchNorm1d         | 512    | [256, 256]                               | [256, 256]
80  | model.softpluses                | ModuleList          | 0      | ?                                        | ?
81  | model.softpluses.0              | Softplus            | 0      | [256, 256]                               | [256, 256]
82  | model.softpluses.1              | Softplus            | 0      | [256, 256]                               | [256, 256]
83  | model.fc_outs                   | ModuleList          | 3.9 K  | ?                                        | ?
84  | model.fc_outs.0                 | OutputLayer         | 257    | [256, 256]                               | [256, 1]
85  | model.fc_outs.0.fc              | Linear              | 257    | [256, 256]                               | [256, 1]
86  | model.fc_outs.1                 | OutputLayer         | 514    | [256, 256]                               | [256, 2]
87  | model.fc_outs.1.fc              | Sequential          | 514    | [256, 256]                               | [256, 2]
88  | model.fc_outs.1.fc.0            | Linear              | 514    | [256, 256]                               | [256, 2]
89  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
90  | model.fc_outs.2                 | OutputLayer         | 514    | [256, 256]                               | [256, 2]
91  | model.fc_outs.2.fc              | Sequential          | 514    | [256, 256]                               | [256, 2]
92  | model.fc_outs.2.fc.0            | Linear              | 514    | [256, 256]                               | [256, 2]
93  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
94  | model.fc_outs.3                 | OutputLayer         | 1.0 K  | [256, 256]                               | [256, 4]
95  | model.fc_outs.3.fc              | Sequential          | 1.0 K  | [256, 256]                               | [256, 4]
96  | model.fc_outs.3.fc.0            | Linear              | 1.0 K  | [256, 256]                               | [256, 4]
97  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                 | [256, 4]
98  | model.fc_outs.4                 | OutputLayer         | 514    | [256, 256]                               | [256, 2]
99  | model.fc_outs.4.fc              | Sequential          | 514    | [256, 256]                               | [256, 2]
100 | model.fc_outs.4.fc.0            | Linear              | 514    | [256, 256]                               | [256, 2]
101 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
102 | model.fc_outs.5                 | OutputLayer         | 514    | [256, 256]                               | [256, 2]
103 | model.fc_outs.5.fc              | Sequential          | 514    | [256, 256]                               | [256, 2]
104 | model.fc_outs.5.fc.0            | Linear              | 514    | [256, 256]                               | [256, 2]
105 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
106 | model.fc_outs.6                 | OutputLayer         | 514    | [256, 256]                               | [256, 2]
107 | model.fc_outs.6.fc              | Sequential          | 514    | [256, 256]                               | [256, 2]
108 | model.fc_outs.6.fc.0            | Linear              | 514    | [256, 256]                               | [256, 2]
109 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                 | [256, 2]
110 | model.task_norms                | ModuleList          | 3.6 K  | ?                                        | ?
111 | model.task_norms.0              | LayerNorm           | 512    | [256, 256]                               | [256, 256]
112 | model.task_norms.1              | LayerNorm           | 512    | [256, 256]                               | [256, 256]
113 | model.task_norms.2              | LayerNorm           | 512    | [256, 256]                               | [256, 256]
114 | model.task_norms.3              | LayerNorm           | 512    | [256, 256]                               | [256, 256]
115 | model.task_norms.4              | LayerNorm           | 512    | [256, 256]                               | [256, 256]
116 | model.task_norms.5              | LayerNorm           | 512    | [256, 256]                               | [256, 256]
117 | model.task_norms.6              | LayerNorm           | 512    | [256, 256]                               | [256, 256]
118 | model.task_attentions           | ModuleList          | 1.4 M  | ?                                        | ?
119 | model.task_attentions.0         | SelfAttention       | 197 K  | [256, 256]                               | [256, 256]
120 | model.task_attentions.0.query   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
121 | model.task_attentions.0.key     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
122 | model.task_attentions.0.value   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
123 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
124 | model.task_attentions.1         | SelfAttention       | 197 K  | [256, 256]                               | [256, 256]
125 | model.task_attentions.1.query   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
126 | model.task_attentions.1.key     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
127 | model.task_attentions.1.value   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
128 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
129 | model.task_attentions.2         | SelfAttention       | 197 K  | [256, 256]                               | [256, 256]
130 | model.task_attentions.2.query   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
131 | model.task_attentions.2.key     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
132 | model.task_attentions.2.value   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
133 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
134 | model.task_attentions.3         | SelfAttention       | 197 K  | [256, 256]                               | [256, 256]
135 | model.task_attentions.3.query   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
136 | model.task_attentions.3.key     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
137 | model.task_attentions.3.value   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
138 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
139 | model.task_attentions.4         | SelfAttention       | 197 K  | [256, 256]                               | [256, 256]
140 | model.task_attentions.4.query   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
141 | model.task_attentions.4.key     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
142 | model.task_attentions.4.value   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
143 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
144 | model.task_attentions.5         | SelfAttention       | 197 K  | [256, 256]                               | [256, 256]
145 | model.task_attentions.5.query   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
146 | model.task_attentions.5.key     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
147 | model.task_attentions.5.value   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
148 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
149 | model.task_attentions.6         | SelfAttention       | 197 K  | [256, 256]                               | [256, 256]
150 | model.task_attentions.6.query   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
151 | model.task_attentions.6.key     | Linear              | 65.8 K | [256, 256]                               | [256, 256]
152 | model.task_attentions.6.value   | Linear              | 65.8 K | [256, 256]                               | [256, 256]
153 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                              | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
7.931     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_16
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'convs.8.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'convs.8.fc_full.bias', 'convs.8.bn1.weight', 'convs.8.bn1.bias', 'convs.8.bn2.weight', 'convs.8.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 12 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 2.0 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 256], [256, 256], [256, 256], [256, 256], [256, 256], [256, 256], [256, 256]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
7.931     Total estimated model params size (MB)
Using no sampler for validation data.
current_epoch(0): metric=0.0742 > best_metric=0.0000, log val results..
[W 2025-12-03 17:46:39,701] Trial 18 failed with parameters: {'atom_fea_len': 96, 'h_fea_len': 256, 'n_conv': 9, 'n_h': 3, 'lr_mult': 12, 'extra_fea_len': 64, 'dropout': 0.25} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 490.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.35 GiB memory in use. Of the allocated memory 20.69 GiB is allocated by PyTorch, and 432.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 90, in forward
    total_gated_fea = self.fc_full(total_nbr_fea)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 580.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 490.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.35 GiB memory in use. Of the allocated memory 20.69 GiB is allocated by PyTorch, and 432.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 17:46:39,702] Trial 18 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 9
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 272
extra_fea_len : 28
h_fea_len : 160
n_conv : 8
n_h : 2
att_S : 64
dropout_prob : 0.5
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=96, bias=True)
  (embedding_atom_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-8): 9 x ConvLayer(
      (fc_full): Linear(in_features=233, out_features=192, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=64, bias=True)
  (embedding_extra_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=160, out_features=256, bias=True)
  (conv_to_fc_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.25, inplace=False)
  (fcs): ModuleList(
    (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
  )
  (norms): ModuleList(
    (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-1): 2 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=256, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=256, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=256, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=256, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=256, out_features=256, bias=True)
      (key): Linear(in_features=256, out_features=256, bias=True)
      (value): Linear(in_features=256, out_features=256, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90b0cd00>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90b0cbe0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90b0c6a0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90b0c670>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90b0c700>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90b0cdf0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f90b0ce50>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 3.2 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 160], [256, 160], [256, 160], [256, 160], [256, 160], [256, 160], [256, 160]]]
1   | model.embedding_atom            | Linear              | 25.3 K | [4608, 92]                                | [4608, 272]
2   | model.embedding_atom_norm       | LayerNorm           | 544    | [4608, 272]                               | [4608, 272]
3   | model.convs                     | ModuleList          | 2.6 M  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
5   | model.convs.0.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
8   | model.convs.0.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
9   | model.convs.0.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
11  | model.convs.1                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
12  | model.convs.1.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
15  | model.convs.1.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
16  | model.convs.1.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
18  | model.convs.2                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
19  | model.convs.2.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
22  | model.convs.2.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
23  | model.convs.2.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
25  | model.convs.3                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
26  | model.convs.3.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
29  | model.convs.3.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
30  | model.convs.3.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
32  | model.convs.4                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
33  | model.convs.4.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
36  | model.convs.4.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
37  | model.convs.4.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
39  | model.convs.5                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
40  | model.convs.5.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
43  | model.convs.5.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
44  | model.convs.5.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
46  | model.convs.6                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
47  | model.convs.6.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
50  | model.convs.6.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
51  | model.convs.6.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
53  | model.convs.7                   | ConvLayer           | 320 K  | [[4608, 272], [4608, 10, 41], [4608, 10]] | [4608, 272]
54  | model.convs.7.fc_full           | Linear              | 318 K  | [4608, 10, 585]                           | [4608, 10, 544]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 272]                           | [4608, 10, 272]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 272]                           | [4608, 10, 272]
57  | model.convs.7.bn1               | BatchNorm1d         | 1.1 K  | [46080, 544]                              | [46080, 544]
58  | model.convs.7.bn2               | BatchNorm1d         | 544    | [4608, 272]                               | [4608, 272]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 272]                               | [4608, 272]
60  | model.embedding_extra           | Linear              | 196    | [256, 6]                                  | [256, 28]
61  | model.embedding_extra_norm      | BatchNorm1d         | 56     | [256, 28]                                 | [256, 28]
62  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 28]                                 | [256, 28]
63  | model.conv_to_fc                | Linear              | 48.2 K | [256, 300]                                | [256, 160]
64  | model.conv_to_fc_norm           | BatchNorm1d         | 320    | [256, 160]                                | [256, 160]
65  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 160]                                | [256, 160]
66  | model.dropout                   | Dropout             | 0      | [256, 160]                                | [256, 160]
67  | model.fcs                       | ModuleList          | 25.8 K | ?                                         | ?
68  | model.fcs.0                     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
69  | model.norms                     | ModuleList          | 320    | ?                                         | ?
70  | model.norms.0                   | BatchNorm1d         | 320    | [256, 160]                                | [256, 160]
71  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
72  | model.softpluses.0              | Softplus            | 0      | [256, 160]                                | [256, 160]
73  | model.fc_outs                   | ModuleList          | 2.4 K  | ?                                         | ?
74  | model.fc_outs.0                 | OutputLayer         | 161    | [256, 160]                                | [256, 1]
75  | model.fc_outs.0.fc              | Linear              | 161    | [256, 160]                                | [256, 1]
76  | model.fc_outs.1                 | OutputLayer         | 322    | [256, 160]                                | [256, 2]
77  | model.fc_outs.1.fc              | Sequential          | 322    | [256, 160]                                | [256, 2]
78  | model.fc_outs.1.fc.0            | Linear              | 322    | [256, 160]                                | [256, 2]
79  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
80  | model.fc_outs.2                 | OutputLayer         | 322    | [256, 160]                                | [256, 2]
81  | model.fc_outs.2.fc              | Sequential          | 322    | [256, 160]                                | [256, 2]
82  | model.fc_outs.2.fc.0            | Linear              | 322    | [256, 160]                                | [256, 2]
83  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
84  | model.fc_outs.3                 | OutputLayer         | 644    | [256, 160]                                | [256, 4]
85  | model.fc_outs.3.fc              | Sequential          | 644    | [256, 160]                                | [256, 4]
86  | model.fc_outs.3.fc.0            | Linear              | 644    | [256, 160]                                | [256, 4]
87  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
88  | model.fc_outs.4                 | OutputLayer         | 322    | [256, 160]                                | [256, 2]
89  | model.fc_outs.4.fc              | Sequential          | 322    | [256, 160]                                | [256, 2]
90  | model.fc_outs.4.fc.0            | Linear              | 322    | [256, 160]                                | [256, 2]
91  | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
92  | model.fc_outs.5                 | OutputLayer         | 322    | [256, 160]                                | [256, 2]
93  | model.fc_outs.5.fc              | Sequential          | 322    | [256, 160]                                | [256, 2]
94  | model.fc_outs.5.fc.0            | Linear              | 322    | [256, 160]                                | [256, 2]
95  | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
96  | model.fc_outs.6                 | OutputLayer         | 322    | [256, 160]                                | [256, 2]
97  | model.fc_outs.6.fc              | Sequential          | 322    | [256, 160]                                | [256, 2]
98  | model.fc_outs.6.fc.0            | Linear              | 322    | [256, 160]                                | [256, 2]
99  | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
100 | model.task_norms                | ModuleList          | 2.2 K  | ?                                         | ?
101 | model.task_norms.0              | LayerNorm           | 320    | [256, 160]                                | [256, 160]
102 | model.task_norms.1              | LayerNorm           | 320    | [256, 160]                                | [256, 160]
103 | model.task_norms.2              | LayerNorm           | 320    | [256, 160]                                | [256, 160]
104 | model.task_norms.3              | LayerNorm           | 320    | [256, 160]                                | [256, 160]
105 | model.task_norms.4              | LayerNorm           | 320    | [256, 160]                                | [256, 160]
106 | model.task_norms.5              | LayerNorm           | 320    | [256, 160]                                | [256, 160]
107 | model.task_norms.6              | LayerNorm           | 320    | [256, 160]                                | [256, 160]
108 | model.task_attentions           | ModuleList          | 540 K  | ?                                         | ?
109 | model.task_attentions.0         | SelfAttention       | 77.3 K | [256, 160]                                | [256, 160]
110 | model.task_attentions.0.query   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
111 | model.task_attentions.0.key     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
112 | model.task_attentions.0.value   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
113 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
114 | model.task_attentions.1         | SelfAttention       | 77.3 K | [256, 160]                                | [256, 160]
115 | model.task_attentions.1.query   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
116 | model.task_attentions.1.key     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
117 | model.task_attentions.1.value   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
118 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
119 | model.task_attentions.2         | SelfAttention       | 77.3 K | [256, 160]                                | [256, 160]
120 | model.task_attentions.2.query   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
121 | model.task_attentions.2.key     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
122 | model.task_attentions.2.value   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
123 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
124 | model.task_attentions.3         | SelfAttention       | 77.3 K | [256, 160]                                | [256, 160]
125 | model.task_attentions.3.query   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
126 | model.task_attentions.3.key     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
127 | model.task_attentions.3.value   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
128 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
129 | model.task_attentions.4         | SelfAttention       | 77.3 K | [256, 160]                                | [256, 160]
130 | model.task_attentions.4.query   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
131 | model.task_attentions.4.key     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
132 | model.task_attentions.4.value   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
133 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
134 | model.task_attentions.5         | SelfAttention       | 77.3 K | [256, 160]                                | [256, 160]
135 | model.task_attentions.5.query   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
136 | model.task_attentions.5.key     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
137 | model.task_attentions.5.value   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
138 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
139 | model.task_attentions.6         | SelfAttention       | 77.3 K | [256, 160]                                | [256, 160]
140 | model.task_attentions.6.query   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
141 | model.task_attentions.6.key     | Linear              | 25.8 K | [256, 160]                                | [256, 160]
142 | model.task_attentions.6.value   | Linear              | 25.8 K | [256, 160]                                | [256, 160]
143 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3.2 M     Trainable params
0         Non-trainable params
3.2 M     Total params
12.838    Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_17
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'norms.0.weight', 'norms.0.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 9 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 3.2 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 160], [256, 160], [256, 160], [256, 160], [256, 160], [256, 160], [256, 160]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3.2 M     Trainable params
0         Non-trainable params
3.2 M     Total params
12.838    Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 17:46:59,640] Trial 19 failed with parameters: {'atom_fea_len': 272, 'h_fea_len': 160, 'n_conv': 8, 'n_h': 2, 'lr_mult': 9, 'extra_fea_len': 28, 'dropout': 0.5} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 22.03 GiB of which 1.50 GiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.33 GiB memory in use. Of the allocated memory 18.26 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 87, in forward
    total_nbr_fea = torch.cat(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 22.03 GiB of which 1.50 GiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.33 GiB memory in use. Of the allocated memory 18.26 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 17:46:59,641] Trial 19 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 7
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 128
extra_fea_len : 52
h_fea_len : 176
n_conv : 1
n_h : 2
att_S : 64
dropout_prob : 0.25
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=272, bias=True)
  (embedding_atom_norm): LayerNorm((272,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-7): 8 x ConvLayer(
      (fc_full): Linear(in_features=585, out_features=544, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=28, bias=True)
  (embedding_extra_norm): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=300, out_features=160, bias=True)
  (conv_to_fc_norm): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.5, inplace=False)
  (fcs): ModuleList(
    (0): Linear(in_features=160, out_features=160, bias=True)
  )
  (norms): ModuleList(
    (0): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0): Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=160, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=160, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=160, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=160, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((160,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=160, out_features=160, bias=True)
      (key): Linear(in_features=160, out_features=160, bias=True)
      (value): Linear(in_features=160, out_features=160, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4b774f0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4b77fd0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4b778b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4b77970>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4b77280>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4b77c70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa4b77640>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
   | Name                            | Type                | Params | In sizes                                  | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0  | model                           | CrystalGraphConvNet | 812 K  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176]]]
1  | model.embedding_atom            | Linear              | 11.9 K | [4608, 92]                                | [4608, 128]
2  | model.embedding_atom_norm       | LayerNorm           | 256    | [4608, 128]                               | [4608, 128]
3  | model.convs                     | ModuleList          | 77.1 K | ?                                         | ?
4  | model.convs.0                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
5  | model.convs.0.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
6  | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
7  | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
8  | model.convs.0.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
9  | model.convs.0.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
10 | model.convs.0.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
11 | model.embedding_extra           | Linear              | 364    | [256, 6]                                  | [256, 52]
12 | model.embedding_extra_norm      | BatchNorm1d         | 104    | [256, 52]                                 | [256, 52]
13 | model.embedding_extra_softplus  | Softplus            | 0      | [256, 52]                                 | [256, 52]
14 | model.conv_to_fc                | Linear              | 31.9 K | [256, 180]                                | [256, 176]
15 | model.conv_to_fc_norm           | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
16 | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 176]                                | [256, 176]
17 | model.dropout                   | Dropout             | 0      | [256, 176]                                | [256, 176]
18 | model.fcs                       | ModuleList          | 31.2 K | ?                                         | ?
19 | model.fcs.0                     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
20 | model.norms                     | ModuleList          | 352    | ?                                         | ?
21 | model.norms.0                   | BatchNorm1d         | 352    | [256, 176]                                | [256, 176]
22 | model.softpluses                | ModuleList          | 0      | ?                                         | ?
23 | model.softpluses.0              | Softplus            | 0      | [256, 176]                                | [256, 176]
24 | model.fc_outs                   | ModuleList          | 2.7 K  | ?                                         | ?
25 | model.fc_outs.0                 | OutputLayer         | 177    | [256, 176]                                | [256, 1]
26 | model.fc_outs.0.fc              | Linear              | 177    | [256, 176]                                | [256, 1]
27 | model.fc_outs.1                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
28 | model.fc_outs.1.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
29 | model.fc_outs.1.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
30 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
31 | model.fc_outs.2                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
32 | model.fc_outs.2.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
33 | model.fc_outs.2.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
34 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
35 | model.fc_outs.3                 | OutputLayer         | 708    | [256, 176]                                | [256, 4]
36 | model.fc_outs.3.fc              | Sequential          | 708    | [256, 176]                                | [256, 4]
37 | model.fc_outs.3.fc.0            | Linear              | 708    | [256, 176]                                | [256, 4]
38 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
39 | model.fc_outs.4                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
40 | model.fc_outs.4.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
41 | model.fc_outs.4.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
42 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
43 | model.fc_outs.5                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
44 | model.fc_outs.5.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
45 | model.fc_outs.5.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
46 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
47 | model.fc_outs.6                 | OutputLayer         | 354    | [256, 176]                                | [256, 2]
48 | model.fc_outs.6.fc              | Sequential          | 354    | [256, 176]                                | [256, 2]
49 | model.fc_outs.6.fc.0            | Linear              | 354    | [256, 176]                                | [256, 2]
50 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
51 | model.task_norms                | ModuleList          | 2.5 K  | ?                                         | ?
52 | model.task_norms.0              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
53 | model.task_norms.1              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
54 | model.task_norms.2              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
55 | model.task_norms.3              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
56 | model.task_norms.4              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
57 | model.task_norms.5              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
58 | model.task_norms.6              | LayerNorm           | 352    | [256, 176]                                | [256, 176]
59 | model.task_attentions           | ModuleList          | 654 K  | ?                                         | ?
60 | model.task_attentions.0         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
61 | model.task_attentions.0.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
62 | model.task_attentions.0.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
63 | model.task_attentions.0.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
64 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
65 | model.task_attentions.1         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
66 | model.task_attentions.1.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
67 | model.task_attentions.1.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
68 | model.task_attentions.1.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
69 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
70 | model.task_attentions.2         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
71 | model.task_attentions.2.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
72 | model.task_attentions.2.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
73 | model.task_attentions.2.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
74 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
75 | model.task_attentions.3         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
76 | model.task_attentions.3.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
77 | model.task_attentions.3.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
78 | model.task_attentions.3.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
79 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
80 | model.task_attentions.4         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
81 | model.task_attentions.4.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
82 | model.task_attentions.4.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
83 | model.task_attentions.4.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
84 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
85 | model.task_attentions.5         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
86 | model.task_attentions.5.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
87 | model.task_attentions.5.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
88 | model.task_attentions.5.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
89 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
90 | model.task_attentions.6         | SelfAttention       | 93.5 K | [256, 176]                                | [256, 176]
91 | model.task_attentions.6.query   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
92 | model.task_attentions.6.key     | Linear              | 31.2 K | [256, 176]                                | [256, 176]
93 | model.task_attentions.6.value   | Linear              | 31.2 K | [256, 176]                                | [256, 176]
94 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
812 K     Trainable params
0         Non-trainable params
812 K     Total params
3.251     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'norms.0.weight', 'norms.0.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 7 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 812 K  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176], [256, 176]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
812 K     Trainable params
0         Non-trainable params
812 K     Total params
3.251     Total estimated model params size (MB)
Using no sampler for validation data.
current_epoch(0): metric=0.0853 > best_metric=0.0000, log val results..
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/trial/_trial.py:503: UserWarning: The reported value is ignored because this `step` 0 is already reported.
  warnings.warn(
Epoch 0, global step 17: 'val_Metric' reached -0.09355 (best -0.09355), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=00-val_Metric=-0.094.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(1): metric=0.3180 > best_metric=0.0853, log val results..
Epoch 1, global step 34: 'val_Metric' reached 0.31801 (best 0.31801), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=01-val_Metric=0.318.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(2): metric=0.3400 > best_metric=0.3180, log val results..
Epoch 2, global step 51: 'val_Metric' reached 0.34002 (best 0.34002), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=02-val_Metric=0.340.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(3): metric=0.3663 > best_metric=0.3400, log val results..
Epoch 3, global step 68: 'val_Metric' reached 0.36630 (best 0.36630), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=03-val_Metric=0.366.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 4, global step 85: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(5): metric=0.4073 > best_metric=0.3663, log val results..
Epoch 5, global step 102: 'val_Metric' reached 0.40735 (best 0.40735), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=05-val_Metric=0.407.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 6, global step 119: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 7, global step 136: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(8): metric=0.4218 > best_metric=0.4073, log val results..
Epoch 8, global step 153: 'val_Metric' reached 0.42179 (best 0.42179), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=08-val_Metric=0.422.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(9): metric=0.4623 > best_metric=0.4218, log val results..
Epoch 9, global step 170: 'val_Metric' reached 0.46225 (best 0.46225), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=09-val_Metric=0.462.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 10, global step 187: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(11): metric=0.4752 > best_metric=0.4623, log val results..
Epoch 11, global step 204: 'val_Metric' reached 0.47515 (best 0.47515), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=11-val_Metric=0.475.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(12): metric=0.4967 > best_metric=0.4752, log val results..
Epoch 12, global step 221: 'val_Metric' reached 0.49671 (best 0.49671), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=12-val_Metric=0.497.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 13, global step 238: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 14, global step 255: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 15, global step 272: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 16, global step 289: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(17): metric=0.5040 > best_metric=0.4967, log val results..
Epoch 17, global step 306: 'val_Metric' reached 0.50396 (best 0.50396), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=17-val_Metric=0.504.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 18, global step 323: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 19, global step 340: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 20, global step 357: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 21, global step 374: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 22, global step 391: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 23, global step 408: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 24, global step 425: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 25, global step 442: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 26, global step 459: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 27, global step 476: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 28, global step 493: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 29, global step 510: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 30, global step 527: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 31, global step 544: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 32, global step 561: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 33, global step 578: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 34, global step 595: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 35, global step 612: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 36, global step 629: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 37, global step 646: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 38, global step 663: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 39, global step 680: 'val_Metric' reached 0.50438 (best 0.50438), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=39-val_Metric=0.504.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 40, global step 697: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 41, global step 714: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 42, global step 731: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 43, global step 748: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 44, global step 765: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 45, global step 782: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 46, global step 799: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(47): metric=0.5088 > best_metric=0.5040, log val results..
Epoch 47, global step 816: 'val_Metric' reached 0.50876 (best 0.50876), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=47-val_Metric=0.509.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 48, global step 833: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
current_epoch(49): metric=0.5264 > best_metric=0.5088, log val results..
Epoch 49, global step 850: 'val_Metric' reached 0.52643 (best 0.52643), saving model to '/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=49-val_Metric=0.526.ckpt' as top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 50, global step 867: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 51, global step 884: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 52, global step 901: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 53, global step 918: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 54, global step 935: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 55, global step 952: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 56, global step 969: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 57, global step 986: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 58, global step 1003: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 59, global step 1020: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 60, global step 1037: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 61, global step 1054: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 62, global step 1071: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 63, global step 1088: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 64, global step 1105: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 65, global step 1122: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 66, global step 1139: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 67, global step 1156: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 68, global step 1173: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 69, global step 1190: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 70, global step 1207: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 71, global step 1224: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 72, global step 1241: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 73, global step 1258: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 74, global step 1275: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 75, global step 1292: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 76, global step 1309: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 77, global step 1326: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 78, global step 1343: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 79, global step 1360: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 80, global step 1377: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 81, global step 1394: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 82, global step 1411: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 83, global step 1428: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 84, global step 1445: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 85, global step 1462: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 86, global step 1479: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 87, global step 1496: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 88, global step 1513: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 89, global step 1530: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 90, global step 1547: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 91, global step 1564: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 92, global step 1581: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 93, global step 1598: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 94, global step 1615: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 95, global step 1632: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 96, global step 1649: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 97, global step 1666: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 98, global step 1683: 'val_Metric' was not in top 1
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Epoch 99, global step 1700: 'val_Metric' was not in top 1
Best model path: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=49-val_Metric=0.526.ckpt
##################################################best
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=49-val_Metric=0.526.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=49-val_Metric=0.526.ckpt
Using no sampler for validation data.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m           Validate metric           [0m[1m [0m[1m [0m[1m            DataLoader 0            [0m[1m [0m

[36m [0m[36m       SSD/val_MulticlassAUROC       [0m[36m [0m[35m [0m[35m         0.7230732440948486         [0m[35m [0m
[36m [0m[36m     SSD/val_MulticlassAccuracy      [0m[36m [0m[35m [0m[35m         0.6602022647857666         [0m[35m [0m
[36m [0m[36m      SSD/val_MulticlassF1Score      [0m[36m [0m[35m [0m[35m         0.6602022647857666         [0m[35m [0m
[36m [0m[36m SSD/val_MulticlassMatthewsCorrCoef  [0m[36m [0m[35m [0m[35m         0.3223935067653656         [0m[35m [0m
[36m [0m[36m         SSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.7538074254989624         [0m[35m [0m
[36m [0m[36m      SSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         1.6994599103927612         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanAbsoluteError      [0m[36m [0m[35m [0m[35m         51.36189270019531          [0m[35m [0m
[36m [0m[36m TSD/val_MeanAbsolutePercentageError [0m[36m [0m[35m [0m[35m        0.14951574802398682         [0m[35m [0m
[36m [0m[36m      TSD/val_MeanSquaredError       [0m[36m [0m[35m [0m[35m          4576.6728515625           [0m[35m [0m
[36m [0m[36m           TSD/val_R2Score           [0m[36m [0m[35m [0m[35m         0.4057115912437439         [0m[35m [0m
[36m [0m[36m         TSD/val_loss_epoch          [0m[36m [0m[35m [0m[35m         0.5763952732086182         [0m[35m [0m
[36m [0m[36m      TSD/val_loss_weight_epoch      [0m[36m [0m[35m [0m[35m         2.5557641983032227         [0m[35m [0m
[36m [0m[36m    WS24_acid/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.6734694242477417         [0m[35m [0m
[36m [0m[36m  WS24_acid/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.6785714030265808         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.6785714030265808         [0m[35m [0m
[36m [0m[36mWS24_acid/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m         0.3823595345020294         [0m[35m [0m
[36m [0m[36m      WS24_acid/val_loss_epoch       [0m[36m [0m[35m [0m[35m         1.5735193490982056         [0m[35m [0m
[36m [0m[36m   WS24_acid/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.18408076465129852         [0m[35m [0m
[36m [0m[36m    WS24_base/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m                0.25                [0m[35m [0m
[36m [0m[36m  WS24_base/val_MulticlassAccuracy   [0m[36m [0m[35m [0m[35m         0.4791666567325592         [0m[35m [0m
[36m [0m[36m   WS24_base/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.4791666567325592         [0m[35m [0m
[36m [0m[36mWS24_base/val_MulticlassMatthewsCorr[0m[36m [0m[35m [0m[35m        -0.05349064618349075        [0m[35m [0m
[36m [0m[36m      WS24_base/val_loss_epoch       [0m[36m [0m[35m [0m[35m         3.4215054512023926         [0m[35m [0m
[36m [0m[36m   WS24_base/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m        0.13148626685142517         [0m[35m [0m
[36m [0m[36m  WS24_boiling/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.5694444179534912         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.4166666567325592         [0m[35m [0m
[36m [0m[36m WS24_boiling/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.4166666567325592         [0m[35m [0m
[36m [0m[36mWS24_boiling/val_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m        -0.16903084516525269        [0m[35m [0m
[36m [0m[36m     WS24_boiling/val_loss_epoch     [0m[36m [0m[35m [0m[35m          2.19228196144104          [0m[35m [0m
[36m [0m[36m WS24_boiling/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m        0.13477341830730438         [0m[35m [0m
[36m [0m[36m   WS24_water/val_MulticlassAUROC    [0m[36m [0m[35m [0m[35m         0.7656258344650269         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7277777791023254         [0m[35m [0m
[36m [0m[36m  WS24_water/val_MulticlassF1Score   [0m[36m [0m[35m [0m[35m         0.7277777791023254         [0m[35m [0m
[36m [0m[36mWS24_water/val_MulticlassMatthewsCor[0m[36m [0m[35m [0m[35m        0.46144962310791016         [0m[35m [0m
[36m [0m[36m      WS24_water/val_loss_epoch      [0m[36m [0m[35m [0m[35m         1.2362161874771118         [0m[35m [0m
[36m [0m[36m  WS24_water/val_loss_weight_epoch   [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m   WS24_water4/val_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.6989614367485046         [0m[35m [0m
[36m [0m[36m WS24_water4/val_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.4628571569919586         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.4628571569919586         [0m[35m [0m
[36m [0m[36mWS24_water4/val_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m        0.24497033655643463         [0m[35m [0m
[36m [0m[36m     WS24_water4/val_loss_epoch      [0m[36m [0m[35m [0m[35m         2.4115638732910156         [0m[35m [0m
[36m [0m[36m  WS24_water4/val_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269         [0m[35m [0m
[36m [0m[36m       val_MergedMetric_epoch        [0m[36m [0m[35m [0m[35m         0.5175691246986389         [0m[35m [0m
[36m [0m[36m             val_Metric              [0m[36m [0m[35m [0m[35m         0.5264262548167313         [0m[35m [0m
[36m [0m[36m           val_loss_epoch            [0m[36m [0m[35m [0m[35m         2.5192553997039795         [0m[35m [0m

TSD/val_loss : tensor(0.5764)
TSD/val_loss_epoch : tensor(0.5764)
TSD/val_loss_weight : tensor(2.5558)
TSD/val_loss_weight_epoch : tensor(2.5558)
TSD/val_R2Score : tensor(0.4057)
TSD/val_MeanAbsoluteError : tensor(51.3619)
TSD/val_MeanAbsolutePercentageError : tensor(0.1495)
TSD/val_MeanSquaredError : tensor(4576.6729)
val_loss : tensor(2.5193)
val_loss_epoch : tensor(2.5193)
val_MergedMetric : tensor(0.5176)
val_MergedMetric_epoch : tensor(0.5176)
SSD/val_loss : tensor(0.7538)
SSD/val_loss_epoch : tensor(0.7538)
SSD/val_loss_weight : tensor(1.6995)
SSD/val_loss_weight_epoch : tensor(1.6995)
SSD/val_MulticlassAccuracy : tensor(0.6602)
SSD/val_MulticlassMatthewsCorrCoef : tensor(0.3224)
SSD/val_MulticlassF1Score : tensor(0.6602)
SSD/val_MulticlassAUROC : tensor(0.7231)
WS24_water/val_loss : tensor(1.2362)
WS24_water/val_loss_epoch : tensor(1.2362)
WS24_water/val_loss_weight : tensor(1.1472)
WS24_water/val_loss_weight_epoch : tensor(1.1472)
WS24_water/val_MulticlassAccuracy : tensor(0.7278)
WS24_water/val_MulticlassMatthewsCorrCoef : tensor(0.4614)
WS24_water/val_MulticlassF1Score : tensor(0.7278)
WS24_water/val_MulticlassAUROC : tensor(0.7656)
WS24_water4/val_loss : tensor(2.4116)
WS24_water4/val_loss_epoch : tensor(2.4116)
WS24_water4/val_loss_weight : tensor(1.1472)
WS24_water4/val_loss_weight_epoch : tensor(1.1472)
WS24_water4/val_MulticlassAccuracy : tensor(0.4629)
WS24_water4/val_MulticlassMatthewsCorrCoef : tensor(0.2450)
WS24_water4/val_MulticlassF1Score : tensor(0.4629)
WS24_water4/val_MulticlassAUROC : tensor(0.6990)
WS24_acid/val_loss : tensor(1.5735)
WS24_acid/val_loss_epoch : tensor(1.5735)
WS24_acid/val_loss_weight : tensor(0.1841)
WS24_acid/val_loss_weight_epoch : tensor(0.1841)
WS24_acid/val_MulticlassAccuracy : tensor(0.6786)
WS24_acid/val_MulticlassMatthewsCorrCoef : tensor(0.3824)
WS24_acid/val_MulticlassF1Score : tensor(0.6786)
WS24_acid/val_MulticlassAUROC : tensor(0.6735)
WS24_base/val_loss : tensor(3.4215)
WS24_base/val_loss_epoch : tensor(3.4215)
WS24_base/val_loss_weight : tensor(0.1315)
WS24_base/val_loss_weight_epoch : tensor(0.1315)
WS24_base/val_MulticlassAccuracy : tensor(0.4792)
WS24_base/val_MulticlassMatthewsCorrCoef : tensor(-0.0535)
WS24_base/val_MulticlassF1Score : tensor(0.4792)
WS24_base/val_MulticlassAUROC : tensor(0.2500)
WS24_boiling/val_loss : tensor(2.1923)
WS24_boiling/val_loss_epoch : tensor(2.1923)
WS24_boiling/val_loss_weight : tensor(0.1348)
WS24_boiling/val_loss_weight_epoch : tensor(0.1348)
WS24_boiling/val_MulticlassAccuracy : tensor(0.4167)
WS24_boiling/val_MulticlassMatthewsCorrCoef : tensor(-0.1690)
WS24_boiling/val_MulticlassF1Score : tensor(0.4167)
WS24_boiling/val_MulticlassAUROC : tensor(0.5694)
val_Metric : tensor(0.5264, dtype=torch.float64)
Restoring states from the checkpoint path at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=49-val_Metric=0.526.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from the checkpoint at /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_18/checkpoints/best-epoch=49-val_Metric=0.526.ckpt
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)

[1m [0m[1m            Test metric             [0m[1m [0m[1m [0m[1m            DataLoader 0             [0m[1m [0m

[36m [0m[36m      SSD/test_MulticlassAUROC      [0m[36m [0m[35m [0m[35m         0.6553599834442139          [0m[35m [0m
[36m [0m[36m    SSD/test_MulticlassAccuracy     [0m[36m [0m[35m [0m[35m         0.6536458134651184          [0m[35m [0m
[36m [0m[36m     SSD/test_MulticlassF1Score     [0m[36m [0m[35m [0m[35m         0.6536458134651184          [0m[35m [0m
[36m [0m[36mSSD/test_MulticlassMatthewsCorrCoef [0m[36m [0m[35m [0m[35m         0.2974105179309845          [0m[35m [0m
[36m [0m[36m        SSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.8255292773246765          [0m[35m [0m
[36m [0m[36m     SSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         1.6994599103927612          [0m[35m [0m
[36m [0m[36m     TSD/test_MeanAbsoluteError     [0m[36m [0m[35m [0m[35m          52.34319305419922          [0m[35m [0m
[36m [0m[36mTSD/test_MeanAbsolutePercentageError[0m[36m [0m[35m [0m[35m         0.15798115730285645         [0m[35m [0m
[36m [0m[36m     TSD/test_MeanSquaredError      [0m[36m [0m[35m [0m[35m           4836.123046875            [0m[35m [0m
[36m [0m[36m          TSD/test_R2Score          [0m[36m [0m[35m [0m[35m         0.32299190759658813         [0m[35m [0m
[36m [0m[36m        TSD/test_loss_epoch         [0m[36m [0m[35m [0m[35m         0.6090709567070007          [0m[35m [0m
[36m [0m[36m     TSD/test_loss_weight_epoch     [0m[36m [0m[35m [0m[35m         2.5557641983032227          [0m[35m [0m
[36m [0m[36m   WS24_acid/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.8086420297622681          [0m[35m [0m
[36m [0m[36m WS24_acid/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.7777777910232544          [0m[35m [0m
[36m [0m[36mWS24_acid/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m          0.55901700258255           [0m[35m [0m
[36m [0m[36m     WS24_acid/test_loss_epoch      [0m[36m [0m[35m [0m[35m          0.848594605922699          [0m[35m [0m
[36m [0m[36m  WS24_acid/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.18408076465129852         [0m[35m [0m
[36m [0m[36m   WS24_base/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.44999998807907104         [0m[35m [0m
[36m [0m[36m WS24_base/test_MulticlassAccuracy  [0m[36m [0m[35m [0m[35m         0.8636363744735718          [0m[35m [0m
[36m [0m[36m  WS24_base/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m         0.8636363744735718          [0m[35m [0m
[36m [0m[36mWS24_base/test_MulticlassMatthewsCo[0m[36m [0m[35m [0m[35m         0.7501487731933594          [0m[35m [0m
[36m [0m[36m     WS24_base/test_loss_epoch      [0m[36m [0m[35m [0m[35m         0.7653347253799438          [0m[35m [0m
[36m [0m[36m  WS24_base/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         0.13148626685142517         [0m[35m [0m
[36m [0m[36m WS24_boiling/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.7396450042724609          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassAccuracy[0m[36m [0m[35m [0m[35m         0.7692307829856873          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.7692307829856873          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_MulticlassMatthew[0m[36m [0m[35m [0m[35m         0.5384615659713745          [0m[35m [0m
[36m [0m[36m    WS24_boiling/test_loss_epoch    [0m[36m [0m[35m [0m[35m         1.1891796588897705          [0m[35m [0m
[36m [0m[36mWS24_boiling/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         0.13477341830730438         [0m[35m [0m
[36m [0m[36m  WS24_water/test_MulticlassAUROC   [0m[36m [0m[35m [0m[35m         0.7379423975944519          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m          0.698630154132843          [0m[35m [0m
[36m [0m[36m WS24_water/test_MulticlassF1Score  [0m[36m [0m[35m [0m[35m          0.698630154132843          [0m[35m [0m
[36m [0m[36mWS24_water/test_MulticlassMatthewsC[0m[36m [0m[35m [0m[35m         0.37800267338752747         [0m[35m [0m
[36m [0m[36m     WS24_water/test_loss_epoch     [0m[36m [0m[35m [0m[35m         1.1695311069488525          [0m[35m [0m
[36m [0m[36m WS24_water/test_loss_weight_epoch  [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m  WS24_water4/test_MulticlassAUROC  [0m[36m [0m[35m [0m[35m         0.7805162668228149          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassAccuracy [0m[36m [0m[35m [0m[35m         0.5137614607810974          [0m[35m [0m
[36m [0m[36m WS24_water4/test_MulticlassF1Score [0m[36m [0m[35m [0m[35m         0.5137614607810974          [0m[35m [0m
[36m [0m[36mWS24_water4/test_MulticlassMatthews[0m[36m [0m[35m [0m[35m         0.28964704275131226         [0m[35m [0m
[36m [0m[36m    WS24_water4/test_loss_epoch     [0m[36m [0m[35m [0m[35m          4.732425212860107          [0m[35m [0m
[36m [0m[36m WS24_water4/test_loss_weight_epoch [0m[36m [0m[35m [0m[35m         1.1472176313400269          [0m[35m [0m
[36m [0m[36m            test_Metric             [0m[36m [0m[35m [0m[35m         0.5272720031579348          [0m[35m [0m
[36m [0m[36m          test_loss_epoch           [0m[36m [0m[35m [0m[35m          3.339972734451294          [0m[35m [0m

TSD/test_loss : tensor(0.6091)
TSD/test_loss_epoch : tensor(0.6091)
TSD/test_loss_weight : tensor(2.5558)
TSD/test_loss_weight_epoch : tensor(2.5558)
TSD/test_R2Score : tensor(0.3230)
TSD/test_MeanAbsoluteError : tensor(52.3432)
TSD/test_MeanAbsolutePercentageError : tensor(0.1580)
TSD/test_MeanSquaredError : tensor(4836.1230)
test_loss : tensor(3.3400)
test_loss_epoch : tensor(3.3400)
SSD/test_loss : tensor(0.8255)
SSD/test_loss_epoch : tensor(0.8255)
SSD/test_loss_weight : tensor(1.6995)
SSD/test_loss_weight_epoch : tensor(1.6995)
SSD/test_MulticlassAccuracy : tensor(0.6536)
SSD/test_MulticlassMatthewsCorrCoef : tensor(0.2974)
SSD/test_MulticlassF1Score : tensor(0.6536)
SSD/test_MulticlassAUROC : tensor(0.6554)
WS24_water/test_loss : tensor(1.1695)
WS24_water/test_loss_epoch : tensor(1.1695)
WS24_water/test_loss_weight : tensor(1.1472)
WS24_water/test_loss_weight_epoch : tensor(1.1472)
WS24_water/test_MulticlassAccuracy : tensor(0.6986)
WS24_water/test_MulticlassMatthewsCorrCoef : tensor(0.3780)
WS24_water/test_MulticlassF1Score : tensor(0.6986)
WS24_water/test_MulticlassAUROC : tensor(0.7379)
WS24_water4/test_loss : tensor(4.7324)
WS24_water4/test_loss_epoch : tensor(4.7324)
WS24_water4/test_loss_weight : tensor(1.1472)
WS24_water4/test_loss_weight_epoch : tensor(1.1472)
WS24_water4/test_MulticlassAccuracy : tensor(0.5138)
WS24_water4/test_MulticlassMatthewsCorrCoef : tensor(0.2896)
WS24_water4/test_MulticlassF1Score : tensor(0.5138)
WS24_water4/test_MulticlassAUROC : tensor(0.7805)
WS24_acid/test_loss : tensor(0.8486)
WS24_acid/test_loss_epoch : tensor(0.8486)
WS24_acid/test_loss_weight : tensor(0.1841)
WS24_acid/test_loss_weight_epoch : tensor(0.1841)
WS24_acid/test_MulticlassAccuracy : tensor(0.7778)
WS24_acid/test_MulticlassMatthewsCorrCoef : tensor(0.5590)
WS24_acid/test_MulticlassF1Score : tensor(0.7778)
WS24_acid/test_MulticlassAUROC : tensor(0.8086)
WS24_base/test_loss : tensor(0.7653)
WS24_base/test_loss_epoch : tensor(0.7653)
WS24_base/test_loss_weight : tensor(0.1315)
WS24_base/test_loss_weight_epoch : tensor(0.1315)
WS24_base/test_MulticlassAccuracy : tensor(0.8636)
WS24_base/test_MulticlassMatthewsCorrCoef : tensor(0.7501)
WS24_base/test_MulticlassF1Score : tensor(0.8636)
WS24_base/test_MulticlassAUROC : tensor(0.4500)
WS24_boiling/test_loss : tensor(1.1892)
WS24_boiling/test_loss_epoch : tensor(1.1892)
WS24_boiling/test_loss_weight : tensor(0.1348)
WS24_boiling/test_loss_weight_epoch : tensor(0.1348)
WS24_boiling/test_MulticlassAccuracy : tensor(0.7692)
WS24_boiling/test_MulticlassMatthewsCorrCoef : tensor(0.5385)
WS24_boiling/test_MulticlassF1Score : tensor(0.7692)
WS24_boiling/test_MulticlassAUROC : tensor(0.7396)
test_Metric : tensor(0.5273, dtype=torch.float64)
[I 2025-12-03 18:12:07,204] Trial 20 finished with value: 0.458112831691546 and parameters: {'atom_fea_len': 128, 'h_fea_len': 176, 'n_conv': 1, 'n_h': 2, 'lr_mult': 7, 'extra_fea_len': 52, 'dropout': 0.25}. Best is trial 8 with value: 0.5247209443643848.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 7
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 256
extra_fea_len : 60
h_fea_len : 112
n_conv : 7
n_h : 10
att_S : 64
dropout_prob : 0.5
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=128, bias=True)
  (embedding_atom_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0): ConvLayer(
      (fc_full): Linear(in_features=297, out_features=256, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=52, bias=True)
  (embedding_extra_norm): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=180, out_features=176, bias=True)
  (conv_to_fc_norm): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.25, inplace=False)
  (fcs): ModuleList(
    (0): Linear(in_features=176, out_features=176, bias=True)
  )
  (norms): ModuleList(
    (0): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0): Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=176, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=176, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=176, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=176, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((176,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=176, out_features=176, bias=True)
      (key): Linear(in_features=176, out_features=176, bias=True)
      (value): Linear(in_features=176, out_features=176, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92a0cc70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92a0cfd0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92a0c520>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92a0cbe0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92a0ccd0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92a0c910>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92a0c460>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 2.4 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 112], [256, 112], [256, 112], [256, 112], [256, 112], [256, 112], [256, 112]]]
1   | model.embedding_atom            | Linear              | 23.8 K | [4608, 92]                                | [4608, 256]
2   | model.embedding_atom_norm       | LayerNorm           | 512    | [4608, 256]                               | [4608, 256]
3   | model.convs                     | ModuleList          | 2.0 M  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
5   | model.convs.0.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
8   | model.convs.0.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
9   | model.convs.0.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
11  | model.convs.1                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
12  | model.convs.1.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
15  | model.convs.1.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
16  | model.convs.1.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
18  | model.convs.2                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
19  | model.convs.2.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
22  | model.convs.2.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
23  | model.convs.2.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
25  | model.convs.3                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
26  | model.convs.3.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
29  | model.convs.3.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
30  | model.convs.3.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
32  | model.convs.4                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
33  | model.convs.4.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
36  | model.convs.4.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
37  | model.convs.4.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
39  | model.convs.5                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
40  | model.convs.5.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
43  | model.convs.5.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
44  | model.convs.5.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
46  | model.convs.6                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
47  | model.convs.6.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
50  | model.convs.6.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
51  | model.convs.6.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
53  | model.embedding_extra           | Linear              | 420    | [256, 6]                                  | [256, 60]
54  | model.embedding_extra_norm      | BatchNorm1d         | 120    | [256, 60]                                 | [256, 60]
55  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 60]                                 | [256, 60]
56  | model.conv_to_fc                | Linear              | 35.5 K | [256, 316]                                | [256, 112]
57  | model.conv_to_fc_norm           | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
58  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 112]                                | [256, 112]
59  | model.dropout                   | Dropout             | 0      | [256, 112]                                | [256, 112]
60  | model.fcs                       | ModuleList          | 113 K  | ?                                         | ?
61  | model.fcs.0                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
62  | model.fcs.1                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
63  | model.fcs.2                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
64  | model.fcs.3                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
65  | model.fcs.4                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
66  | model.fcs.5                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
67  | model.fcs.6                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
68  | model.fcs.7                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
69  | model.fcs.8                     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
70  | model.norms                     | ModuleList          | 2.0 K  | ?                                         | ?
71  | model.norms.0                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
72  | model.norms.1                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
73  | model.norms.2                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
74  | model.norms.3                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
75  | model.norms.4                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
76  | model.norms.5                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
77  | model.norms.6                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
78  | model.norms.7                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
79  | model.norms.8                   | BatchNorm1d         | 224    | [256, 112]                                | [256, 112]
80  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
81  | model.softpluses.0              | Softplus            | 0      | [256, 112]                                | [256, 112]
82  | model.softpluses.1              | Softplus            | 0      | [256, 112]                                | [256, 112]
83  | model.softpluses.2              | Softplus            | 0      | [256, 112]                                | [256, 112]
84  | model.softpluses.3              | Softplus            | 0      | [256, 112]                                | [256, 112]
85  | model.softpluses.4              | Softplus            | 0      | [256, 112]                                | [256, 112]
86  | model.softpluses.5              | Softplus            | 0      | [256, 112]                                | [256, 112]
87  | model.softpluses.6              | Softplus            | 0      | [256, 112]                                | [256, 112]
88  | model.softpluses.7              | Softplus            | 0      | [256, 112]                                | [256, 112]
89  | model.softpluses.8              | Softplus            | 0      | [256, 112]                                | [256, 112]
90  | model.fc_outs                   | ModuleList          | 1.7 K  | ?                                         | ?
91  | model.fc_outs.0                 | OutputLayer         | 113    | [256, 112]                                | [256, 1]
92  | model.fc_outs.0.fc              | Linear              | 113    | [256, 112]                                | [256, 1]
93  | model.fc_outs.1                 | OutputLayer         | 226    | [256, 112]                                | [256, 2]
94  | model.fc_outs.1.fc              | Sequential          | 226    | [256, 112]                                | [256, 2]
95  | model.fc_outs.1.fc.0            | Linear              | 226    | [256, 112]                                | [256, 2]
96  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
97  | model.fc_outs.2                 | OutputLayer         | 226    | [256, 112]                                | [256, 2]
98  | model.fc_outs.2.fc              | Sequential          | 226    | [256, 112]                                | [256, 2]
99  | model.fc_outs.2.fc.0            | Linear              | 226    | [256, 112]                                | [256, 2]
100 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
101 | model.fc_outs.3                 | OutputLayer         | 452    | [256, 112]                                | [256, 4]
102 | model.fc_outs.3.fc              | Sequential          | 452    | [256, 112]                                | [256, 4]
103 | model.fc_outs.3.fc.0            | Linear              | 452    | [256, 112]                                | [256, 4]
104 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
105 | model.fc_outs.4                 | OutputLayer         | 226    | [256, 112]                                | [256, 2]
106 | model.fc_outs.4.fc              | Sequential          | 226    | [256, 112]                                | [256, 2]
107 | model.fc_outs.4.fc.0            | Linear              | 226    | [256, 112]                                | [256, 2]
108 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
109 | model.fc_outs.5                 | OutputLayer         | 226    | [256, 112]                                | [256, 2]
110 | model.fc_outs.5.fc              | Sequential          | 226    | [256, 112]                                | [256, 2]
111 | model.fc_outs.5.fc.0            | Linear              | 226    | [256, 112]                                | [256, 2]
112 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
113 | model.fc_outs.6                 | OutputLayer         | 226    | [256, 112]                                | [256, 2]
114 | model.fc_outs.6.fc              | Sequential          | 226    | [256, 112]                                | [256, 2]
115 | model.fc_outs.6.fc.0            | Linear              | 226    | [256, 112]                                | [256, 2]
116 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
117 | model.task_norms                | ModuleList          | 1.6 K  | ?                                         | ?
118 | model.task_norms.0              | LayerNorm           | 224    | [256, 112]                                | [256, 112]
119 | model.task_norms.1              | LayerNorm           | 224    | [256, 112]                                | [256, 112]
120 | model.task_norms.2              | LayerNorm           | 224    | [256, 112]                                | [256, 112]
121 | model.task_norms.3              | LayerNorm           | 224    | [256, 112]                                | [256, 112]
122 | model.task_norms.4              | LayerNorm           | 224    | [256, 112]                                | [256, 112]
123 | model.task_norms.5              | LayerNorm           | 224    | [256, 112]                                | [256, 112]
124 | model.task_norms.6              | LayerNorm           | 224    | [256, 112]                                | [256, 112]
125 | model.task_attentions           | ModuleList          | 265 K  | ?                                         | ?
126 | model.task_attentions.0         | SelfAttention       | 38.0 K | [256, 112]                                | [256, 112]
127 | model.task_attentions.0.query   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
128 | model.task_attentions.0.key     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
129 | model.task_attentions.0.value   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
130 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
131 | model.task_attentions.1         | SelfAttention       | 38.0 K | [256, 112]                                | [256, 112]
132 | model.task_attentions.1.query   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
133 | model.task_attentions.1.key     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
134 | model.task_attentions.1.value   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
135 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
136 | model.task_attentions.2         | SelfAttention       | 38.0 K | [256, 112]                                | [256, 112]
137 | model.task_attentions.2.query   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
138 | model.task_attentions.2.key     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
139 | model.task_attentions.2.value   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
140 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
141 | model.task_attentions.3         | SelfAttention       | 38.0 K | [256, 112]                                | [256, 112]
142 | model.task_attentions.3.query   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
143 | model.task_attentions.3.key     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
144 | model.task_attentions.3.value   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
145 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
146 | model.task_attentions.4         | SelfAttention       | 38.0 K | [256, 112]                                | [256, 112]
147 | model.task_attentions.4.query   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
148 | model.task_attentions.4.key     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
149 | model.task_attentions.4.value   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
150 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
151 | model.task_attentions.5         | SelfAttention       | 38.0 K | [256, 112]                                | [256, 112]
152 | model.task_attentions.5.query   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
153 | model.task_attentions.5.key     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
154 | model.task_attentions.5.value   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
155 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
156 | model.task_attentions.6         | SelfAttention       | 38.0 K | [256, 112]                                | [256, 112]
157 | model.task_attentions.6.query   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
158 | model.task_attentions.6.key     | Linear              | 12.7 K | [256, 112]                                | [256, 112]
159 | model.task_attentions.6.value   | Linear              | 12.7 K | [256, 112]                                | [256, 112]
160 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.4 M     Trainable params
0         Non-trainable params
2.4 M     Total params
9.767     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_19
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight', 'fcs.7.weight', 'fcs.8.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'fcs.7.bias', 'fcs.8.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'norms.7.weight', 'norms.7.bias', 'norms.8.weight', 'norms.8.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 7 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 2.4 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 112], [256, 112], [256, 112], [256, 112], [256, 112], [256, 112], [256, 112]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.4 M     Trainable params
0         Non-trainable params
2.4 M     Total params
9.767     Total estimated model params size (MB)
Using no sampler for validation data.
current_epoch(0): metric=0.0986 > best_metric=0.0000, log val results..
[W 2025-12-03 18:12:22,681] Trial 21 failed with parameters: {'atom_fea_len': 256, 'h_fea_len': 112, 'n_conv': 7, 'n_h': 10, 'lr_mult': 7, 'extra_fea_len': 60, 'dropout': 0.5} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 794.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 204.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.62 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 94, in forward
    nbr_filter = self.sigmoid(nbr_filter)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 329, in forward
    return torch.sigmoid(input)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 794.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 204.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.62 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 18:12:22,682] Trial 21 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 1
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 176
extra_fea_len : 32
h_fea_len : 16
n_conv : 9
n_h : 3
att_S : 64
dropout_prob : 0.45
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=256, bias=True)
  (embedding_atom_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-6): 7 x ConvLayer(
      (fc_full): Linear(in_features=553, out_features=512, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=60, bias=True)
  (embedding_extra_norm): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=316, out_features=112, bias=True)
  (conv_to_fc_norm): BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.5, inplace=False)
  (fcs): ModuleList(
    (0-8): 9 x Linear(in_features=112, out_features=112, bias=True)
  )
  (norms): ModuleList(
    (0-8): 9 x BatchNorm1d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-8): 9 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=112, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=112, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=112, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=112, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((112,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=112, out_features=112, bias=True)
      (key): Linear(in_features=112, out_features=112, bias=True)
      (value): Linear(in_features=112, out_features=112, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f927c0a30>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f927c04c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f927c0820>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f927c0280>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f927c0a60>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f927c07c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f927c0f10>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 1.3 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 16], [256, 16], [256, 16], [256, 16], [256, 16], [256, 16], [256, 16]]]
1   | model.embedding_atom            | Linear              | 16.4 K | [4608, 92]                                | [4608, 176]
2   | model.embedding_atom_norm       | LayerNorm           | 352    | [4608, 176]                               | [4608, 176]
3   | model.convs                     | ModuleList          | 1.3 M  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
5   | model.convs.0.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
8   | model.convs.0.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
9   | model.convs.0.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
11  | model.convs.1                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
12  | model.convs.1.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
15  | model.convs.1.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
16  | model.convs.1.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
18  | model.convs.2                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
19  | model.convs.2.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
22  | model.convs.2.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
23  | model.convs.2.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
25  | model.convs.3                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
26  | model.convs.3.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
29  | model.convs.3.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
30  | model.convs.3.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
32  | model.convs.4                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
33  | model.convs.4.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
36  | model.convs.4.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
37  | model.convs.4.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
39  | model.convs.5                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
40  | model.convs.5.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
43  | model.convs.5.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
44  | model.convs.5.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
46  | model.convs.6                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
47  | model.convs.6.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
50  | model.convs.6.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
51  | model.convs.6.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
53  | model.convs.7                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
54  | model.convs.7.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
57  | model.convs.7.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
58  | model.convs.7.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
60  | model.convs.8                   | ConvLayer           | 139 K  | [[4608, 176], [4608, 10, 41], [4608, 10]] | [4608, 176]
61  | model.convs.8.fc_full           | Linear              | 138 K  | [4608, 10, 393]                           | [4608, 10, 352]
62  | model.convs.8.sigmoid           | Sigmoid             | 0      | [4608, 10, 176]                           | [4608, 10, 176]
63  | model.convs.8.softplus1         | Softplus            | 0      | [4608, 10, 176]                           | [4608, 10, 176]
64  | model.convs.8.bn1               | BatchNorm1d         | 704    | [46080, 352]                              | [46080, 352]
65  | model.convs.8.bn2               | BatchNorm1d         | 352    | [4608, 176]                               | [4608, 176]
66  | model.convs.8.softplus2         | Softplus            | 0      | [4608, 176]                               | [4608, 176]
67  | model.embedding_extra           | Linear              | 224    | [256, 6]                                  | [256, 32]
68  | model.embedding_extra_norm      | BatchNorm1d         | 64     | [256, 32]                                 | [256, 32]
69  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 32]                                 | [256, 32]
70  | model.conv_to_fc                | Linear              | 3.3 K  | [256, 208]                                | [256, 16]
71  | model.conv_to_fc_norm           | BatchNorm1d         | 32     | [256, 16]                                 | [256, 16]
72  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 16]                                 | [256, 16]
73  | model.dropout                   | Dropout             | 0      | [256, 16]                                 | [256, 16]
74  | model.fcs                       | ModuleList          | 544    | ?                                         | ?
75  | model.fcs.0                     | Linear              | 272    | [256, 16]                                 | [256, 16]
76  | model.fcs.1                     | Linear              | 272    | [256, 16]                                 | [256, 16]
77  | model.norms                     | ModuleList          | 64     | ?                                         | ?
78  | model.norms.0                   | BatchNorm1d         | 32     | [256, 16]                                 | [256, 16]
79  | model.norms.1                   | BatchNorm1d         | 32     | [256, 16]                                 | [256, 16]
80  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
81  | model.softpluses.0              | Softplus            | 0      | [256, 16]                                 | [256, 16]
82  | model.softpluses.1              | Softplus            | 0      | [256, 16]                                 | [256, 16]
83  | model.fc_outs                   | ModuleList          | 255    | ?                                         | ?
84  | model.fc_outs.0                 | OutputLayer         | 17     | [256, 16]                                 | [256, 1]
85  | model.fc_outs.0.fc              | Linear              | 17     | [256, 16]                                 | [256, 1]
86  | model.fc_outs.1                 | OutputLayer         | 34     | [256, 16]                                 | [256, 2]
87  | model.fc_outs.1.fc              | Sequential          | 34     | [256, 16]                                 | [256, 2]
88  | model.fc_outs.1.fc.0            | Linear              | 34     | [256, 16]                                 | [256, 2]
89  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
90  | model.fc_outs.2                 | OutputLayer         | 34     | [256, 16]                                 | [256, 2]
91  | model.fc_outs.2.fc              | Sequential          | 34     | [256, 16]                                 | [256, 2]
92  | model.fc_outs.2.fc.0            | Linear              | 34     | [256, 16]                                 | [256, 2]
93  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
94  | model.fc_outs.3                 | OutputLayer         | 68     | [256, 16]                                 | [256, 4]
95  | model.fc_outs.3.fc              | Sequential          | 68     | [256, 16]                                 | [256, 4]
96  | model.fc_outs.3.fc.0            | Linear              | 68     | [256, 16]                                 | [256, 4]
97  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
98  | model.fc_outs.4                 | OutputLayer         | 34     | [256, 16]                                 | [256, 2]
99  | model.fc_outs.4.fc              | Sequential          | 34     | [256, 16]                                 | [256, 2]
100 | model.fc_outs.4.fc.0            | Linear              | 34     | [256, 16]                                 | [256, 2]
101 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
102 | model.fc_outs.5                 | OutputLayer         | 34     | [256, 16]                                 | [256, 2]
103 | model.fc_outs.5.fc              | Sequential          | 34     | [256, 16]                                 | [256, 2]
104 | model.fc_outs.5.fc.0            | Linear              | 34     | [256, 16]                                 | [256, 2]
105 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
106 | model.fc_outs.6                 | OutputLayer         | 34     | [256, 16]                                 | [256, 2]
107 | model.fc_outs.6.fc              | Sequential          | 34     | [256, 16]                                 | [256, 2]
108 | model.fc_outs.6.fc.0            | Linear              | 34     | [256, 16]                                 | [256, 2]
109 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
110 | model.task_norms                | ModuleList          | 224    | ?                                         | ?
111 | model.task_norms.0              | LayerNorm           | 32     | [256, 16]                                 | [256, 16]
112 | model.task_norms.1              | LayerNorm           | 32     | [256, 16]                                 | [256, 16]
113 | model.task_norms.2              | LayerNorm           | 32     | [256, 16]                                 | [256, 16]
114 | model.task_norms.3              | LayerNorm           | 32     | [256, 16]                                 | [256, 16]
115 | model.task_norms.4              | LayerNorm           | 32     | [256, 16]                                 | [256, 16]
116 | model.task_norms.5              | LayerNorm           | 32     | [256, 16]                                 | [256, 16]
117 | model.task_norms.6              | LayerNorm           | 32     | [256, 16]                                 | [256, 16]
118 | model.task_attentions           | ModuleList          | 5.7 K  | ?                                         | ?
119 | model.task_attentions.0         | SelfAttention       | 816    | [256, 16]                                 | [256, 16]
120 | model.task_attentions.0.query   | Linear              | 272    | [256, 16]                                 | [256, 16]
121 | model.task_attentions.0.key     | Linear              | 272    | [256, 16]                                 | [256, 16]
122 | model.task_attentions.0.value   | Linear              | 272    | [256, 16]                                 | [256, 16]
123 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
124 | model.task_attentions.1         | SelfAttention       | 816    | [256, 16]                                 | [256, 16]
125 | model.task_attentions.1.query   | Linear              | 272    | [256, 16]                                 | [256, 16]
126 | model.task_attentions.1.key     | Linear              | 272    | [256, 16]                                 | [256, 16]
127 | model.task_attentions.1.value   | Linear              | 272    | [256, 16]                                 | [256, 16]
128 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
129 | model.task_attentions.2         | SelfAttention       | 816    | [256, 16]                                 | [256, 16]
130 | model.task_attentions.2.query   | Linear              | 272    | [256, 16]                                 | [256, 16]
131 | model.task_attentions.2.key     | Linear              | 272    | [256, 16]                                 | [256, 16]
132 | model.task_attentions.2.value   | Linear              | 272    | [256, 16]                                 | [256, 16]
133 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
134 | model.task_attentions.3         | SelfAttention       | 816    | [256, 16]                                 | [256, 16]
135 | model.task_attentions.3.query   | Linear              | 272    | [256, 16]                                 | [256, 16]
136 | model.task_attentions.3.key     | Linear              | 272    | [256, 16]                                 | [256, 16]
137 | model.task_attentions.3.value   | Linear              | 272    | [256, 16]                                 | [256, 16]
138 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
139 | model.task_attentions.4         | SelfAttention       | 816    | [256, 16]                                 | [256, 16]
140 | model.task_attentions.4.query   | Linear              | 272    | [256, 16]                                 | [256, 16]
141 | model.task_attentions.4.key     | Linear              | 272    | [256, 16]                                 | [256, 16]
142 | model.task_attentions.4.value   | Linear              | 272    | [256, 16]                                 | [256, 16]
143 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
144 | model.task_attentions.5         | SelfAttention       | 816    | [256, 16]                                 | [256, 16]
145 | model.task_attentions.5.query   | Linear              | 272    | [256, 16]                                 | [256, 16]
146 | model.task_attentions.5.key     | Linear              | 272    | [256, 16]                                 | [256, 16]
147 | model.task_attentions.5.value   | Linear              | 272    | [256, 16]                                 | [256, 16]
148 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
149 | model.task_attentions.6         | SelfAttention       | 816    | [256, 16]                                 | [256, 16]
150 | model.task_attentions.6.query   | Linear              | 272    | [256, 16]                                 | [256, 16]
151 | model.task_attentions.6.key     | Linear              | 272    | [256, 16]                                 | [256, 16]
152 | model.task_attentions.6.value   | Linear              | 272    | [256, 16]                                 | [256, 16]
153 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.3 M     Trainable params
0         Non-trainable params
1.3 M     Total params
5.140     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_20
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'convs.8.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'convs.8.fc_full.bias', 'convs.8.bn1.weight', 'convs.8.bn1.bias', 'convs.8.bn2.weight', 'convs.8.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 1 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 1.3 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 16], [256, 16], [256, 16], [256, 16], [256, 16], [256, 16], [256, 16]]]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
1.3 M     Trainable params
0         Non-trainable params
1.3 M     Total params
5.140     Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 18:12:34,633] Trial 22 failed with parameters: {'atom_fea_len': 176, 'h_fea_len': 16, 'n_conv': 9, 'n_h': 3, 'lr_mult': 1, 'extra_fea_len': 32, 'dropout': 0.45} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 584.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 132.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 19.99 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 96, in forward
    nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 584.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 132.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.70 GiB memory in use. Of the allocated memory 19.99 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 18:12:34,634] Trial 22 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 2
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 256
extra_fea_len : 4
h_fea_len : 96
n_conv : 6
n_h : 10
att_S : 64
dropout_prob : 0.8
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=176, bias=True)
  (embedding_atom_norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-8): 9 x ConvLayer(
      (fc_full): Linear(in_features=393, out_features=352, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=32, bias=True)
  (embedding_extra_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=208, out_features=16, bias=True)
  (conv_to_fc_norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.45, inplace=False)
  (fcs): ModuleList(
    (0-1): 2 x Linear(in_features=16, out_features=16, bias=True)
  )
  (norms): ModuleList(
    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-1): 2 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=16, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=16, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=16, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=16, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((16,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=16, out_features=16, bias=True)
      (key): Linear(in_features=16, out_features=16, bias=True)
      (value): Linear(in_features=16, out_features=16, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f884751f0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f89144340>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f891448e0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f89144a60>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f891445b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f89144c40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f89144520>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 2.0 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96]]]
1   | model.embedding_atom            | Linear              | 23.8 K | [4608, 92]                                | [4608, 256]
2   | model.embedding_atom_norm       | LayerNorm           | 512    | [4608, 256]                               | [4608, 256]
3   | model.convs                     | ModuleList          | 1.7 M  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
5   | model.convs.0.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
8   | model.convs.0.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
9   | model.convs.0.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
11  | model.convs.1                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
12  | model.convs.1.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
15  | model.convs.1.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
16  | model.convs.1.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
18  | model.convs.2                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
19  | model.convs.2.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
22  | model.convs.2.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
23  | model.convs.2.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
25  | model.convs.3                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
26  | model.convs.3.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
29  | model.convs.3.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
30  | model.convs.3.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
32  | model.convs.4                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
33  | model.convs.4.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
36  | model.convs.4.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
37  | model.convs.4.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
39  | model.convs.5                   | ConvLayer           | 285 K  | [[4608, 256], [4608, 10, 41], [4608, 10]] | [4608, 256]
40  | model.convs.5.fc_full           | Linear              | 283 K  | [4608, 10, 553]                           | [4608, 10, 512]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 256]                           | [4608, 10, 256]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 256]                           | [4608, 10, 256]
43  | model.convs.5.bn1               | BatchNorm1d         | 1.0 K  | [46080, 512]                              | [46080, 512]
44  | model.convs.5.bn2               | BatchNorm1d         | 512    | [4608, 256]                               | [4608, 256]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 256]                               | [4608, 256]
46  | model.embedding_extra           | Linear              | 28     | [256, 6]                                  | [256, 4]
47  | model.embedding_extra_norm      | BatchNorm1d         | 8      | [256, 4]                                  | [256, 4]
48  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 4]                                  | [256, 4]
49  | model.conv_to_fc                | Linear              | 25.1 K | [256, 260]                                | [256, 96]
50  | model.conv_to_fc_norm           | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
51  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 96]                                 | [256, 96]
52  | model.dropout                   | Dropout             | 0      | [256, 96]                                 | [256, 96]
53  | model.fcs                       | ModuleList          | 83.8 K | ?                                         | ?
54  | model.fcs.0                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
55  | model.fcs.1                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
56  | model.fcs.2                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
57  | model.fcs.3                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
58  | model.fcs.4                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
59  | model.fcs.5                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
60  | model.fcs.6                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
61  | model.fcs.7                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
62  | model.fcs.8                     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
63  | model.norms                     | ModuleList          | 1.7 K  | ?                                         | ?
64  | model.norms.0                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
65  | model.norms.1                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
66  | model.norms.2                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
67  | model.norms.3                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
68  | model.norms.4                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
69  | model.norms.5                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
70  | model.norms.6                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
71  | model.norms.7                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
72  | model.norms.8                   | BatchNorm1d         | 192    | [256, 96]                                 | [256, 96]
73  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
74  | model.softpluses.0              | Softplus            | 0      | [256, 96]                                 | [256, 96]
75  | model.softpluses.1              | Softplus            | 0      | [256, 96]                                 | [256, 96]
76  | model.softpluses.2              | Softplus            | 0      | [256, 96]                                 | [256, 96]
77  | model.softpluses.3              | Softplus            | 0      | [256, 96]                                 | [256, 96]
78  | model.softpluses.4              | Softplus            | 0      | [256, 96]                                 | [256, 96]
79  | model.softpluses.5              | Softplus            | 0      | [256, 96]                                 | [256, 96]
80  | model.softpluses.6              | Softplus            | 0      | [256, 96]                                 | [256, 96]
81  | model.softpluses.7              | Softplus            | 0      | [256, 96]                                 | [256, 96]
82  | model.softpluses.8              | Softplus            | 0      | [256, 96]                                 | [256, 96]
83  | model.fc_outs                   | ModuleList          | 1.5 K  | ?                                         | ?
84  | model.fc_outs.0                 | OutputLayer         | 97     | [256, 96]                                 | [256, 1]
85  | model.fc_outs.0.fc              | Linear              | 97     | [256, 96]                                 | [256, 1]
86  | model.fc_outs.1                 | OutputLayer         | 194    | [256, 96]                                 | [256, 2]
87  | model.fc_outs.1.fc              | Sequential          | 194    | [256, 96]                                 | [256, 2]
88  | model.fc_outs.1.fc.0            | Linear              | 194    | [256, 96]                                 | [256, 2]
89  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
90  | model.fc_outs.2                 | OutputLayer         | 194    | [256, 96]                                 | [256, 2]
91  | model.fc_outs.2.fc              | Sequential          | 194    | [256, 96]                                 | [256, 2]
92  | model.fc_outs.2.fc.0            | Linear              | 194    | [256, 96]                                 | [256, 2]
93  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
94  | model.fc_outs.3                 | OutputLayer         | 388    | [256, 96]                                 | [256, 4]
95  | model.fc_outs.3.fc              | Sequential          | 388    | [256, 96]                                 | [256, 4]
96  | model.fc_outs.3.fc.0            | Linear              | 388    | [256, 96]                                 | [256, 4]
97  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
98  | model.fc_outs.4                 | OutputLayer         | 194    | [256, 96]                                 | [256, 2]
99  | model.fc_outs.4.fc              | Sequential          | 194    | [256, 96]                                 | [256, 2]
100 | model.fc_outs.4.fc.0            | Linear              | 194    | [256, 96]                                 | [256, 2]
101 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
102 | model.fc_outs.5                 | OutputLayer         | 194    | [256, 96]                                 | [256, 2]
103 | model.fc_outs.5.fc              | Sequential          | 194    | [256, 96]                                 | [256, 2]
104 | model.fc_outs.5.fc.0            | Linear              | 194    | [256, 96]                                 | [256, 2]
105 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
106 | model.fc_outs.6                 | OutputLayer         | 194    | [256, 96]                                 | [256, 2]
107 | model.fc_outs.6.fc              | Sequential          | 194    | [256, 96]                                 | [256, 2]
108 | model.fc_outs.6.fc.0            | Linear              | 194    | [256, 96]                                 | [256, 2]
109 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
110 | model.task_norms                | ModuleList          | 1.3 K  | ?                                         | ?
111 | model.task_norms.0              | LayerNorm           | 192    | [256, 96]                                 | [256, 96]
112 | model.task_norms.1              | LayerNorm           | 192    | [256, 96]                                 | [256, 96]
113 | model.task_norms.2              | LayerNorm           | 192    | [256, 96]                                 | [256, 96]
114 | model.task_norms.3              | LayerNorm           | 192    | [256, 96]                                 | [256, 96]
115 | model.task_norms.4              | LayerNorm           | 192    | [256, 96]                                 | [256, 96]
116 | model.task_norms.5              | LayerNorm           | 192    | [256, 96]                                 | [256, 96]
117 | model.task_norms.6              | LayerNorm           | 192    | [256, 96]                                 | [256, 96]
118 | model.task_attentions           | ModuleList          | 195 K  | ?                                         | ?
119 | model.task_attentions.0         | SelfAttention       | 27.9 K | [256, 96]                                 | [256, 96]
120 | model.task_attentions.0.query   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
121 | model.task_attentions.0.key     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
122 | model.task_attentions.0.value   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
123 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
124 | model.task_attentions.1         | SelfAttention       | 27.9 K | [256, 96]                                 | [256, 96]
125 | model.task_attentions.1.query   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
126 | model.task_attentions.1.key     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
127 | model.task_attentions.1.value   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
128 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
129 | model.task_attentions.2         | SelfAttention       | 27.9 K | [256, 96]                                 | [256, 96]
130 | model.task_attentions.2.query   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
131 | model.task_attentions.2.key     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
132 | model.task_attentions.2.value   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
133 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
134 | model.task_attentions.3         | SelfAttention       | 27.9 K | [256, 96]                                 | [256, 96]
135 | model.task_attentions.3.query   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
136 | model.task_attentions.3.key     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
137 | model.task_attentions.3.value   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
138 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
139 | model.task_attentions.4         | SelfAttention       | 27.9 K | [256, 96]                                 | [256, 96]
140 | model.task_attentions.4.query   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
141 | model.task_attentions.4.key     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
142 | model.task_attentions.4.value   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
143 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
144 | model.task_attentions.5         | SelfAttention       | 27.9 K | [256, 96]                                 | [256, 96]
145 | model.task_attentions.5.query   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
146 | model.task_attentions.5.key     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
147 | model.task_attentions.5.value   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
148 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
149 | model.task_attentions.6         | SelfAttention       | 27.9 K | [256, 96]                                 | [256, 96]
150 | model.task_attentions.6.query   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
151 | model.task_attentions.6.key     | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
152 | model.task_attentions.6.value   | Linear              | 9.3 K  | [256, 96]                                 | [256, 96]
153 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.178     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_21
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight', 'fcs.7.weight', 'fcs.8.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'fcs.7.bias', 'fcs.8.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'norms.7.weight', 'norms.7.bias', 'norms.8.weight', 'norms.8.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 2 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 2.0 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96], [256, 96]]]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.178     Total estimated model params size (MB)
Using no sampler for validation data.
current_epoch(0): metric=0.0581 > best_metric=0.0000, log val results..
[W 2025-12-03 18:12:48,995] Trial 23 failed with parameters: {'atom_fea_len': 256, 'h_fea_len': 96, 'n_conv': 6, 'n_h': 10, 'lr_mult': 2, 'extra_fea_len': 4, 'dropout': 0.8} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 22.03 GiB of which 1.15 GiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.67 GiB memory in use. Of the allocated memory 18.05 GiB is allocated by PyTorch, and 2.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 91, in forward
    total_gated_fea = self.bn1(total_gated_fea.view(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py", line 2817, in batch_norm
    return torch.batch_norm(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 22.03 GiB of which 1.15 GiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 20.67 GiB memory in use. Of the allocated memory 18.05 GiB is allocated by PyTorch, and 2.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 18:12:49,002] Trial 23 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 8
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 240
extra_fea_len : 28
h_fea_len : 192
n_conv : 8
n_h : 10
att_S : 64
dropout_prob : 0.0
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=256, bias=True)
  (embedding_atom_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-5): 6 x ConvLayer(
      (fc_full): Linear(in_features=553, out_features=512, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=4, bias=True)
  (embedding_extra_norm): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=260, out_features=96, bias=True)
  (conv_to_fc_norm): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.8, inplace=False)
  (fcs): ModuleList(
    (0-8): 9 x Linear(in_features=96, out_features=96, bias=True)
  )
  (norms): ModuleList(
    (0-8): 9 x BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-8): 9 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=96, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=96, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=96, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=96, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=96, out_features=96, bias=True)
      (key): Linear(in_features=96, out_features=96, bias=True)
      (value): Linear(in_features=96, out_features=96, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa0646f70>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa0646670>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa0646ee0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa0646c40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa0646460>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa0646580>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8fa0646790>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 3.2 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192]]]
1   | model.embedding_atom            | Linear              | 22.3 K | [4608, 92]                                | [4608, 240]
2   | model.embedding_atom_norm       | LayerNorm           | 480    | [4608, 240]                               | [4608, 240]
3   | model.convs                     | ModuleList          | 2.0 M  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
5   | model.convs.0.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
8   | model.convs.0.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
9   | model.convs.0.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
11  | model.convs.1                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
12  | model.convs.1.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
15  | model.convs.1.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
16  | model.convs.1.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
18  | model.convs.2                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
19  | model.convs.2.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
22  | model.convs.2.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
23  | model.convs.2.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
25  | model.convs.3                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
26  | model.convs.3.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
29  | model.convs.3.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
30  | model.convs.3.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
32  | model.convs.4                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
33  | model.convs.4.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
36  | model.convs.4.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
37  | model.convs.4.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
39  | model.convs.5                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
40  | model.convs.5.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
43  | model.convs.5.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
44  | model.convs.5.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
46  | model.convs.6                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
47  | model.convs.6.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
50  | model.convs.6.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
51  | model.convs.6.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
53  | model.convs.7                   | ConvLayer           | 252 K  | [[4608, 240], [4608, 10, 41], [4608, 10]] | [4608, 240]
54  | model.convs.7.fc_full           | Linear              | 250 K  | [4608, 10, 521]                           | [4608, 10, 480]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 240]                           | [4608, 10, 240]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 240]                           | [4608, 10, 240]
57  | model.convs.7.bn1               | BatchNorm1d         | 960    | [46080, 480]                              | [46080, 480]
58  | model.convs.7.bn2               | BatchNorm1d         | 480    | [4608, 240]                               | [4608, 240]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 240]                               | [4608, 240]
60  | model.embedding_extra           | Linear              | 196    | [256, 6]                                  | [256, 28]
61  | model.embedding_extra_norm      | BatchNorm1d         | 56     | [256, 28]                                 | [256, 28]
62  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 28]                                 | [256, 28]
63  | model.conv_to_fc                | Linear              | 51.6 K | [256, 268]                                | [256, 192]
64  | model.conv_to_fc_norm           | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
65  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 192]                                | [256, 192]
66  | model.dropout                   | Dropout             | 0      | [256, 192]                                | [256, 192]
67  | model.fcs                       | ModuleList          | 333 K  | ?                                         | ?
68  | model.fcs.0                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
69  | model.fcs.1                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
70  | model.fcs.2                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
71  | model.fcs.3                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
72  | model.fcs.4                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
73  | model.fcs.5                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
74  | model.fcs.6                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
75  | model.fcs.7                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
76  | model.fcs.8                     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
77  | model.norms                     | ModuleList          | 3.5 K  | ?                                         | ?
78  | model.norms.0                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
79  | model.norms.1                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
80  | model.norms.2                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
81  | model.norms.3                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
82  | model.norms.4                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
83  | model.norms.5                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
84  | model.norms.6                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
85  | model.norms.7                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
86  | model.norms.8                   | BatchNorm1d         | 384    | [256, 192]                                | [256, 192]
87  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
88  | model.softpluses.0              | Softplus            | 0      | [256, 192]                                | [256, 192]
89  | model.softpluses.1              | Softplus            | 0      | [256, 192]                                | [256, 192]
90  | model.softpluses.2              | Softplus            | 0      | [256, 192]                                | [256, 192]
91  | model.softpluses.3              | Softplus            | 0      | [256, 192]                                | [256, 192]
92  | model.softpluses.4              | Softplus            | 0      | [256, 192]                                | [256, 192]
93  | model.softpluses.5              | Softplus            | 0      | [256, 192]                                | [256, 192]
94  | model.softpluses.6              | Softplus            | 0      | [256, 192]                                | [256, 192]
95  | model.softpluses.7              | Softplus            | 0      | [256, 192]                                | [256, 192]
96  | model.softpluses.8              | Softplus            | 0      | [256, 192]                                | [256, 192]
97  | model.fc_outs                   | ModuleList          | 2.9 K  | ?                                         | ?
98  | model.fc_outs.0                 | OutputLayer         | 193    | [256, 192]                                | [256, 1]
99  | model.fc_outs.0.fc              | Linear              | 193    | [256, 192]                                | [256, 1]
100 | model.fc_outs.1                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
101 | model.fc_outs.1.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
102 | model.fc_outs.1.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
103 | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
104 | model.fc_outs.2                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
105 | model.fc_outs.2.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
106 | model.fc_outs.2.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
107 | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
108 | model.fc_outs.3                 | OutputLayer         | 772    | [256, 192]                                | [256, 4]
109 | model.fc_outs.3.fc              | Sequential          | 772    | [256, 192]                                | [256, 4]
110 | model.fc_outs.3.fc.0            | Linear              | 772    | [256, 192]                                | [256, 4]
111 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
112 | model.fc_outs.4                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
113 | model.fc_outs.4.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
114 | model.fc_outs.4.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
115 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
116 | model.fc_outs.5                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
117 | model.fc_outs.5.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
118 | model.fc_outs.5.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
119 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
120 | model.fc_outs.6                 | OutputLayer         | 386    | [256, 192]                                | [256, 2]
121 | model.fc_outs.6.fc              | Sequential          | 386    | [256, 192]                                | [256, 2]
122 | model.fc_outs.6.fc.0            | Linear              | 386    | [256, 192]                                | [256, 2]
123 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
124 | model.task_norms                | ModuleList          | 2.7 K  | ?                                         | ?
125 | model.task_norms.0              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
126 | model.task_norms.1              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
127 | model.task_norms.2              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
128 | model.task_norms.3              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
129 | model.task_norms.4              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
130 | model.task_norms.5              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
131 | model.task_norms.6              | LayerNorm           | 384    | [256, 192]                                | [256, 192]
132 | model.task_attentions           | ModuleList          | 778 K  | ?                                         | ?
133 | model.task_attentions.0         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
134 | model.task_attentions.0.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
135 | model.task_attentions.0.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
136 | model.task_attentions.0.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
137 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
138 | model.task_attentions.1         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
139 | model.task_attentions.1.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
140 | model.task_attentions.1.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
141 | model.task_attentions.1.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
142 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
143 | model.task_attentions.2         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
144 | model.task_attentions.2.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
145 | model.task_attentions.2.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
146 | model.task_attentions.2.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
147 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
148 | model.task_attentions.3         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
149 | model.task_attentions.3.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
150 | model.task_attentions.3.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
151 | model.task_attentions.3.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
152 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
153 | model.task_attentions.4         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
154 | model.task_attentions.4.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
155 | model.task_attentions.4.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
156 | model.task_attentions.4.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
157 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
158 | model.task_attentions.5         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
159 | model.task_attentions.5.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
160 | model.task_attentions.5.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
161 | model.task_attentions.5.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
162 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
163 | model.task_attentions.6         | SelfAttention       | 111 K  | [256, 192]                                | [256, 192]
164 | model.task_attentions.6.query   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
165 | model.task_attentions.6.key     | Linear              | 37.1 K | [256, 192]                                | [256, 192]
166 | model.task_attentions.6.value   | Linear              | 37.1 K | [256, 192]                                | [256, 192]
167 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3.2 M     Trainable params
0         Non-trainable params
3.2 M     Total params
12.847    Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_22
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight', 'fcs.5.weight', 'fcs.6.weight', 'fcs.7.weight', 'fcs.8.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'fcs.5.bias', 'fcs.6.bias', 'fcs.7.bias', 'fcs.8.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'norms.5.weight', 'norms.5.bias', 'norms.6.weight', 'norms.6.bias', 'norms.7.weight', 'norms.7.bias', 'norms.8.weight', 'norms.8.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 8 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 3.2 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192], [256, 192]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
3.2 M     Trainable params
0         Non-trainable params
3.2 M     Total params
12.847    Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 18:13:01,612] Trial 24 failed with parameters: {'atom_fea_len': 240, 'h_fea_len': 192, 'n_conv': 8, 'n_h': 10, 'lr_mult': 8, 'extra_fea_len': 28, 'dropout': 0.0} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 770.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 266.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.56 GiB memory in use. Of the allocated memory 19.07 GiB is allocated by PyTorch, and 2.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 95, in forward
    nbr_core = self.softplus1(nbr_core)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 901, in forward
    return F.softplus(input, self.beta, self.threshold)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 266.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.56 GiB memory in use. Of the allocated memory 19.07 GiB is allocated by PyTorch, and 2.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 18:13:01,613] Trial 24 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 11
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 144
extra_fea_len : 40
h_fea_len : 272
n_conv : 9
n_h : 4
att_S : 64
dropout_prob : 0.4
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=240, bias=True)
  (embedding_atom_norm): LayerNorm((240,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-7): 8 x ConvLayer(
      (fc_full): Linear(in_features=521, out_features=480, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=28, bias=True)
  (embedding_extra_norm): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=268, out_features=192, bias=True)
  (conv_to_fc_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.0, inplace=False)
  (fcs): ModuleList(
    (0-8): 9 x Linear(in_features=192, out_features=192, bias=True)
  )
  (norms): ModuleList(
    (0-8): 9 x BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-8): 9 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=192, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=192, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=192, out_features=192, bias=True)
      (key): Linear(in_features=192, out_features=192, bias=True)
      (value): Linear(in_features=192, out_features=192, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92450c40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92450af0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92450070>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92450280>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f92450580>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f924504c0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f924507f0>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 2.7 M  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 272], [256, 272], [256, 272], [256, 272], [256, 272], [256, 272], [256, 272]]]
1   | model.embedding_atom            | Linear              | 13.4 K | [4608, 92]                                | [4608, 144]
2   | model.embedding_atom_norm       | LayerNorm           | 288    | [4608, 144]                               | [4608, 144]
3   | model.convs                     | ModuleList          | 863 K  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
5   | model.convs.0.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
8   | model.convs.0.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
9   | model.convs.0.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
11  | model.convs.1                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
12  | model.convs.1.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
15  | model.convs.1.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
16  | model.convs.1.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
18  | model.convs.2                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
19  | model.convs.2.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
22  | model.convs.2.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
23  | model.convs.2.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
25  | model.convs.3                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
26  | model.convs.3.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
29  | model.convs.3.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
30  | model.convs.3.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
32  | model.convs.4                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
33  | model.convs.4.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
36  | model.convs.4.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
37  | model.convs.4.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
39  | model.convs.5                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
40  | model.convs.5.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
43  | model.convs.5.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
44  | model.convs.5.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
46  | model.convs.6                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
47  | model.convs.6.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
50  | model.convs.6.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
51  | model.convs.6.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
53  | model.convs.7                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
54  | model.convs.7.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
57  | model.convs.7.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
58  | model.convs.7.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
60  | model.convs.8                   | ConvLayer           | 95.9 K | [[4608, 144], [4608, 10, 41], [4608, 10]] | [4608, 144]
61  | model.convs.8.fc_full           | Linear              | 95.0 K | [4608, 10, 329]                           | [4608, 10, 288]
62  | model.convs.8.sigmoid           | Sigmoid             | 0      | [4608, 10, 144]                           | [4608, 10, 144]
63  | model.convs.8.softplus1         | Softplus            | 0      | [4608, 10, 144]                           | [4608, 10, 144]
64  | model.convs.8.bn1               | BatchNorm1d         | 576    | [46080, 288]                              | [46080, 288]
65  | model.convs.8.bn2               | BatchNorm1d         | 288    | [4608, 144]                               | [4608, 144]
66  | model.convs.8.softplus2         | Softplus            | 0      | [4608, 144]                               | [4608, 144]
67  | model.embedding_extra           | Linear              | 280    | [256, 6]                                  | [256, 40]
68  | model.embedding_extra_norm      | BatchNorm1d         | 80     | [256, 40]                                 | [256, 40]
69  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 40]                                 | [256, 40]
70  | model.conv_to_fc                | Linear              | 50.3 K | [256, 184]                                | [256, 272]
71  | model.conv_to_fc_norm           | BatchNorm1d         | 544    | [256, 272]                                | [256, 272]
72  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 272]                                | [256, 272]
73  | model.dropout                   | Dropout             | 0      | [256, 272]                                | [256, 272]
74  | model.fcs                       | ModuleList          | 222 K  | ?                                         | ?
75  | model.fcs.0                     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
76  | model.fcs.1                     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
77  | model.fcs.2                     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
78  | model.norms                     | ModuleList          | 1.6 K  | ?                                         | ?
79  | model.norms.0                   | BatchNorm1d         | 544    | [256, 272]                                | [256, 272]
80  | model.norms.1                   | BatchNorm1d         | 544    | [256, 272]                                | [256, 272]
81  | model.norms.2                   | BatchNorm1d         | 544    | [256, 272]                                | [256, 272]
82  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
83  | model.softpluses.0              | Softplus            | 0      | [256, 272]                                | [256, 272]
84  | model.softpluses.1              | Softplus            | 0      | [256, 272]                                | [256, 272]
85  | model.softpluses.2              | Softplus            | 0      | [256, 272]                                | [256, 272]
86  | model.fc_outs                   | ModuleList          | 4.1 K  | ?                                         | ?
87  | model.fc_outs.0                 | OutputLayer         | 273    | [256, 272]                                | [256, 1]
88  | model.fc_outs.0.fc              | Linear              | 273    | [256, 272]                                | [256, 1]
89  | model.fc_outs.1                 | OutputLayer         | 546    | [256, 272]                                | [256, 2]
90  | model.fc_outs.1.fc              | Sequential          | 546    | [256, 272]                                | [256, 2]
91  | model.fc_outs.1.fc.0            | Linear              | 546    | [256, 272]                                | [256, 2]
92  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
93  | model.fc_outs.2                 | OutputLayer         | 546    | [256, 272]                                | [256, 2]
94  | model.fc_outs.2.fc              | Sequential          | 546    | [256, 272]                                | [256, 2]
95  | model.fc_outs.2.fc.0            | Linear              | 546    | [256, 272]                                | [256, 2]
96  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
97  | model.fc_outs.3                 | OutputLayer         | 1.1 K  | [256, 272]                                | [256, 4]
98  | model.fc_outs.3.fc              | Sequential          | 1.1 K  | [256, 272]                                | [256, 4]
99  | model.fc_outs.3.fc.0            | Linear              | 1.1 K  | [256, 272]                                | [256, 4]
100 | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
101 | model.fc_outs.4                 | OutputLayer         | 546    | [256, 272]                                | [256, 2]
102 | model.fc_outs.4.fc              | Sequential          | 546    | [256, 272]                                | [256, 2]
103 | model.fc_outs.4.fc.0            | Linear              | 546    | [256, 272]                                | [256, 2]
104 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
105 | model.fc_outs.5                 | OutputLayer         | 546    | [256, 272]                                | [256, 2]
106 | model.fc_outs.5.fc              | Sequential          | 546    | [256, 272]                                | [256, 2]
107 | model.fc_outs.5.fc.0            | Linear              | 546    | [256, 272]                                | [256, 2]
108 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
109 | model.fc_outs.6                 | OutputLayer         | 546    | [256, 272]                                | [256, 2]
110 | model.fc_outs.6.fc              | Sequential          | 546    | [256, 272]                                | [256, 2]
111 | model.fc_outs.6.fc.0            | Linear              | 546    | [256, 272]                                | [256, 2]
112 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
113 | model.task_norms                | ModuleList          | 3.8 K  | ?                                         | ?
114 | model.task_norms.0              | LayerNorm           | 544    | [256, 272]                                | [256, 272]
115 | model.task_norms.1              | LayerNorm           | 544    | [256, 272]                                | [256, 272]
116 | model.task_norms.2              | LayerNorm           | 544    | [256, 272]                                | [256, 272]
117 | model.task_norms.3              | LayerNorm           | 544    | [256, 272]                                | [256, 272]
118 | model.task_norms.4              | LayerNorm           | 544    | [256, 272]                                | [256, 272]
119 | model.task_norms.5              | LayerNorm           | 544    | [256, 272]                                | [256, 272]
120 | model.task_norms.6              | LayerNorm           | 544    | [256, 272]                                | [256, 272]
121 | model.task_attentions           | ModuleList          | 1.6 M  | ?                                         | ?
122 | model.task_attentions.0         | SelfAttention       | 222 K  | [256, 272]                                | [256, 272]
123 | model.task_attentions.0.query   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
124 | model.task_attentions.0.key     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
125 | model.task_attentions.0.value   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
126 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
127 | model.task_attentions.1         | SelfAttention       | 222 K  | [256, 272]                                | [256, 272]
128 | model.task_attentions.1.query   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
129 | model.task_attentions.1.key     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
130 | model.task_attentions.1.value   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
131 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
132 | model.task_attentions.2         | SelfAttention       | 222 K  | [256, 272]                                | [256, 272]
133 | model.task_attentions.2.query   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
134 | model.task_attentions.2.key     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
135 | model.task_attentions.2.value   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
136 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
137 | model.task_attentions.3         | SelfAttention       | 222 K  | [256, 272]                                | [256, 272]
138 | model.task_attentions.3.query   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
139 | model.task_attentions.3.key     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
140 | model.task_attentions.3.value   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
141 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
142 | model.task_attentions.4         | SelfAttention       | 222 K  | [256, 272]                                | [256, 272]
143 | model.task_attentions.4.query   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
144 | model.task_attentions.4.key     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
145 | model.task_attentions.4.value   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
146 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
147 | model.task_attentions.5         | SelfAttention       | 222 K  | [256, 272]                                | [256, 272]
148 | model.task_attentions.5.query   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
149 | model.task_attentions.5.key     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
150 | model.task_attentions.5.value   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
151 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
152 | model.task_attentions.6         | SelfAttention       | 222 K  | [256, 272]                                | [256, 272]
153 | model.task_attentions.6.query   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
154 | model.task_attentions.6.key     | Linear              | 74.3 K | [256, 272]                                | [256, 272]
155 | model.task_attentions.6.value   | Linear              | 74.3 K | [256, 272]                                | [256, 272]
156 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.7 M     Trainable params
0         Non-trainable params
2.7 M     Total params
10.879    Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_23
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'convs.8.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'convs.8.fc_full.bias', 'convs.8.bn1.weight', 'convs.8.bn1.bias', 'convs.8.bn2.weight', 'convs.8.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 11 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 2.7 M  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 272], [256, 272], [256, 272], [256, 272], [256, 272], [256, 272], [256, 272]]]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
2.7 M     Trainable params
0         Non-trainable params
2.7 M     Total params
10.879    Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 18:13:13,781] Trial 25 failed with parameters: {'atom_fea_len': 144, 'h_fea_len': 272, 'n_conv': 9, 'n_h': 4, 'lr_mult': 11, 'extra_fea_len': 40, 'dropout': 0.4} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 1.09 GiB. GPU 0 has a total capacity of 22.03 GiB of which 354.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.48 GiB memory in use. Of the allocated memory 20.51 GiB is allocated by PyTorch, and 757.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 90, in forward
    total_gated_fea = self.fc_full(total_nbr_fea)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.09 GiB. GPU 0 has a total capacity of 22.03 GiB of which 354.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.48 GiB memory in use. Of the allocated memory 20.51 GiB is allocated by PyTorch, and 757.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 18:13:13,782] Trial 25 failed with value None.
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [16, 300] and step=16, but the range is not divisible by `step`. It will be replaced with [16, 288].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:684: UserWarning: The distribution is specified by [4, 65] and step=4, but the range is not divisible by `step`. It will be replaced with [4, 64].
  warnings.warn(
/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0, 0.801] and step=0.05, but the range is not divisible by `step`. It will be replaced with [0.0, 0.8].
  warnings.warn(
Global seed set to 42
final_train: False
dl_sampler:  random
prop_cols: ['Label']
Number of TSD training data: 1555
prop_cols: ['Label']
Number of SSD training data: 1034
prop_cols: ['water_label']
Number of WS24_water training data: 698
prop_cols: ['water4_label']
Number of WS24_water4 training data: 698
prop_cols: ['acid_label']
Number of WS24_acid training data: 112
prop_cols: ['base_label']
Number of WS24_base training data: 80
prop_cols: ['boiling_label']
Number of WS24_boiling training data: 82
Number of total training data: 4259
prop_cols: ['Label']
Number of TSD validation data: 388
prop_cols: ['Label']
Number of SSD validation data: 250
prop_cols: ['water_label']
Number of WS24_water validation data: 175
prop_cols: ['water4_label']
Number of WS24_water4 validation data: 175
prop_cols: ['acid_label']
Number of WS24_acid validation data: 28
prop_cols: ['base_label']
Number of WS24_base validation data: 20
prop_cols: ['boiling_label']
Number of WS24_boiling validation data: 24
Number of total validation data: 1060
prop_cols: ['Label']
Number of TSD test data: 480
prop_cols: ['Label']
Number of SSD test data: 324
prop_cols: ['water_label']
Number of WS24_water test data: 219
prop_cols: ['water4_label']
Number of WS24_water4 test data: 219
prop_cols: ['acid_label']
Number of WS24_acid test data: 36
prop_cols: ['base_label']
Number of WS24_base test data: 24
prop_cols: ['boiling_label']
Number of WS24_boiling test data: 26
Number of total test data: 1328
##################################################args
batch_size : 256
num_workers : 14
random_seed : 42
accelerator : gpu
devices : 1
max_epochs : 500
limit_train_batches : None
limit_val_batches : None
auto_lr_bs_find : False
progress_bar : False
focal_alpha : 0.25
focal_gamma : 2
optim : adam
lr : 0.001
weight_decay : 1e-05
momentum : 0.9
optim_config : fine
group_lr : True
lr_mult : 13
lr_scheduler : reduce_on_plateau
lr_decay_steps : 20
lr_milestones : [10, 20, 30, 50]
lr_decay_rate : 0.8
lr_decay_min_lr : 1e-06
max_steps : -1
decay_power : 1
warmup_steps : 2
load_best : False
load_dir : None
load_ver : None
load_v_num : None
log_dir : logs
patience : 50
min_delta : 0.001
monitor : val_Metric
mode : max
eval_freq : 10
max_num_nbr : 10
radius : 8
dmin : 0
step : 0.2
use_cell_params : True
use_extra_fea : False
task_weights : [0.36510918055881664, 0.242779995304062, 0.16388823667527588, 0.16388823667527588, 0.026297252876262032, 0.018783752054472882, 0.019253345855834703]
augment : False
max_sample_size : {'train': 2004, 'val': 501}
model_name : att_cgcnn
atom_fea_len : 128
extra_fea_len : 32
h_fea_len : 80
n_conv : 8
n_h : 6
att_S : 64
dropout_prob : 0.65
att_pooling : False
task_norm : True
dwa_temp : 2.0
dwa_alpha : 0.8
atom_layer_norm : True
task_att_type : self
data_dir : ./data
tasks : ['TSD', 'SSD', 'WS24_water', 'WS24_water4', 'WS24_acid', 'WS24_base', 'WS24_boiling']
task_types : ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
dl_sampler : random
loss_aggregation : fixed_weight_sum
model_cfg : att_cgcnn
max_graph_len : 200
reconstruct : False
task_cfg : tsd_ssd_ws24
pruning : False
optuna_name : optuna
dataset_cls : <class 'CGCNN_MT.datamodule.dataset.LoadGraphData'>
orig_extra_fea_len : 6
orig_atom_fea_len : 92
nbr_fea_len : 41
model : CrystalGraphConvNet(
  (embedding_atom): Linear(in_features=92, out_features=144, bias=True)
  (embedding_atom_norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
  (convs): ModuleList(
    (0-8): 9 x ConvLayer(
      (fc_full): Linear(in_features=329, out_features=288, bias=True)
      (sigmoid): Sigmoid()
      (softplus1): Softplus(beta=1.0, threshold=20.0)
      (bn1): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (softplus2): Softplus(beta=1.0, threshold=20.0)
    )
  )
  (embedding_extra): Linear(in_features=6, out_features=40, bias=True)
  (embedding_extra_norm): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (embedding_extra_softplus): Softplus(beta=1.0, threshold=20.0)
  (conv_to_fc): Linear(in_features=184, out_features=272, bias=True)
  (conv_to_fc_norm): BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_to_fc_softplus): Softplus(beta=1.0, threshold=20.0)
  (dropout): Dropout(p=0.4, inplace=False)
  (fcs): ModuleList(
    (0-2): 3 x Linear(in_features=272, out_features=272, bias=True)
  )
  (norms): ModuleList(
    (0-2): 3 x BatchNorm1d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (softpluses): ModuleList(
    (0-2): 3 x Softplus(beta=1.0, threshold=20.0)
  )
  (fc_outs): ModuleList(
    (0): OutputLayer(
      (fc): Linear(in_features=272, out_features=1, bias=True)
    )
    (1-2): 2 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=272, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (3): OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=272, out_features=4, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
    (4-6): 3 x OutputLayer(
      (fc): Sequential(
        (0): Linear(in_features=272, out_features=2, bias=True)
        (1): LogSoftmax(dim=1)
      )
    )
  )
  (task_norms): ModuleList(
    (0-6): 7 x LayerNorm((272,), eps=1e-05, elementwise_affine=True)
  )
  (task_attentions): ModuleList(
    (0-6): 7 x SelfAttention(
      (query): Linear(in_features=272, out_features=272, bias=True)
      (key): Linear(in_features=272, out_features=272, bias=True)
      (value): Linear(in_features=272, out_features=272, bias=True)
      (softmax): Softmax(dim=-1)
    )
  )
)
normalizers : [<CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0430>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0f40>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d07f0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0c10>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0130>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d08b0>, <CGCNN_MT.datamodule.data_interface.Normalizer object at 0x7a8f926d0490>]
ckpt_path : None
strategy : auto
##################################################args
task_types:  ['regression', 'classification', 'classification', 'classification_4', 'classification', 'classification', 'classification']
    | Name                            | Type                | Params | In sizes                                  | Out sizes
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   | model                           | CrystalGraphConvNet | 813 K  | ?                                         | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 80], [256, 80], [256, 80], [256, 80], [256, 80], [256, 80], [256, 80]]]
1   | model.embedding_atom            | Linear              | 11.9 K | [4608, 92]                                | [4608, 128]
2   | model.embedding_atom_norm       | LayerNorm           | 256    | [4608, 128]                               | [4608, 128]
3   | model.convs                     | ModuleList          | 616 K  | ?                                         | ?
4   | model.convs.0                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
5   | model.convs.0.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
6   | model.convs.0.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
7   | model.convs.0.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
8   | model.convs.0.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
9   | model.convs.0.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
10  | model.convs.0.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
11  | model.convs.1                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
12  | model.convs.1.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
13  | model.convs.1.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
14  | model.convs.1.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
15  | model.convs.1.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
16  | model.convs.1.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
17  | model.convs.1.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
18  | model.convs.2                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
19  | model.convs.2.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
20  | model.convs.2.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
21  | model.convs.2.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
22  | model.convs.2.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
23  | model.convs.2.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
24  | model.convs.2.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
25  | model.convs.3                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
26  | model.convs.3.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
27  | model.convs.3.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
28  | model.convs.3.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
29  | model.convs.3.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
30  | model.convs.3.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
31  | model.convs.3.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
32  | model.convs.4                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
33  | model.convs.4.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
34  | model.convs.4.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
35  | model.convs.4.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
36  | model.convs.4.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
37  | model.convs.4.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
38  | model.convs.4.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
39  | model.convs.5                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
40  | model.convs.5.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
41  | model.convs.5.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
42  | model.convs.5.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
43  | model.convs.5.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
44  | model.convs.5.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
45  | model.convs.5.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
46  | model.convs.6                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
47  | model.convs.6.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
48  | model.convs.6.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
49  | model.convs.6.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
50  | model.convs.6.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
51  | model.convs.6.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
52  | model.convs.6.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
53  | model.convs.7                   | ConvLayer           | 77.1 K | [[4608, 128], [4608, 10, 41], [4608, 10]] | [4608, 128]
54  | model.convs.7.fc_full           | Linear              | 76.3 K | [4608, 10, 297]                           | [4608, 10, 256]
55  | model.convs.7.sigmoid           | Sigmoid             | 0      | [4608, 10, 128]                           | [4608, 10, 128]
56  | model.convs.7.softplus1         | Softplus            | 0      | [4608, 10, 128]                           | [4608, 10, 128]
57  | model.convs.7.bn1               | BatchNorm1d         | 512    | [46080, 256]                              | [46080, 256]
58  | model.convs.7.bn2               | BatchNorm1d         | 256    | [4608, 128]                               | [4608, 128]
59  | model.convs.7.softplus2         | Softplus            | 0      | [4608, 128]                               | [4608, 128]
60  | model.embedding_extra           | Linear              | 224    | [256, 6]                                  | [256, 32]
61  | model.embedding_extra_norm      | BatchNorm1d         | 64     | [256, 32]                                 | [256, 32]
62  | model.embedding_extra_softplus  | Softplus            | 0      | [256, 32]                                 | [256, 32]
63  | model.conv_to_fc                | Linear              | 12.9 K | [256, 160]                                | [256, 80]
64  | model.conv_to_fc_norm           | BatchNorm1d         | 160    | [256, 80]                                 | [256, 80]
65  | model.conv_to_fc_softplus       | Softplus            | 0      | [256, 80]                                 | [256, 80]
66  | model.dropout                   | Dropout             | 0      | [256, 80]                                 | [256, 80]
67  | model.fcs                       | ModuleList          | 32.4 K | ?                                         | ?
68  | model.fcs.0                     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
69  | model.fcs.1                     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
70  | model.fcs.2                     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
71  | model.fcs.3                     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
72  | model.fcs.4                     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
73  | model.norms                     | ModuleList          | 800    | ?                                         | ?
74  | model.norms.0                   | BatchNorm1d         | 160    | [256, 80]                                 | [256, 80]
75  | model.norms.1                   | BatchNorm1d         | 160    | [256, 80]                                 | [256, 80]
76  | model.norms.2                   | BatchNorm1d         | 160    | [256, 80]                                 | [256, 80]
77  | model.norms.3                   | BatchNorm1d         | 160    | [256, 80]                                 | [256, 80]
78  | model.norms.4                   | BatchNorm1d         | 160    | [256, 80]                                 | [256, 80]
79  | model.softpluses                | ModuleList          | 0      | ?                                         | ?
80  | model.softpluses.0              | Softplus            | 0      | [256, 80]                                 | [256, 80]
81  | model.softpluses.1              | Softplus            | 0      | [256, 80]                                 | [256, 80]
82  | model.softpluses.2              | Softplus            | 0      | [256, 80]                                 | [256, 80]
83  | model.softpluses.3              | Softplus            | 0      | [256, 80]                                 | [256, 80]
84  | model.softpluses.4              | Softplus            | 0      | [256, 80]                                 | [256, 80]
85  | model.fc_outs                   | ModuleList          | 1.2 K  | ?                                         | ?
86  | model.fc_outs.0                 | OutputLayer         | 81     | [256, 80]                                 | [256, 1]
87  | model.fc_outs.0.fc              | Linear              | 81     | [256, 80]                                 | [256, 1]
88  | model.fc_outs.1                 | OutputLayer         | 162    | [256, 80]                                 | [256, 2]
89  | model.fc_outs.1.fc              | Sequential          | 162    | [256, 80]                                 | [256, 2]
90  | model.fc_outs.1.fc.0            | Linear              | 162    | [256, 80]                                 | [256, 2]
91  | model.fc_outs.1.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
92  | model.fc_outs.2                 | OutputLayer         | 162    | [256, 80]                                 | [256, 2]
93  | model.fc_outs.2.fc              | Sequential          | 162    | [256, 80]                                 | [256, 2]
94  | model.fc_outs.2.fc.0            | Linear              | 162    | [256, 80]                                 | [256, 2]
95  | model.fc_outs.2.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
96  | model.fc_outs.3                 | OutputLayer         | 324    | [256, 80]                                 | [256, 4]
97  | model.fc_outs.3.fc              | Sequential          | 324    | [256, 80]                                 | [256, 4]
98  | model.fc_outs.3.fc.0            | Linear              | 324    | [256, 80]                                 | [256, 4]
99  | model.fc_outs.3.fc.1            | LogSoftmax          | 0      | [256, 4]                                  | [256, 4]
100 | model.fc_outs.4                 | OutputLayer         | 162    | [256, 80]                                 | [256, 2]
101 | model.fc_outs.4.fc              | Sequential          | 162    | [256, 80]                                 | [256, 2]
102 | model.fc_outs.4.fc.0            | Linear              | 162    | [256, 80]                                 | [256, 2]
103 | model.fc_outs.4.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
104 | model.fc_outs.5                 | OutputLayer         | 162    | [256, 80]                                 | [256, 2]
105 | model.fc_outs.5.fc              | Sequential          | 162    | [256, 80]                                 | [256, 2]
106 | model.fc_outs.5.fc.0            | Linear              | 162    | [256, 80]                                 | [256, 2]
107 | model.fc_outs.5.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
108 | model.fc_outs.6                 | OutputLayer         | 162    | [256, 80]                                 | [256, 2]
109 | model.fc_outs.6.fc              | Sequential          | 162    | [256, 80]                                 | [256, 2]
110 | model.fc_outs.6.fc.0            | Linear              | 162    | [256, 80]                                 | [256, 2]
111 | model.fc_outs.6.fc.1            | LogSoftmax          | 0      | [256, 2]                                  | [256, 2]
112 | model.task_norms                | ModuleList          | 1.1 K  | ?                                         | ?
113 | model.task_norms.0              | LayerNorm           | 160    | [256, 80]                                 | [256, 80]
114 | model.task_norms.1              | LayerNorm           | 160    | [256, 80]                                 | [256, 80]
115 | model.task_norms.2              | LayerNorm           | 160    | [256, 80]                                 | [256, 80]
116 | model.task_norms.3              | LayerNorm           | 160    | [256, 80]                                 | [256, 80]
117 | model.task_norms.4              | LayerNorm           | 160    | [256, 80]                                 | [256, 80]
118 | model.task_norms.5              | LayerNorm           | 160    | [256, 80]                                 | [256, 80]
119 | model.task_norms.6              | LayerNorm           | 160    | [256, 80]                                 | [256, 80]
120 | model.task_attentions           | ModuleList          | 136 K  | ?                                         | ?
121 | model.task_attentions.0         | SelfAttention       | 19.4 K | [256, 80]                                 | [256, 80]
122 | model.task_attentions.0.query   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
123 | model.task_attentions.0.key     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
124 | model.task_attentions.0.value   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
125 | model.task_attentions.0.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
126 | model.task_attentions.1         | SelfAttention       | 19.4 K | [256, 80]                                 | [256, 80]
127 | model.task_attentions.1.query   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
128 | model.task_attentions.1.key     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
129 | model.task_attentions.1.value   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
130 | model.task_attentions.1.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
131 | model.task_attentions.2         | SelfAttention       | 19.4 K | [256, 80]                                 | [256, 80]
132 | model.task_attentions.2.query   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
133 | model.task_attentions.2.key     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
134 | model.task_attentions.2.value   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
135 | model.task_attentions.2.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
136 | model.task_attentions.3         | SelfAttention       | 19.4 K | [256, 80]                                 | [256, 80]
137 | model.task_attentions.3.query   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
138 | model.task_attentions.3.key     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
139 | model.task_attentions.3.value   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
140 | model.task_attentions.3.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
141 | model.task_attentions.4         | SelfAttention       | 19.4 K | [256, 80]                                 | [256, 80]
142 | model.task_attentions.4.query   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
143 | model.task_attentions.4.key     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
144 | model.task_attentions.4.value   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
145 | model.task_attentions.4.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
146 | model.task_attentions.5         | SelfAttention       | 19.4 K | [256, 80]                                 | [256, 80]
147 | model.task_attentions.5.query   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
148 | model.task_attentions.5.key     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
149 | model.task_attentions.5.value   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
150 | model.task_attentions.5.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
151 | model.task_attentions.6         | SelfAttention       | 19.4 K | [256, 80]                                 | [256, 80]
152 | model.task_attentions.6.query   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
153 | model.task_attentions.6.key     | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
154 | model.task_attentions.6.value   | Linear              | 6.5 K  | [256, 80]                                 | [256, 80]
155 | model.task_attentions.6.softmax | Softmax             | 0      | [256, 1, 1]                               | [256, 1, 1]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
813 K     Trainable params
0         Non-trainable params
813 K     Total params
3.254     Total estimated model params size (MB)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
log_dir: /home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/logs/TSD_SSD_WS24_water_WS24_water4_WS24_acid_WS24_base_WS24_boiling_seed42_att_cgcnn/version_24
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
==================================================
normal_decay
['embedding_atom.weight', 'convs.0.fc_full.weight', 'convs.1.fc_full.weight', 'convs.2.fc_full.weight', 'convs.3.fc_full.weight', 'convs.4.fc_full.weight', 'convs.5.fc_full.weight', 'convs.6.fc_full.weight', 'convs.7.fc_full.weight', 'embedding_extra.weight', 'conv_to_fc.weight', 'fcs.0.weight', 'fcs.1.weight', 'fcs.2.weight', 'fcs.3.weight', 'fcs.4.weight']
==================================================
normal_no_decay
['embedding_atom.bias', 'embedding_atom_norm.weight', 'embedding_atom_norm.bias', 'convs.0.fc_full.bias', 'convs.0.bn1.weight', 'convs.0.bn1.bias', 'convs.0.bn2.weight', 'convs.0.bn2.bias', 'convs.1.fc_full.bias', 'convs.1.bn1.weight', 'convs.1.bn1.bias', 'convs.1.bn2.weight', 'convs.1.bn2.bias', 'convs.2.fc_full.bias', 'convs.2.bn1.weight', 'convs.2.bn1.bias', 'convs.2.bn2.weight', 'convs.2.bn2.bias', 'convs.3.fc_full.bias', 'convs.3.bn1.weight', 'convs.3.bn1.bias', 'convs.3.bn2.weight', 'convs.3.bn2.bias', 'convs.4.fc_full.bias', 'convs.4.bn1.weight', 'convs.4.bn1.bias', 'convs.4.bn2.weight', 'convs.4.bn2.bias', 'convs.5.fc_full.bias', 'convs.5.bn1.weight', 'convs.5.bn1.bias', 'convs.5.bn2.weight', 'convs.5.bn2.bias', 'convs.6.fc_full.bias', 'convs.6.bn1.weight', 'convs.6.bn1.bias', 'convs.6.bn2.weight', 'convs.6.bn2.bias', 'convs.7.fc_full.bias', 'convs.7.bn1.weight', 'convs.7.bn1.bias', 'convs.7.bn2.weight', 'convs.7.bn2.bias', 'embedding_extra.bias', 'embedding_extra_norm.weight', 'embedding_extra_norm.bias', 'conv_to_fc.bias', 'conv_to_fc_norm.weight', 'conv_to_fc_norm.bias', 'fcs.0.bias', 'fcs.1.bias', 'fcs.2.bias', 'fcs.3.bias', 'fcs.4.bias', 'norms.0.weight', 'norms.0.bias', 'norms.1.weight', 'norms.1.bias', 'norms.2.weight', 'norms.2.bias', 'norms.3.weight', 'norms.3.bias', 'norms.4.weight', 'norms.4.bias', 'task_norms.0.weight', 'task_norms.0.bias', 'task_norms.1.weight', 'task_norms.1.bias', 'task_norms.2.weight', 'task_norms.2.bias', 'task_norms.3.weight', 'task_norms.3.bias', 'task_norms.4.weight', 'task_norms.4.bias', 'task_norms.5.weight', 'task_norms.5.bias', 'task_norms.6.weight', 'task_norms.6.bias']
==================================================
head_decay
['fc_outs.0.fc.weight', 'fc_outs.1.fc.0.weight', 'fc_outs.2.fc.0.weight', 'fc_outs.3.fc.0.weight', 'fc_outs.4.fc.0.weight', 'fc_outs.5.fc.0.weight', 'fc_outs.6.fc.0.weight', 'task_attentions.0.query.weight', 'task_attentions.0.key.weight', 'task_attentions.0.value.weight', 'task_attentions.1.query.weight', 'task_attentions.1.key.weight', 'task_attentions.1.value.weight', 'task_attentions.2.query.weight', 'task_attentions.2.key.weight', 'task_attentions.2.value.weight', 'task_attentions.3.query.weight', 'task_attentions.3.key.weight', 'task_attentions.3.value.weight', 'task_attentions.4.query.weight', 'task_attentions.4.key.weight', 'task_attentions.4.value.weight', 'task_attentions.5.query.weight', 'task_attentions.5.key.weight', 'task_attentions.5.value.weight', 'task_attentions.6.query.weight', 'task_attentions.6.key.weight', 'task_attentions.6.value.weight']
==================================================
head_no_decay
['fc_outs.0.fc.bias', 'fc_outs.1.fc.0.bias', 'fc_outs.2.fc.0.bias', 'fc_outs.3.fc.0.bias', 'fc_outs.4.fc.0.bias', 'fc_outs.5.fc.0.bias', 'fc_outs.6.fc.0.bias', 'task_attentions.0.query.bias', 'task_attentions.0.key.bias', 'task_attentions.0.value.bias', 'task_attentions.1.query.bias', 'task_attentions.1.key.bias', 'task_attentions.1.value.bias', 'task_attentions.2.query.bias', 'task_attentions.2.key.bias', 'task_attentions.2.value.bias', 'task_attentions.3.query.bias', 'task_attentions.3.key.bias', 'task_attentions.3.value.bias', 'task_attentions.4.query.bias', 'task_attentions.4.key.bias', 'task_attentions.4.value.bias', 'task_attentions.5.query.bias', 'task_attentions.5.key.bias', 'task_attentions.5.value.bias', 'task_attentions.6.query.bias', 'task_attentions.6.key.bias', 'task_attentions.6.value.bias']
==================================================
log_vars
[]
Loading `train_dataloader` to estimate number of stepping batches.
Using random sampler for training data.
max_epochs: 500 | max_steps: 8500 | warmup_steps : 2 lr_mult : 13 | weight_decay : 1e-05 | decay_power : 1

  | Name  | Type                | Params | In sizes | Out sizes
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0 | model | CrystalGraphConvNet | 813 K  | ?        | [[[256, 1], [256, 2], [256, 2], [256, 4], [256, 2], [256, 2], [256, 2]], [[256, 80], [256, 80], [256, 80], [256, 80], [256, 80], [256, 80], [256, 80]]]
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
813 K     Trainable params
0         Non-trainable params
813 K     Total params
3.254     Total estimated model params size (MB)
Using no sampler for validation data.
[W 2025-12-03 18:13:25,510] Trial 26 failed with parameters: {'atom_fea_len': 128, 'h_fea_len': 80, 'n_conv': 8, 'n_h': 6, 'lr_mult': 13, 'extra_fea_len': 32, 'dropout': 0.65} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 848.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 574.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.26 GiB memory in use. Of the allocated memory 20.10 GiB is allocated by PyTorch, and 956.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').
Traceback (most recent call last):
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/optuna/study/_optimize.py", line 205, in _run_trial
    value_or_values = func(trial)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/hyperopt.py", line 174, in objective
    best_metric = main(args, trial)  # Retrieve the best validation loss from the Trainer's checkpoint callback
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/main.py", line 161, in main
    trainer.fit(model, datamodule)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in fit
    call._call_and_handle_interrupt(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 43, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 571, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 980, in _run
    results = self._run_stage()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self.fit_loop.run()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 202, in run
    self.advance()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 355, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 219, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 188, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 266, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 146, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1276, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 161, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 231, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 116, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 516, in wrapper
    out = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/optimizer.py", line 81, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 103, in _wrap_closure
    closure_result = closure()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 142, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 128, in closure
    step_output = self._step_fn()
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 315, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 294, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 380, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 143, in training_step
    loss = self._step(batch, batch_idx, split='train')
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/module.py", line 188, in _step
    outputs, last_layer_feas = self.model(**batch)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/att_cgcnn.py", line 115, in forward
    atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/Desktop/D/MOFSNN_D/CGCNN_MT/module/layers.py", line 91, in forward
    total_gated_fea = self.bn1(total_gated_fea.view(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
  File "/home/dharunkraja/miniconda3/envs/mofsnn/lib/python3.9/site-packages/torch/nn/functional.py", line 2817, in batch_norm
    return torch.batch_norm(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 848.00 MiB. GPU 0 has a total capacity of 22.03 GiB of which 574.94 MiB is free. Process 3469 has 26.47 MiB memory in use. Including non-PyTorch memory, this process has 21.26 GiB memory in use. Of the allocated memory 20.10 GiB is allocated by PyTorch, and 956.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W 2025-12-03 18:13:25,512] Trial 26 failed with value None.
Number of finished trials: 27
Best trial:
  Value: 0.5247209443643848
  Params:
    atom_fea_len: 48
    h_fea_len: 96
    n_conv: 4
    n_h: 6
    lr_mult: 13
    extra_fea_len: 52
    dropout: 0.75
Training completed with return code: 0